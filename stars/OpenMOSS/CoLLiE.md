---
project: CoLLiE
stars: 417
description: Collaborative Training of Large Language Models in an Efficient Way
url: https://github.com/OpenMOSS/CoLLiE
---

CoLLiE
======

CoLLiE (Collaborative Tuning of Large Language Models in an Efficient Way)ï¼Œä¸€ä¸ªå¸®åŠ©æ‚¨ä»é›¶å¼€å§‹è®­ç»ƒå¤§æ¨¡å‹çš„å®Œæ•´å·¥å…·ç®±ã€‚

#### 

\[ ç®€ä½“ä¸­æ–‡ \] | \[ English \]

æ–°é—»
--

-   \[2023/12\] ğŸ‰ CoLLiEè¢«EMNLP System Demonstrationsæ¥æ”¶ï¼šCoLLiE: Collaborative Training of Large Language Models in an Efficient Way
-   \[2023/08\] è¯„æµ‹ç»“æœæ–°å¢æ˜¾å­˜å ç”¨ä¸æ¨¡å‹å¤§å°çš„å…³ç³»å’Œååé‡ã€‚
-   \[2023/07\] å‘å¸ƒPythonåŒ…`collie-lm`ã€‚æ‚¨å¯ä»¥åœ¨PyPIä¸­æŸ¥çœ‹æ›´å¤šç»†èŠ‚ï¼

ç›®å½•
--

-   ä¸ºä»€ä¹ˆé€‰æ‹©CoLLiE
-   ç‰¹æ€§
-   CoLLiEæ”¯æŒçš„æ¨¡å‹
-   è¯„æµ‹
-   å®‰è£…
-   Dockerå®‰è£…
-   ä½¿ç”¨
    -   å¿«é€Ÿå¼€å§‹
    -   æœ‰è¶£çš„æ’ä»¶
    -   æ›´å¤šæˆåŠŸæ ·ä¾‹å’Œå®Œæ•´æ•™ç¨‹
-   ç¤¾åŒº
-   è´¡çŒ®è€…
-   å¼•ç”¨æˆ‘ä»¬

ä¸ºä»€ä¹ˆé€‰æ‹©CoLLiE
-----------

CoLLiEæ˜¯ä¸€ä¸ªå¯ä»¥å¸®åŠ©æ‚¨ä»é›¶å¼€å§‹è®­ç»ƒå¤§æ¨¡å‹çš„å®Œæ•´å·¥å…·ç®±ï¼Œå®ƒæä¾›äº†æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹å¾®è°ƒã€æ¨¡å‹ä¿å­˜ä»¥åŠè®­ç»ƒè¿‡ç¨‹å„é¡¹æŒ‡æ ‡ç›‘æµ‹ç­‰åŠŸèƒ½ã€‚CoLLiEé›†æˆäº†ç°æœ‰çš„å¹¶è¡Œç­–ç•¥ã€é«˜æ•ˆå‚æ•°å¾®è°ƒæ–¹æ³•å’Œé«˜æ•ˆä¼˜åŒ–å™¨ï¼Œä»¥åŠ å¿«è®­ç»ƒçš„é€Ÿåº¦ï¼Œæé«˜è®­ç»ƒçš„è´¨é‡ï¼Œé™ä½è®­ç»ƒçš„å¼€é”€ã€‚CoLLiEæ”¯æŒä¸»æµçš„å¤šç§æ¨¡å‹ï¼ˆå¦‚MOSS, InternLM, LLaMA, ChatGLMç­‰ï¼‰ï¼Œæ‚¨å¯ä»¥è½»æ¾åœ¨ä¸åŒçš„æ¨¡å‹ä¹‹é—´åˆ‡æ¢ã€‚æ­¤å¤–ï¼ŒCoLLiEæä¾›äº†ä¸°å¯Œçš„æ–‡æ¡£ï¼Œä½¿åˆå­¦è€…å¯ä»¥å¿«é€Ÿå…¥é—¨ã€‚åŒæ—¶ï¼ŒCoLLiEè¿˜æä¾›äº†é«˜åº¦å¯å®šåˆ¶åŒ–çš„åŠŸèƒ½å’Œçµæ´»çš„é…ç½®é€‰é¡¹ï¼Œä½¿æœ‰ç»éªŒçš„ç”¨æˆ·èƒ½å¤Ÿæ ¹æ®è‡ªå·±çš„éœ€æ±‚è¿›è¡Œä¸ªæ€§åŒ–å®šåˆ¶ã€‚æ— è®ºæ‚¨æ˜¯åˆå­¦è€…è¿˜æ˜¯æœ‰ç»éªŒçš„ä¸“ä¸šäººå£«ï¼ŒCoLLiEéƒ½å¯ä»¥ä¸ºæ‚¨æä¾›æ»¡è¶³éœ€æ±‚çš„è§£å†³æ–¹æ¡ˆã€‚

ç‰¹ç‚¹
--

CoLLiE åŸºäº _DeepSpeed_ å’Œ _PyTorch_ï¼Œä¸ºå¤§å‹è¯­è¨€æ¨¡å‹æä¾›åä½œå¼å’Œé«˜æ•ˆçš„è°ƒä¼˜æ–¹æ³•ã€‚ å®ƒä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å››ä¸ªç‰¹ç‚¹ï¼š

-   å¹¶è¡Œç­–ç•¥
    -   æ•°æ®å¹¶è¡Œ (DP)
    -   æµæ°´çº¿å¹¶è¡Œ (PP)
    -   å¼ é‡å¹¶è¡Œ (TP)
    -   é›¶å†—ä½™ä¼˜åŒ–å™¨ (ZeRO)
-   é«˜æ•ˆå¾®è°ƒ
    -   LOMO
    -   LoRA
    -   Flash Attention
-   è®¾è®¡ä¼˜é›…
-   ç”¨æˆ·å‹å¥½

å®Œæ•´ç‰¹æ€§

CoLLiEæ”¯æŒçš„æ¨¡å‹
-----------

-   MOSSç³»åˆ—ï¼šMOSS-MOON
-   InternLMç³»åˆ—ï¼šInternLM2
-   LLaMAç³»åˆ—ï¼šLLaMAã€LLaMA-2
-   ChatGLMç³»åˆ—ï¼šChatGLMã€ChatGLM2

è¯„æµ‹
--

### æ˜¾å­˜å ç”¨

ä½¿ç”¨å¼ é‡å¹¶è¡Œæµ‹è¯•äº†æ‰¹é‡å¤§å°ä¸º 1ï¼Œåºåˆ—é•¿åº¦ä¸º 2048ï¼Œæ¢¯åº¦ç´¯è®¡æ­¥æ•°ä¸º 2 ä¸‹æ˜¾å­˜å ç”¨æƒ…å†µï¼Œç»“æœå¦‚ä¸‹ï¼š

### ååé‡

åœ¨ A100 å’Œ RTX-3090 ä¸Šæµ‹è¯•äº†ä¸åŒæ‰¹é‡å¤§å°ä¸‹ä½¿ç”¨ Adam ä¼˜åŒ–å™¨çš„ååé‡ï¼Œç»“æœå¦‚ä¸‹ï¼š

å®‰è£…
--

åœ¨å®‰è£…å‰ï¼Œä½ éœ€è¦ç¡®ä¿ï¼š

-   PyTorch >= 1.13
-   CUDA >= 11.6
-   Linux OS

### PyPIå®‰è£…

ä½ å¯ä»¥ç®€å•åœ°é€šè¿‡PyPIå®‰è£…ï¼Œå‘½ä»¤å¦‚ä¸‹ï¼š

pip install collie-lm

### æºç å®‰è£…

git clone https://github.com/OpenLMLab/collie
python setup.py install

Dockerå®‰è£…
--------

ä½¿ç”¨
--

### å¿«é€Ÿå¼€å§‹

ä¸‹é¢å°†æä¾›ä¸€ä¸ªä½¿ç”¨CoLLiEè®­ç»ƒMossçš„æ ·ä¾‹ï¼ŒåŒæ—¶ä½¿ç”¨LOMOä¼˜åŒ–å™¨ï¼Œå¹¶ä¸”å¼€å¯ZeRO3æ¥é™ä½æ˜¾å­˜æ¶ˆè€—ã€‚

é‚£ä¹ˆï¼Œè¯·æŒ‰ç…§ä¸‹é¢çš„æ­¥éª¤å¼€å¯ä½ çš„å¤§æ¨¡å‹è®­ç»ƒä¹‹æ—…å§~

#### ç¬¬ä¸€æ­¥ï¼šå¯¼å…¥å¿…è¦çš„åŒ…

from transformers import AutoTokenizer
from collie.config import CollieConfig
from collie.data import CollieDatasetForTraining
from collie.data import CollieDataLoader
from collie.optim.lomo import Lomo
from collie.controller.trainer import Trainer
from collie.controller.evaluator import EvaluatorForPerplexity, EvaluatorForGeneration
from collie.models.moss\_moon import Moss003MoonForCausalLM
from collie.utils.monitor import StepTimeMonitor, TGSMonitor, MemoryMonitor, LossMonitor, EvalMonitor
from collie.metrics import DecodeMetric, PPLMetric
from collie.module import GPTLMLoss
from collie.utils.data\_provider import GradioProvider

#### ç¬¬äºŒæ­¥ï¼šè®¾ç½®è·¯å¾„

é€‰æ‹©é¢„è®­ç»ƒæ¨¡å‹ä¸ºMOSS

```
pretrained_model = "fnlp/moss-moon-003-sft"
```

#### ç¬¬ä¸‰æ­¥ï¼šè®¾ç½®CoLLiEé…ç½®

config \= CollieConfig.from\_pretrained(pretrained\_model, trust\_remote\_code\=True)
\# å¼ é‡å¹¶è¡Œ
config.tp\_size \= 2
\# æ•°æ®å¹¶è¡Œ
config.dp\_size \= 1
\# æµæ°´çº¿å¹¶è¡Œ
config.pp\_size \= 1
\# è®­ç»ƒçš„epochæ•°é‡
config.train\_epochs \= 1
\# æ¯{100}ä¸ªstepè¿›è¡Œä¸€æ¬¡eval
config.eval\_per\_n\_steps \= 100
\# æ¯{1}ä¸ªepochè¿›è¡Œä¸€æ¬¡eval
config.eval\_per\_n\_epochs \= 1 
\# æ¯ä¸ªGPUçš„batch\_sizeè®¾ç½®ä¸º{16}
config.train\_micro\_batch\_size \= 16
\# æ¯æ¬¡evalçš„batch\_sizeä¸º{1}
config.eval\_batch\_size \= 1
\# è®¾ç½®DeepSpeedé…ç½®
config.ds\_config \= {
        \# å¼€å¯FP16
        "fp16": {
            "enabled": True
        },
        "zero\_allow\_untested\_optimizer": True,
        "zero\_force\_ds\_cpu\_optimizer": False,
        \# å¼€å¯ZeRO-3
        "zero\_optimization": {
            "stage": 3,
            "offload\_optimizer": {
                "device": "cpu",
                "pin\_memory": False
            }
        },
        "monitor\_config": {
            "enabled": True,
            "tag": "adan",
            "csv\_monitor": {
                "enabled": True,
                "output\_path": "./ds\_logs/"
            }
        }
}

#### ç¬¬å››æ­¥ï¼šè®¾ç½®Tokenizer

tokenizer \= AutoTokenizer.from\_pretrained("fnlp/moss-moon-003-sft", trust\_remote\_code\=True)

#### ç¬¬äº”æ­¥ï¼šåŠ è½½æ•°æ®é›†

è¿™é‡Œè‡ªå®šä¹‰ä¸€ä¸ªæ•°æ®é›†ï¼Œæ•°æ®æ ¼å¼å¯ä»¥æä¾›ä¸¤ç§å½¢å¼ï¼Œå…·ä½“è¯·å‚è€ƒæ–‡æ¡£ã€‚

train\_dataset \= \[
    {
        'input': 'Collie is a python package for ',
        'output': 'finetuning large language models.'
    } for \_ in range(10000)
\]
train\_dataset \= CollieDatasetForTraining(train\_dataset, tokenizer)
eval\_dataset \= train\_dataset\[:32\]

#### ç¬¬å…­æ­¥ï¼šåŠ è½½é¢„è®­ç»ƒæ¨¡å‹

model \= Moss003MoonForCausalLM.from\_pretrained(pretrained\_model, config\=config)

#### ç¬¬ä¸ƒæ­¥ï¼šè®¾ç½®ä¼˜åŒ–å™¨

optimizer \= Lomo(
    model,
    lr \= 0.001,
    clip\_grad\_norm \= 5.0
)

#### ç¬¬å…«æ­¥ï¼šæ·»åŠ ç›‘è§†å™¨

monitors \= \[
    \# æ¯ä¸ªstepç”¨æ—¶ç›‘æµ‹
    StepTimeMonitor(config),
    \# TGSï¼ˆæ¯ç§’ç”Ÿæˆtokenæ•°é‡ç›‘æµ‹ï¼‰
    TGSMonitor(config),
    \# æ˜¾å­˜ä½¿ç”¨æƒ…å†µç›‘æµ‹
    MemoryMonitor(config),
    \# Losså€¼ç›‘æµ‹
    LossMonitor(config),
    \# Evalç»“æœç›‘æµ‹
    EvalMonitor(config)
\]

#### ç¬¬ä¹æ­¥ï¼šæ·»åŠ Evaluator

è¿™é‡Œæ·»åŠ ä¸¤ä¸ªEvaluatorï¼Œåˆ†åˆ«ç”¨äºè®¡ç®—PPL(å›°æƒ‘åº¦ï¼šPerplexity)å’Œä¿å­˜Decodeç»“æœã€‚

evaluator\_ppl \= EvaluatorForPerplexity(
    model \= model,
    config \= config,
    dataset \= eval\_dataset,
    monitors \= \[
        EvalMonitor(config)
    \],
    metrics \= {
        'ppl': PPLMetric()
    }
)
evaluator\_decode \= EvaluatorForGeneration(
    model \= model,
    config \= config,
    tokenizer \= tokenizer,
    dataset \= eval\_dataset,
    monitors \= \[
        EvalMonitor(config)
    \],
    metrics \= {
        'decode': DecodeMetric()
    }

)

#### ç¬¬åæ­¥ï¼šå®ä¾‹åŒ–Trainer

trainer \= Trainer(
    model \= model,
    config \= config,
    loss\_fn \= GPTLMLoss(\-100),
    optimizer \= optimizer,
    train\_dataset \= train\_dataset,
    monitors \= monitors,
    evaluators \= \[evaluator\_ppl, evaluator\_decode\],
)
\# å¼€å§‹è®­ç»ƒ/éªŒè¯
trainer.train()

#### æœ€åä¸€æ­¥ï¼šå¯åŠ¨å‘½ä»¤è¡Œï¼Œå¼€å§‹è®­ç»ƒï¼ğŸ‘

Command CUDA\_VISIBLE\_DEVICES=0,1,2,3 torchrun --rdzv\_backend=c10d --rdzv\_endpoint=localhost:29402 --nnodes=1 --nproc\_per\_node=4 finetune\_moss\_for\_training.py

å¦‚æœä½ çš„å‘½ä»¤è¡Œå‡ºç°å¦‚ä¸‹çš„è¿›åº¦æ¡ï¼Œé‚£ä¹ˆæ­å–œä½ ï¼Œä½ å·²ç»æˆåŠŸå¼€å§‹è®­ç»ƒä½ çš„å¤§æ¨¡å‹ï¼

å®Œæ•´ä»£ç è¯·å‚è€ƒexamples/finetune\_moss\_for\_training.pyã€‚

### æœ‰è¶£çš„æ’ä»¶

CoLLiEæä¾›äº†è®¸å¤šå³æ’å³ç”¨çš„æ’ä»¶ï¼Œä¸‹é¢å°†ä»‹ç»Monitoræ£€æµ‹å™¨å’Œå¼‚æ­¥DataProviderï¼Œæ›´å¤šæ’ä»¶ç­‰å¾…æ¢ç´¢å’Œå¼€å‘...

#### Monitorç›‘æµ‹å™¨

åœ¨CollieConfig.ds\_configä¸­æ·»åŠ monitoré…ç½®ï¼Œå¹¶åœ¨Trainerä¸­å¯ç”¨å³å¯åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ‰“å¼€ç›‘æµ‹å™¨ã€‚

    "monitor\_config": {
        \# å¼€å¯æ£€æµ‹å™¨
        "enabled": True,
        \# ä¿å­˜çš„æ–‡ä»¶åå‰ç¼€
        "tag": "adan",
        \# ä¿å­˜æ–‡ä»¶æ ¼å¼:csv
        "csv\_monitor": {
            "enabled": True,
            \# ä¿å­˜æ–‡ä»¶å¤¹
            "output\_path": "./ds\_logs/"
        }
    }

å¯ç”¨æ£€æµ‹å™¨åï¼Œä½ å°†åœ¨`ds_logs`æ–‡ä»¶å¤¹ä¸­è·å–ç›¸å…³çš„æ–‡ä»¶ï¼Œå¦‚ï¼š

#### å¼‚æ­¥DataProvider

ä½ åªéœ€è¦åœ¨Trainerä¸­æ·»åŠ ï¼šdata\_providerï¼Œå³å¯åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ‰“å¼€ä¸€ä¸ªå¼‚æ­¥DataProviderï¼Œæ–¹ä¾¿åŠæ—¶Human Evalï¼

trainer \= Trainer(
    model \= model,
    config \= config,
    loss\_fn \= GPTLMLoss(\-100),
    optimizer \= optimizer,
    train\_dataset \= train\_dataset,
    monitors \= monitors,
    evaluators \= \[evaluator\_ppl, evaluator\_decode\],
    \# æ·»åŠ 
    data\_provider \= GradioProvider(tokenizer)
)

### æ›´å¤šæˆåŠŸæ ·ä¾‹å’Œå®Œæ•´æ•™ç¨‹

CoLLiEæä¾›äº†å®Œæ•´çš„ æ•™ç¨‹ã€‚ æ›´å¤šçš„ç¤ºä¾‹ä¹Ÿå¯åœ¨ ç¤ºä¾‹ ä¸­æŸ¥çœ‹ã€‚

ç¤¾åŒº
--

è´¡çŒ®è€…
---

å¼•ç”¨æˆ‘ä»¬
----
