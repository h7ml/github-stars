---
project: openai-api-proxy
stars: 1627
description: ä¸€è¡ŒDockerå‘½ä»¤éƒ¨ç½²çš„ OpenAI/GPT APIä»£ç†ï¼Œæ”¯æŒSSEæµå¼è¿”å›ã€è…¾è®¯äº‘å‡½æ•° ã€‚Simple proxy for OpenAi api via a one-line docker command
url: https://github.com/easychen/openai-api-proxy
---

openai-api-proxy
================

å¯ä»¥éƒ¨ç½²åˆ°dockerå’Œäº‘å‡½æ•°çš„OpenAI APIä»£ç† Simple proxy for OpenAi api via a one-line docker command

ğŸŒ³ å¦‚æœä½ æ‡’å¾—è‡ªå·±æ­å»ºï¼Œé‚£ä¹ˆå¯ä»¥è¯•è¯•å›½å†…å¯ä»¥è®¿é—®ã€å¯ä»¥å¾®ä¿¡å……å€¼çš„ç¬¬ä¸‰æ–¹OpenAI APIæœåŠ¡ï¼šAPI2D.comï¼Œæ”¯æŒChaté…±ã€OpenCatã€NextWebã€VSCodeæ’ä»¶ã€‚

-   è…¾è®¯äº‘å‡½æ•°éƒ¨ç½²æ•™ç¨‹ ğŸ”¥ è…¾è®¯äº‘å‡½æ•°ä»4æœˆ25æ—¥èµ·å·²ç»å…¨åœ°åŸŸæ”¯æŒSSEï¼Œæ¨èä½¿ç”¨
-   ç®€ä½“ä¸­æ–‡ä½¿ç”¨è¯´æ˜
-   ã€Šå¦‚ä½•å¿«é€Ÿå¼€å‘ä¸€ä¸ªOpenAI/GPTåº”ç”¨ï¼šå›½å†…å¼€å‘è€…ç¬”è®°ã€‹

ğŸ‰ å·²ç»æ”¯æŒSSEï¼Œå¯ä»¥å®æ—¶è¿”å›å†…å®¹

ä»¥ä¸‹è‹±æ–‡ç”±GPTç¿»è¯‘ã€‚The following English was translated by GPT.

âš ï¸ This is the server-side of the proxy, not the client-side. It needs to be deployed to a network environment that can access the openai api.

Features
--------

1.  Supports SSE streaming output
2.  Built-in text moderation (requires Tencent Cloud KEY configuration)
3.  ğŸ’ª SSE streaming output supports text moderation, that's how powerful it is.

NodeJS Deployment
-----------------

You can deploy ./app.js to any environment that supports nodejs 14+, such as cloud functions and edge computing platforms.

1.  Copy app.js and package.json to the directory
2.  Install dependencies with yarn install
3.  Start the service with node app.js

Docker Deployment
-----------------

```
docker run -p 9000:9000 easychen/ai.level06.com:latest
```

The proxy address is http://${IP}:9000

### Available Environment Variables

1.  PORT: Service port
2.  PROXY\_KEY: Proxy access key, used to restrict access
3.  TIMEOUT: Request timeout, default 30 seconds
4.  TENCENT\_CLOUD\_SID: Tencent Cloud secret\_id
5.  TENCENT\_CLOUD\_SKEY: Tencent Cloud secret\_key
6.  TENCENT\_CLOUD\_AP: Tencent Cloud region (e.g. ap-singapore Singapore)

API Usage
---------

1.  Change the domain/IP (with port number) of the openai request address in the original project (e.g. https://api.openai.com) to the domain/IP of this proxy.
2.  If PROXY\_KEY is set, add `:<PROXY_KEY>` after the openai key. If not set, no modification is required.
3.  moderation: true enables moderation, false disables moderation
4.  moderation\_level: high interrupts all sentences whose moderation result is not Pass, low only interrupts sentences whose moderation result is Block.

Notes
-----

1.  Only supports GET and POST methods, not file-related interfaces.
2.  SSE is not currently supported, so stream-related options need to be turned off Now supported.

Client-side Usage Example
-------------------------

Using `https://www.npmjs.com/package/chatgpt` as an example:

chatApi\= new gpt.ChatGPTAPI({
    apiKey: 'sk.....:<proxy\_key\_here>',
    apiBaseUrl: "http://localhost:9001/v1", // Replace with proxy domain/IP
});
   

Acknowledgements
----------------

1.  SSE reference to chatgpt-api project related code
