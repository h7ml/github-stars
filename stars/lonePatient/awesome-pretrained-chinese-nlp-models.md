---
project: awesome-pretrained-chinese-nlp-models
stars: 5428
description: Awesome Pretrained Chinese NLP Modelsï¼Œé«˜è´¨é‡ä¸­æ–‡é¢„è®­ç»ƒæ¨¡å‹&å¤§æ¨¡å‹&å¤šæ¨¡æ€æ¨¡å‹&å¤§è¯­è¨€æ¨¡å‹é›†åˆ
url: https://github.com/lonePatient/awesome-pretrained-chinese-nlp-models
---

Awesome Pretrained Chinese NLP Models
=====================================

è®ºæ–‡: A Survey of Large Language Models

åœ¨è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸä¸­ï¼Œé¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼ˆPretrained Language Modelsï¼‰å·²æˆä¸ºéå¸¸é‡è¦çš„åŸºç¡€æŠ€æœ¯ï¼Œæœ¬ä»“åº“ä¸»è¦æ”¶é›†ç›®å‰ç½‘ä¸Šå…¬å¼€çš„ä¸€äº›é«˜è´¨é‡ä¸­æ–‡é¢„è®­ç»ƒæ¨¡å‹ã€ä¸­æ–‡å¤šæ¨¡æ€æ¨¡å‹ã€ä¸­æ–‡å¤§è¯­è¨€æ¨¡å‹ç­‰å†…å®¹(æ„Ÿè°¢åˆ†äº«èµ„æºçš„å¤§ä½¬)ï¼Œå¹¶å°†æŒç»­æ›´æ–°......

> å›½å†…ä¸‹è½½HuggingFaceä»“åº“æ¨¡å‹æ¨èä½¿ç”¨HuggingFaceé•œåƒåœ°å€: https://hf-mirror.com/

Expand Table of Contents
========================

-   æ›´æ–°æ—¥å¿—
    
-   é€šç”¨åŸºç¡€å¤§æ¨¡å‹
    
-   å‚ç›´åŸºç¡€å¤§æ¨¡å‹
    
-   é€šç”¨å¯¹è¯å¤§æ¨¡å‹
    
-   å‚ç›´å¯¹è¯å¤§æ¨¡å‹
    
-   å¤šæ¨¡æ€å¯¹è¯å¤§æ¨¡å‹
    
-   æ¨ç†ç±»å¤§æ¨¡å‹
    
-   å¤§æ¨¡å‹è¯„ä¼°åŸºå‡†
    
-   åœ¨çº¿ä½“éªŒå¤§æ¨¡å‹
    
-   å¼€æºæ¨¡å‹åº“å¹³å°
    
-   å¼€æºæ•°æ®é›†åº“
    
-   å¼€æºä¸­æ–‡æŒ‡ä»¤æ•°æ®é›†
    
-   Embedding
    
-   Other-Awesome
    
-   NLUç³»åˆ—
    
    -   BERT
    -   RoBERTa
    -   ALBERT
    -   NEZHA
    -   XLNET
    -   MacBERT
    -   WoBERT
    -   ELECTRA
    -   ZEN
    -   ERNIE
    -   ERNIE3
    -   RoFormer
    -   StructBERT
    -   Lattice-BERT
    -   Mengzi-BERT
    -   ChineseBERT
    -   TaCL
    -   MC-BERT
    -   äºŒéƒç¥
    -   PERT
    -   MobileBERT
    -   GAU-Î±
    -   DeBERTa
    -   GlyphBERT
    -   CKBERT
    -   LERT
    -   RoCBert
    -   m3e
    -   LEALLA
    

-   NLGç³»åˆ—
    
    -   GPT
    -   GPT-3
    -   NEZHA-GEN
    -   CPM-Generate
    -   T5
    -   T5-PEGASUS
    -   Mengzi-T5
    -   ç›˜å¤Î±
    -   EVA
    -   BART
    -   é—»ä»²
    -   ä½™å…ƒ
    -   RWKV
    -   Bloom
    -   PromptCLUE
    -   ChatYuan
    -   SkyText
    -   ProphetNet
    

-   NLU-NLGç³»åˆ—
    
    -   UniLM
    -   Simbert
    -   RoFormer-sim
    -   CPM-2
    -   CPT
    -   å‘¨æ–‡ç‹
    -   GLM
    -   PLUG
    -   OPD
    
-   Multi-Modal
    
    -   WenLan
    -   CogView
    -   ç´«ä¸œå¤ªåˆ
    -   Mengzi-oscar
    -   R2D2
    -   Chinese-CLIP
    -   TaiYi-CLIP
    -   AltCLIP
    -   AltDiffusion
    -   Taiyi-Stable-Diffusion
    -   wukong
    -   OFA
    -   QA-CLIP
    

-   Table
    
    -   SDCUP
    

`å¤‡æ³¨`

> ND: Non-Causal Decoder or Prefix LM

> CD: Causal Decoder

> ED: Encoder-Decoder

Base-LLM
--------

> å¤§è§„æ¨¡åŸºç¡€æ¨¡å‹ï¼šè¡¨æ ¼ä¸­åªç½—åˆ—å‡ºå‚æ•°é‡`å¤§äº7B`ä»¥ä¸Šæ¨¡å‹ã€‚

æ¨¡å‹

å¤§å°

æ—¶é—´

è¯­è¨€

é¢†åŸŸ

ä¸‹è½½

é¡¹ç›®åœ°å€

æœºæ„/ä¸ªäºº

æ¶æ„

æ–‡çŒ®

å¤‡æ³¨

XVERSE-MoE

255B/A36B

2024-09

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

XVERSE-MoE-A36B

xverse-ai

MoE

Qwen-2.5

0.5/1.5/3/7/14/32/72B

2024-09

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

Qwen2.5

QwenLM

CD

Blog

Tele-FLM

52B/102B/1TB

2024-07

å¤šè¯­

é€šç”¨

\[ğŸ¤—HF\]

/

CofeAI

CD

Tele-FLM Technical Report

meta-llama-3.1

8/70/405B

2024-07

å¤šè¯­

é€šç”¨

\[ğŸ¤—HF\]

llama3

meta-llama

CD

internlm2.5-Base

7B

2024-07

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

InternLM

InternLM

CD

ğŸ“œTechnical Report

MAP-NEO-Base

2/7B

2024-06

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

MAP-NEO

multimodal-art-projection

CD

Paper

Nemotron-4-Base

340B

2024-06

å¤šè¯­

é€šç”¨

ğŸ¤—HF

/

NVIDIA

CD

technical report.

Index-Base

1.9B

2024-06

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

Index-1.9B

bilibili

CD

Report

Qwen2-Base

0.5/2/5/7/72B

2024-06

å¤šè¯­

é€šç”¨

ğŸ¤—HF

Qwen2

QwenLM

CD

Blog

GLM-4-Base

9B

2024-06

å¤šè¯­

é€šç”¨

ğŸ¤—HF

GLM-4

THUDM

/

Yi-1.5-Base

6/9/34B

2024-05

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

Yi-1.5

01-ai

CD

Paper

DeepSeek-V2-Base

A21B/236B

2024-05

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

DeepSeek-V2

deepseek-ai

MOE

Paper

Llama-3-Base

8/70B

2024-04

å¤šè¯­

é€šç”¨

ğŸ¤—HF

**llama3**

Meta Llama

CD

Zhinao-Base

7B

2024-04

ä¸­è‹±

é€šç”¨

ğŸ¤—HF ğŸ¤–

/

å¥‡è™ç§‘æŠ€

CD

XVERSE-MoE

A4.2B/25.8B

2024-04

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

XVERSE-MoE-A4.2B

xverse-ai

MoE

SoftTiger-Base

13/70B

2024-04

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

TigerBot

TigerResearch

CD

HammerLLM

1.4b

2024-04

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

HammerLLM

DataHammer

Mengzi3-Base

13B

2024-04

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

Mengzi3

Langboat

CD

Breeze-Base

7B

2024-02

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

/

MediaTek Research

TowerBase

7/13B

2024-02

å¤šè¯­

é€šç”¨

\[ğŸ¤—HF\]

/

Unbabel

CD

Qwen1.5-Base

0.5/1.8/4  
7/14/32/72/110B

2024-02

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

Qwen1.5

Qwen

/

Blog

LongAlign-Base

6/7/13B

2024-02

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

LongAlign

THUDM

/

Paper

Chinese-Mixtral-Base

8x7B

2024-02

ä¸­è‹±

é€šç”¨

\[Baidu\] \[ğŸ¤—HF\]

Chinese-Mixtral

Yiming Cui

MOE

iFlytekSpark-Base

13B

2024-01

ä¸­è‹±

é€šç”¨

mindspore

/

ç§‘å¤§è®¯é£

CD

Orion-Base

14B

2024-01

å¤šè¯­

é€šç”¨

\[ğŸ¤—HF\]

Orion

OrionStarAI

CD

Paper

RAG  
Plugin

YaYi2-Base

30B

2023-12

å¤šè¯­

é€šç”¨

\[ğŸ¤—HF\]

YAYI2

wenge-research

CD

Paper

Aquila2-Base

7/34/70B

2023-12

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

Aquila2

FlagAI

CD

Alaya-Base

7B

2023-12

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

Alaya

DataCanvas

CD

Qwen-Base

1.8/7  
14/72B

2023-12

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

Qwen

é˜¿é‡Œäº‘

CD

Paper Report Report2

DeepSeek-Base

7/67B

2023-11

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

DeepSeek-LLM

deepseek-ai

CD

Yuan-2.0

2/51  
102B

2023-11

ä¸­è‹±

é€šç”¨

baidu \[ğŸ¤—HF\]

Yuan-2.0

IEIT-Yuan

CD

Alaya-Base

7B

2023-11

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

Alaya

DataCanvasIO

CD

Yi-Base

6/9/34B

2023-11

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

Yi

01.AI

CD

XVERSE-Base

7/13  
65B

2023-11

å¤šè¯­

é€šç”¨

\[ğŸ¤—HF\]

XVERSE

å…ƒè±¡ç§‘æŠ€

CD

Nanbeige-Base

16B

2023-11

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

Nanbeige

Nanbeige LLM Lab

CD

LingoWhale

8B

2023-11

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

LingoWhale-8B

DeepLang AI

CD

Skywork-base

13B

2023-10

ä¸­æ–‡

é€šç”¨

\[ğŸ¤—HF\]

Skywork

SkyworkAI

CD

Paper

BlueLM-Base

7B

2023-11

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

BlueLM

vivo AI Lab

CD

Chatglm3-base

6B

2023-10

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

ChatGLM3

THUDM

ND

Ziya2-Base

13B

2023-10

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

Fengshenbang-LM

IDEAç ”ç©¶é™¢

CD

OpenBA-LM

15B

2023-09

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

OpenBA

OpenNLG Group

ED

Paper

TigerBot-Base-70B

80B

2023-09

å¤šè¯­

é€šç”¨

\[ğŸ¤—HF\]

TigerBot

è™åšç§‘æŠ€

CD

Paper

FLM

101B

2023-09

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

/

CofeAI

CD

falcon

7/40  
180B

2023-09

å¤šè¯­

é€šç”¨

\[ğŸ¤—HF\]

/

Technology Innovation Institute

CD

Baichuan2

7/13B

2023-09

ä¸­æ–‡

é€šç”¨

\[ğŸ¤—HF\]

Baichuan2

ç™¾å·æ™ºèƒ½

CD

Chinese-LLaMA-2-16K

7/13B

2023-08

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

Chinese-LLaMA-Alpaca-2

Yiming Cui

CD

YuLan-LLaMA-2

13B

2023-08

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

YuLan-Chat

ä¸­å›½äººæ°‘å¤§å­¦

CD

Aquila-Base-33B

33B

2023-08

ä¸­è‹±

é€šç”¨

TODO

Aquila

FlagAI

CD

TigerBot-Base-13B

13B

2023-08

å¤šè¯­

é€šç”¨

\[ğŸ¤—HF\]

TigerBot

è™åšç§‘æŠ€

CD

Linly-Chinese-LLaMA-2

7/13B

2023-07

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

Linly

æ·±åœ³å¤§å­¦è®¡ç®—æœºè§†è§‰ç ”ç©¶æ‰€

CD

Chinese-LLaMA-2

7B

2023-07

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

Chinese-LLaMA-Alpaca-2

Yiming Cui

CD

Jiang-base

13B

2023-07

ä¸­æ–‡

é€šç”¨

\[ğŸ¤—HF\]

/

çŸ¥æœªæ™ºèƒ½

CD

bwx

7/13B

2023-07

ä¸­æ–‡

é€šç”¨

\[ğŸ¤—HF\]

/

è“é²¸å›½æ•°

CD

Llama2

7/13  
70B

2023-07

å¤šè¯­

é€šç”¨

\[ğŸ¤—HF\]

llama

Meta

CD

Paper

PolyLM

13B

2023-07

å¤šè¯­

é€šç”¨

\[ğŸ¤—HF\]

PolyLM

è¾¾æ‘©é™¢

CD

Paper

Baichuan-13B

13B

2023-07

ä¸­æ–‡

é€šç”¨

\[ğŸ¤—HF\]

Baichuan-13B

ç™¾å·æ™ºèƒ½

CD

TigerBot

7B

2023-07

å¤šè¯­

é€šç”¨

\[ğŸ¤—HF\]

TigerBot

è™åšç§‘æŠ€

CD

InternLM-base

7/20B

2023-07

ä¸­æ–‡

é€šç”¨

\[ğŸ¤—HF\]

InternLM

ä¸Šæµ·äººå·¥æ™ºèƒ½å®éªŒå®¤

CD

report

MPT

7/30B

2023-06

å¤šè¯­

é€šç”¨

\[ğŸ¤—HF\]

llm-foundry

MosaicML

CD

Baichuan

7B

2023-06

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

baichuan-7B

ç™¾å·æ™ºèƒ½

CD

Chinese-Falcon

7B

2023-06

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

Linly

æ·±åœ³å¤§å­¦è®¡ç®—æœºè§†è§‰ç ”ç©¶æ‰€

CD

Blog

AtomGPT

13B

2023-06

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

/

åŸå­å›å£°

CD

Aquila

7B

2023-06

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

Aquila

FlagAI

CD

Chinese-LLaMA

33B

2023-06

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

Chinese-LLaMA-Alpaca

Yiming Cui

CD

TigerBot

7B

2023-06

å¤šè¯­

é€šç”¨

\[ğŸ¤—HF\]

TigerBot

è™åšç§‘æŠ€

CD

Panda-OpenLLaMA

7B

2023-05

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

pandallm

dandelionsllm

CD

Panda

7/13B

2023-05

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

pandallm

dandelionsllm

CD

OpenLLaMA

13B

2023-05

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

Linly

æ·±åœ³å¤§å­¦è®¡ç®—æœºè§†è§‰ç ”ç©¶æ‰€

CD

BiLLa-LLM

7B

2023-05

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

BiLLa

Zhongli Li

CD

Ziya-LLaMA-Reward

7B

2023-05

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

Fengshenbang-LM

IDEAç ”ç©¶é™¢

CD

YuYan

11B

2023-04

ä¸­æ–‡

é€šç”¨

\[ğŸ¤—HF\]

/

ç½‘æ˜“ä¼ç¾²

CD

Paper

Chinese-LLaMA

7/13/33B

2023-04

ä¸­æ–‡

é€šç”¨

\[ğŸ¤—HF\]

Linly

æ·±åœ³å¤§å­¦è®¡ç®—æœºè§†è§‰ç ”ç©¶æ‰€

CD

Blog

OpenChineseLLaMA

7B

2023-04

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

OpenChineseLLaMA

OpenLMLab

CD

MOSS-003

16B

2023-04

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

MOSS

å¤æ—¦å¤§å­¦

CD

BBT-2-Text

13B

2023-04

ä¸­æ–‡

é€šç”¨

ç”³è¯·

BBT-FinCUGE-Applications

è¶…å¯¹ç§°

CD

Paper

BBT-2-Text

12B

2023-04

ä¸­æ–‡

é€šç”¨

ç”³è¯·

BBT-FinCUGE-Applications

è¶…å¯¹ç§°

CD

Paper

Chinese-LLaMA

13B

2023-04

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

Chinese-LLaMA-Alpaca

Yiming Cui

CD

flan-ul2

20B

2023-03

å¤šè¯­

é€šç”¨

\[ğŸ¤—HF\]

ul2

Google

ED

Paper

CPM-Bee

10B

2023-01

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

CPM-Bee

OpenBMB

CD

BLOOM

176B

2022-11

å¤šè¯­

é€šç”¨

\[ğŸ¤—HF\]

Megatron-DeepSpeed

BigScience

CD

Paper

_BLOOMZ_

176B

2022-11

å¤šè¯­

é€šç”¨

\[ğŸ¤—HF\]

Megatron-DeepSpeed

BigScience

CD

Paper

flan-t5-xxl

11B

2022-11

å¤šè¯­

é€šç”¨

\[ğŸ¤—HF\]

t5x

Google

ED

paper

CPM-Ant+

10B

2022-10

ä¸­è‹±

é€šç”¨

BMB

CPM-Live

OpenBMB

CD

blog

GLM

130B

2022-10

ä¸­è‹±

é€šç”¨

ç”³è¯·

GLM-130B

æ¸…åå¤§å­¦

ND

paper

CPM-Ant

10B

2022-09

ä¸­æ–‡

é€šç”¨

\[ğŸ¤—HF\]

CPM-Live

OpenBMB

CD

blog

GLM

10B

2022-09

ä¸­æ–‡

é€šç”¨

\[ğŸ¤—HF\]

GLM

æ¸…åå¤§å­¦

ND

paper

æº1.0

245B

2021-09

ä¸­æ–‡

é€šç”¨

API

Yian-1.0

æµªæ½®

CD

paper

CPM-2

10/11/  
200B

2021-06

ä¸­æ–‡

é€šç”¨

ç”³è¯·

CPM

æ™ºæºç ”ç©¶é™¢

ED

paper

PanGu-Alpha

13/200B

2021-05

ä¸­æ–‡

é€šç”¨

\[ğŸ¤—HF\]

PanGu-Alpha

é¹åŸå®éªŒå®¤

CD

paper

PLUG

27B

2021-04

ä¸­æ–‡

é€šç”¨

ç”³è¯·

AliceMind

é˜¿é‡Œå·´å·´

ED

GPT-3

13/30B

2021-04

ä¸­æ–‡

é€šç”¨

TODO

GPT-3

è¾¾æ‘©é™¢

CD

\[Back to Top\]

Domain-Base-LLM
---------------

> å„ä¸ªå‚ç›´é¢†åŸŸå¼€æºåŸºç¡€æ¨¡å‹

æ¨¡å‹

å¤§å°

æ—¶é—´

è¯­è¨€

é¢†åŸŸ

ä¸‹è½½

é¡¹ç›®åœ°å€

æœºæ„/ä¸ªäºº

æ¶æ„

æ–‡çŒ®

å¤‡æ³¨

Qwen-2.5

1.5/7B

2024-09

ä¸­è‹±

ä»£ç 

ğŸ¤—HF

Qwen2.5

QwenLM

CD

Blog

Qwen-2.5

1.5/7/72B

2024-09

ä¸­è‹±

æ•°å­¦

ğŸ¤—HF

Qwen2.5

QwenLM

CD

Blog

Tongyi-Finance-Base

14B

2023-11

ä¸­æ–‡

é‡‘è

ModelScope

é€šä¹‰é‡‘è-14B

é€šä¹‰é‡‘èå¤§æ¨¡å‹

CD

ChiMed-GPT

13B

2023-10

ä¸­æ–‡

åŒ»ç–—

\[ğŸ¤—HF\]

ChiMed-GPT

ä¸­å›½ç§‘å­¦æŠ€æœ¯å¤§å­¦

CD

Paper

CodeShell-base

7B

2023-10

ä¸­è‹±

ä»£ç 

\[ğŸ¤—HF\]

codeshell

WisdomShell

CD

WiNGPT-base

7B

2023-09

ä¸­æ–‡

åŒ»å­¦

\[ğŸ¤—HF\]

WiNGPT2

Winning Health AI Research

CD

XuanYuan

70B

2023-09

ä¸­æ–‡

é‡‘è

\[ğŸ¤—HF\]

XuanYuan

åº¦å°æ»¡

CD

Report

CodeLLAma

7/13/  
34B

2023-08

å¤šè¯­

ä»£ç 

\[ğŸ¤—HF\]

codellama

Meta Research

CD

Paper

educhat-base-002

7/13B

2023-06

ä¸­è‹±

æ•™è‚²

\[ğŸ¤—HF\]

EduChat

åä¸œå¸ˆèŒƒå¤§å­¦

CD

AquilaCode-NV

7B

2023-06

ä¸­è‹±

ä»£ç 

\[ğŸ¤—HF\]

Aquila

FlagAI

CD

AquilaCode-TS

7B

2023-06

ä¸­è‹±

ä»£ç 

\[ğŸ¤—HF\]

Aquila

FlagAI

CD

LaWGPT

7B

2023-05

ä¸­è‹±

æ³•å¾‹

\[ğŸ¤—HF\]

LawGPT

Pengxiao Song

CD

CodeGeeX

13B

2022-06

å¤šè¯­

ä»£ç 

ç”³è¯·

CodeGeeX

æ¸…åå¤§å­¦

CD

blog

\[Back to Top\]

ChatLLM
-------

> å…·å¤‡é—®ç­”å’Œå¯¹è¯ç­‰åŠŸèƒ½çš„å¤§å‹è¯­è¨€æ¨¡å‹ã€‚

æ¨¡å‹

å¤§å°

æ—¶é—´

è¯­è¨€

é¢†åŸŸ

ä¸‹è½½

é¡¹ç›®åœ°å€

æœºæ„/ä¸ªäºº

æ¶æ„

æ–‡çŒ®

GLM-4.6

A32/355B

2025-10

ä¸­è‹±

é€šç”¨

**Hugging Face**

GLM-4.5

zai-org

MoE

technical blog

**Ling-1T**

1T

2025-10

å¤šè¯­

é€šç”¨

**ğŸ¤— Huggingface**

/

inclusionAI

CD

**Qwen3-Next**

A3/80B

2025-09

ä¸­è‹±

é€šç”¨

**ğŸ¤— Huggingface**

Qwen3

QwenLM

MoE

Qwen3-Next

Kimi-k2

A32B/1T

2025-08

ä¸­è‹±

é€šç”¨

HF

Kimi-K2

MoonshotAI

MoE

**Paper**

ERNIE-4.5

A47/300B A3/21B

2025-07

ä¸­è‹±

é€šç”¨

**ğŸ¤— Huggingface**

/

BaiDu

MoE

Technical Report

Qwen-3

4/14/30/235B

2025-05

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

Qwen3

QwenLM

CD/MoE

blog

MiMo

7B

2025-05

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

MiMo

XiaomiMiMo

CD

Paper

GLM-4-0414

9/32B

2025-04

å¤šè¯­

é€šç”¨

ğŸ¤—HF

GLM-4

THUDM

**Moonlight**

A3/16B

2025-02

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

Moonlight

MoonshotAI

MoE

**Tech Report**

phi-4

14B

2025--01

å¤šè¯­

é€šç”¨

ğŸ¤—HF

/

Microsoft

CD

Phi-4 Technical Report

InternLM3

8B

2025--01

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

InternLM

InternLM

CD

Technical Report

deepseek-v3

671B

2024-12

å¤šè¯­

é€šç”¨

ğŸ¤—HF

DeepSeek-V3

deepseek-ai

MoE

**Paper Link**

Megrez-3B-Instruct

3B

2024-12

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

Infini-Megrez

infinigence

CD

Athene-V2-Chat

72B

2024-11

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

/

Nexusflow

CD

Blog

Athene-V2-Agent

72B

2024-11

ä¸­è‹±

å·¥å…·è°ƒç”¨

ğŸ¤—HF

/

Nexusflow

CD

Blog

Hunyuan-Large

A52/389B

2024-11

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

Tencent-Hunyuan-Large

Tencent

MoE

Paper

Aya-Expanse

8/32B

2024-10

å¤šè¯­

é€šç”¨

ğŸ¤—HF

/

Cohere For AI

CD

Granite 3.0

1/2/3/8B

2024-10

å¤šè¯­

é€šç”¨

ğŸ¤—HF

granite-3.0-language-models

ibm-granite

CD

Paper

Granite 3.0-MoE

1B/3B/A400M

2024-10

å¤šè¯­

é€šç”¨

ğŸ¤—HF

granite-3.0-language-models

ibm-granite

MoE

Paper

TeleChat2

115B

2024-09

ä¸­è‹±

é€šç”¨

ğŸ¤– ModelScope

TeleChat2

Tele-AI

CD

Qwen-2.5

0.5/1.5/3/7/14/32/72B

2024-09

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

Qwen2.5

QwenLM

CD

Blog

XVERSE-MoE

255B/A36B

2024-09

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

XVERSE-MoE-A36B

xverse-ai

MoE

DeepSeek-V2.5

236B/A21B

2024-09

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

DeepSeek-V2

deepseek-ai

MOE

Paper

MiniCPM3

4B

2024-09

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

MiniCPM

OpenBMB

CD

MiniCPM Paper

C4AI Command R+ 08-2024

104B

2024-08

å¤šè¯­

é€šç”¨

ğŸ¤—HF

/

CohereForAI

CD

JIUTIAN-Chat

39/A13B

2024-07

ä¸­è‹±

é€šç”¨

ğŸ¤–MS

/

ä¸­å›½ç§»åŠ¨JiuTian-AI

MOE

meta-llama-3.1

8/70/405B

2024-07

å¤šè¯­

é€šç”¨

\[ğŸ¤—HF\]

llama3

meta-llama

CD

internlm2.5-chat

7B

2024-07

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

InternLM

InternLM

CD

ğŸ“œTechnical Report

Mistral-large-insruct-2407

123B

2024-07

å¤šè¯­

é€šç”¨

ğŸ¤—HF

/

Mistral AI

blog post

DeepSeek-V2-Chat-0628

236B

2024-07

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

DeepSeek-V2

deepseek-ai

MOE

Paper

C4ai-command-r-plus

104B

2024-07

å¤šè¯­

é€šç”¨

ğŸ¤—HF

/

CohereForAI

CD

Gemma-2-chat

9/27B

2024-06

å¤šè¯­

é€šç”¨

ğŸ¤—HF

/

Google

CD

MAP-NEO-Chat

2/7B

2024-06

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

MAP-NEO

multimodal-art-projection

CD

Paper

GEB-Chat

1.3B

2024-06

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

/

GEB-AGI

CD

Paper

Nemotron-4-Chat

340B

2024-06

å¤šè¯­

é€šç”¨

ğŸ¤—HF

/

NVIDIA

CD

technical report.

Index-Chat

1.9B

2024-06

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

Index-1.9B

bilibili

CD

Report

Qwen2-MoE

57B/A14B

2024-06

å¤šè¯­

é€šç”¨

ğŸ¤—HF

Qwen2

QwenLM

MoE

Blog

Qwen2-Chat

0.5/2/5/7/72B

2024-06

å¤šè¯­

é€šç”¨

ğŸ¤—HF

Qwen2

QwenLM

CD

Blog

GLM-4-Chat

9B

2024-06

å¤šè¯­

é€šç”¨

ğŸ¤—HF

GLM-4

THUDM

/

Skywork-MoE

16/A22B/146B

2024-06

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

Skywork-MoE

SkyworkAI

MoE

Tech Report

Yuan2.0

40/A3.7B

2024-05

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

Yuan2.0-M32

IEIT-Yuan

MOE

Paper

æ˜Ÿè¾°-Chat

52B

2024-05

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

TeleChat-52B

Tele-AI

CD

LingLong

317M

2024-05

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

linglong

nkcs-iclab

CD

Sailor

14B

2024-05

7è¯­

é€šç”¨

ğŸ¤—HF

sailor-llm

sail-sg

CD

Paper

Nanbeige2

8/16B

2024-05

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

Nanbeige

Nanbeige

CD

Yi-1.5-Chat

6/9/34B

2024-05

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

Yi-1.5

01-ai

CD

Paper

DeepSeek-V2-Chat

A21B/236B

2024-05

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

DeepSeek-V2

deepseek-ai

MOE

Paper

XVERSE-MoE

A4.2B/25.8B

2024-05

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

XVERSE-MoE-A4.2B

xverse-ai

MOE

Llama3-zh

8/70B

2024-04

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

/

/

CD

llama3ä¸­æ–‡åˆ—è¡¨

Llama3-Chinese-Chat

8B

2024-04

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

/

Shenzhi Wang

CD

Llama-3-Chat

8/70B

2024-04

å¤šè¯­

é€šç”¨

ğŸ¤—HF

**llama3**

Meta Llama

CD

Zhinao-Chat

7B

2024-04

ä¸­è‹±

é€šç”¨

ğŸ¤—HF ğŸ¤–

/

å¥‡è™ç§‘æŠ€

CD

MiniCPM-MoE

8x2B

2024-04

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

MiniCPM

OpenBMB

MoE

Nanbeige2-Chat

8B

2024-04

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

Nanbeige

Nanbeige LLM Lab

CD

Sailor

7B

2024-04

å¤šè¯­

é€šç”¨

ğŸ¤—HF

sailor-llm

Sea AI Lab

CD

Paper

Mengzi3-Chat

13B

2024-04

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

Mengzi3

Langboat

CD

Qwen-MoE

2.7B

2024-03

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

Qwen1.5

Qwen

MoE

Blog

Command-R

35B

2024-03

å¤šè¯­

é€šç”¨

ğŸ¤—HF

/

CohereForAI

CD

Breeze-Instruct

7B

2024-02

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

/

MediaTek Research

aya-101

13B

2024-02

å¤šè¯­

é€šç”¨

ğŸ¤—HF

/

Cohere For AI

CD

Paper

ChemLLM

7B

2024-02

å¤šè¯­

é€šç”¨

ğŸ¤—HF

/

AI4Chem

CD

Paper

TowerInstruct

7/13B

2024-02

å¤šè¯­

é€šç”¨

\[ğŸ¤—HF\]

/

Unbabel

CD

Qwen1.5-Chat

0.5/1.8/4/  
7/14/32/72/110B

2024-02

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

Qwen1.5

Qwen

/

Blog

MiniCPM

2B

2024-02

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\] ModelScope

MiniCPM

OpenBMB

/

Report

**LongAlign-Chat**

6/7/13B

2024-02

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

LongAlign

THUDM

/

Paper

Chinese-Mixtral-Chat

8x7B

2024-02

ä¸­è‹±

é€šç”¨

\[Baidu\] \[ğŸ¤—HF\]

Chinese-Mixtral

Yiming Cui

MOE

iFlytekSpark-Chat

13B

2024-01

ä¸­è‹±

é€šç”¨

mindspore

/

ç§‘å¤§è®¯é£

CD

rwkv-5-world

0.1/1/  
3/7B

2023-01

å¤šè¯­

é€šç”¨

\[ğŸ¤—HF\]

RWKV-LM

BlinkDL

URL

Orion-Chat

14B

2024-01

å¤šè¯­

é€šç”¨

\[ğŸ¤—HF\]

Orion

OrionStarAI

CD

Paper

internlm2-chat

7/20B

2024-01

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

InternLM

InternLM

CD

Report

Chinese-Mixtral

8x7B

2023-01

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

/

HIT-SCIR

CD-MOE

Telechat

7/12B

2024-01

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

Telechatx

Tele-AI

CD

Report

kagentlms

7/13B

2024-01

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

KwaiAgents

KwaiKEG

YaYi2-Chat

30B

2023-12

å¤šè¯­

é€šç”¨

\[ğŸ¤—HF\]

YAYI2

wenge-research

CD

Paper

SUS-Chat

34/72B

2023-12

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

SUS-Chat

SUSTech-IDEA

CD

Aquila2-Chat

7/34/70B

2023-12

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

Aquila2

FlagAI

CD

Alaya-Chat

7B

2023-12

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

Alaya

DataCanvas

CD

Qwen-Chat

1.8/7/  
14/72B

2023-12

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

Qwen

é˜¿é‡Œäº‘

CD

Paper Report Report2

DeepSeek-Chat

7/67B

2023-11

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

DeepSeek-LLM

deepseek-ai

CD

Yi-Chat

6/34B

2023-11

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

Yi

01.AI

CD

Alaya-Chat

7B

2023-11

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

Alaya

DataCanvasIO

CD

OrionStar-Yi-Chat

34B

2023-11

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

OrionStar-Yi-34B-Chat

OrionStarAI

CD

Nanbeige-Chat

16B

2023-11

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

Nanbeige

Nanbeige LLM Lab

CD

OpenChat 3.5

7B

2023-11

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

openchat

OpenChat

CD

Paper

XVERSE-Chat

7/13B

2023-11

å¤šè¯­

é€šç”¨

\[ğŸ¤—HF\]

XVERSE

å…ƒè±¡ç§‘æŠ€

CD

AndesGPT

7B

2023-11

ä¸­æ–‡

é€šç”¨

\[ğŸ¤—HF\]

AndesGPT-7B

OPPO-Mente-Lab

CD

SeaLLM-Chat

13B

2023-11

å¤šè¯­

é€šç”¨

\[ğŸ¤—HF\]

SeaLLMs

SeaLLMs

CD

BlueLM

7B

2023-11

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

BlueLM

vivo AI Lab

CD

Skywork-chat

13B

2023-10

ä¸­æ–‡

é€šç”¨

\[ğŸ¤—HF\]

Skywork

SkyworkAI

CD

Paper

Zephyr

7B

2023-10

å¤šè¯­

é€šç”¨

\[ğŸ¤—HF\]

alignment-handbook

Hugging Face H4

CD

Paper

Mistral

7B

2023-10

å¤šè¯­

é€šç”¨

\[ğŸ¤—HF\]

mistral-src

Mistral AI

CD

Paper

chatglm3

6B

2023-10

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

ChatGLM3

THUDM

ND

Zhiyin-chat

7B

2023-10

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

Zhiyin

ä¸­ç§‘é™¢å£°å­¦æ‰€

CD

Ziya2-Chat

13B

2023-10

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

Fengshenbang-LM

IDEAç ”ç©¶é™¢

CD

Vulture

40/180B

2023-10

å¤šè¯­

é€šç”¨

\[ğŸ¤—HF\]

/

VILM-AI

TODO

Vulture

3/7/  
40/180B

2023-09

å¤šè¯­

é€šç”¨

\[ğŸ¤—HF\]

/

VILM

CD

Colossal-LLaMA-2

7B

2023-09

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

ColossalAI

HPC-AI Tech

CD

Blog

OpenBA-chat

15B

2023-09

ä¸­è‹±

é€šç”¨

TODO

OpenBA

OpenNLG Group

ED

Paper

WeMix-LLaMA2

7/70B

2023-09

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

WeMix-LLM

Alpha-VLLM

CD

Stable Beluga

7/13/70B

2023-09

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

/

Stability AI

CD

TigerBot-chat

70B

2023-09

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

TigerBot

è™åšç§‘æŠ€

CD

Paper

Openbuddy\_llama

70B

2023-09

å¤šè¯­

é€šç”¨

\[ğŸ¤—HF\]

OpenBuddy

OpenBuddy

CD

falcon-180B-chat

180B

2023-09

å¤šè¯­

é€šç”¨

\[ğŸ¤—HF\]

/

Technology Innovation Institute

CD

Baichuan2

7/13B

2023-09

ä¸­æ–‡

é€šç”¨

\[ğŸ¤—HF\]

Baichuan2

ç™¾å·æ™ºèƒ½

CD

Chinese-Alpaca-2-16K

7/13B

2023-09

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

Chinese-LLaMA-Alpaca-2

Yiming Cui

CD

InternLM-Chat-8k

7B

2023-08

ä¸­æ–‡

é€šç”¨

\[ğŸ¤—HF\]

InternLM

ä¸Šæµ·äººå·¥æ™ºèƒ½å®éªŒå®¤

CD

report

InternLM-Chat-v1.1

7B

2023-08

ä¸­æ–‡

é€šç”¨

\[ğŸ¤—HF\]

InternLM

ä¸Šæµ·äººå·¥æ™ºèƒ½å®éªŒå®¤

CD

report

YuLan-Chat-2

13B

2023-08

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

YuLan-Chat

ä¸­å›½äººæ°‘å¤§å­¦

CD

falcon

7/40B

2023-06

å¤šè¯­

é€šç”¨

\[ğŸ¤—HF\]

\[ğŸ¤—HF\]

Technology Innovation Institute

CD

Toucan

7B

2023-08

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

Toucan-LLM

Kendryte

CD

Zhuzhi

6B

2023-08

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

Zhuzhi-6B

ç«¹é—´æ™ºèƒ½

ND

Atom

7B

2023-08

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

Llama2-Chinese

FlagAlpha

CD

openbuddy

3/7/  
13/40B

2023-08

å¤šè¯­

é€šç”¨

\[ğŸ¤—HF\]

OpenBuddy

OpenBuddy

CD

Aquila-Chat-33B

33B

2023-08

ä¸­è‹±

é€šç”¨

TODO

Aquila

FlagAI

CD

vicuna-V1.5-16K

7/13B

2023-08

å¤šè¯­

é€šç”¨

\[ğŸ¤—HF\]

FastChat

lm-sys

CD

Paper

vicuna-V1.5

7/13B

2023-08

å¤šè¯­

é€šç”¨

\[ğŸ¤—HF\]

FastChat

lm-sys

CD

Paper

Chinese-Alpaca-2

13B

2023-08

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

Chinese-LLaMA-Alpaca-2

Yiming Cui

CD

WizardLM-V1.0

70B

2023-08

å¤šè¯­

é€šç”¨

\[ğŸ¤—HF\]

WizardLM

operatorx

CD

TigerBot-chat-13B

13B

2023-07

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

TigerBot

è™åšç§‘æŠ€

CD

huozi

7B

2023-08

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

huozi

å“ˆå·¥å¤§

CD

Chinese-Alpaca-2

7B

2023-07

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

Chinese-LLaMA-Alpaca-2

Yiming Cui

CD

AntX

7/13B

2023-07

ä¸­æ–‡

é€šç”¨

\[ğŸ¤—HF\]

/

AntX.ai

CD

BatGPT

15B

2023-07

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

BatGPT

ä¸Šæµ·äº¤é€šå¤§å­¦

ND

Paper

WizardLM-V1.2

13B

2023-07

å¤šè¯­

é€šç”¨

\[ğŸ¤—HF\]

WizardLM

operatorx

CD

Paper

llama2-Chinese-chat

13B

2023-07

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

llama2-Chinese-chat

Ke Bai

CD

Jiang-chat

13B

2023-07

ä¸­æ–‡

é€šç”¨

\[ğŸ¤—HF\]

/

çŸ¥æœªæ™ºèƒ½

CD

Llama2-chinese-chat

7/13B

2023-07

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

Llama2-Chinese

FlagAlpha

CD

LL7M

7B

2023-07

å¤šè¯­

é€šç”¨

\[ğŸ¤—HF\]

/

Joseph Cheung

CD

Chinese-Llama-2

7B

2023-07

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

Chinese-Llama-2-7b

LinkSoul-AI

CD

Llama2-chat

7/13/70B

2023-07

å¤šè¯­

é€šç”¨

\[ğŸ¤—HF\]

llama

Meta

CD

Paper

PolyLM-chat

13B

2023-07

å¤šè¯­

é€šç”¨

\[ğŸ¤—HF\]

PolyLM

è¾¾æ‘©é™¢

CD

Paper

Baichuan-13B-chat

13B

2023-07

ä¸­æ–‡

é€šç”¨

\[ğŸ¤—HF\]

Baichuan-13B

ç™¾å·æ™ºèƒ½

CD

vicuna-V1.3

7/13/33B

2023-07

å¤šè¯­

é€šç”¨

\[ğŸ¤—HF\]

FastChat

lm-sys

CD

Paper

WizardLM-V1.0

7/13/30B

2023-07

å¤šè¯­

é€šç”¨

\[ğŸ¤—HF\]

WizardLM

operatorx

CD

Paper

TigerBot-v2-sft

7B

2023-07

å¤šè¯­

é€šç”¨

\[ğŸ¤—HF\]

TigerBot

è™åšç§‘æŠ€

CD

InternLM-chat

7/20B

2023-07

ä¸­æ–‡

é€šç”¨

\[ğŸ¤—HF\]

InternLM

ä¸Šæµ·äººå·¥æ™ºèƒ½å®éªŒå®¤

CD

report

vicunaæ±‰åŒ–ç‰ˆ

33B

2023-07

ä¸­æ–‡

é€šç”¨

baidu-hiks

chinese-StableVicuna

ziwang-com

CD

CuteGPT

13B

2023-07

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

CuteGPT

å¤æ—¦å¤§å­¦çŸ¥è¯†å·¥åœº

CD

MPT-chat

7/30B

2023-06

å¤šè¯­

é€šç”¨

\[ğŸ¤—HF\]

llm-foundry

MosaicML

CD

ChatGLM2

6B

2023-06

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

ChatGLM2-6B

æ¸…åå¤§å­¦

ND

BayLing

7/13B

2023-06

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

BayLing

ä¸­å›½ç§‘å­¦é™¢

CD

ZhiXi-Diff

13B

2023-06

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

KnowLLM

æµ™æ±Ÿå¤§å­¦

CD

Anima

33B

2023-06

ä¸­æ–‡

é€šç”¨

\[ğŸ¤—HF\]

Anima

Gavin Li

CD

OpenLLaMA-Chinese

3/7/13B

2023-06

ä¸­æ–‡

é€šç”¨

\[ğŸ¤—HF\]

OpenLLaMA-Chinese

FittenTech

CD

openbuddy-falcon-7b-v1.5

7B

2023-06

å¤šè¯­

é€šç”¨

\[ğŸ¤—HF\]

OpenBuddy

OpenBuddy

CD

AtomGPT\_chat

13B

2023-06

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

AtomGPT

åŸå­å›å£°

CD

AquilaChat

7B

2023-06

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

Aquila

FlagAI

CD

YuLan-Chat

13/65B

2023-06

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

YuLan-Chat

ä¸­å›½äººæ°‘å¤§å­¦

CD

Chinese-Alpaca

33B

2023-06

ä¸­æ–‡

é€šç”¨

\[ğŸ¤—HF\]

Chinese-LLaMA-Alpaca

Yiming Cui

CD

TigerBot-sft

7/180B

2023-06

å¤šè¯­

é€šç”¨

\[ğŸ¤—HF\]

TigerBot

è™åšç§‘æŠ€

CD

ChatYuan

7B

2023-06

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

ChatYuan-7B

ClueAI

CD

Panda-Instruct

13B

2023-05

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

pandallm

dandelionsllm

CD

Panda-Instruct

7B

2023-05

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

pandallm

dandelionsllm

CD

BiLLa-SFT

7B

2023-05

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

BiLLa

Zhongli Li

CD

Ziya-LLaMA-v1

13B

2023-05

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

Fengshenbang-LM

IDEAç ”ç©¶é™¢

CD

Blog

BLOOMChat V1.0

176B

2023-05

å¤šè¯­

é€šç”¨

\[ğŸ¤—HF\]

bloomchat

SambaNova Systems

CD

Blog

BiLLa

7B

2023-05

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

BiLLa

Zhongli Li

CD

Bactrian-X

7/13B

2023-05

å¤šè¯­

é€šç”¨

\[ğŸ¤—HF\]

bactrian-x

MBZUAI

CD

Bactrian-ZH

7B

2023-05

ä¸­æ–‡

é€šç”¨

\[ğŸ¤—HF\]

bactrian-x

MBZUAI

CD

ChatFlow

7/13B

2023-05

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

Linly

æ·±åœ³å¤§å­¦è®¡ç®—æœºè§†è§‰ç ”ç©¶æ‰€

CD

OpenBuddy

7/13B

2023-05

å¤šè¯­

é€šç”¨

\[ğŸ¤—HF\]

OpenBuddy

OpenBuddy

CD

YuYan-dialogue

11B

2023-04

ä¸­æ–‡

é€šç”¨

\[ğŸ¤—HF\]

/

ç½‘æ˜“ä¼ç¾²

CD

paper

Moss-moon-003-sft-plugin

16B

2023-04

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

MOSS

å¤æ—¦å¤§å­¦

CD

moss-moon-003-sft

16B

2023-04

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

MOSS

å¤æ—¦å¤§å­¦

CD

RWKV-4-Raven

3/7/14B

2023-04

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

ChatRWKV

BlinkDL

RNN

Blog

Phoenix-inst-chat

7B

2023-04

ä¸­æ–‡

é€šç”¨

\[ğŸ¤—HF\]

LLMZoo

é¦™æ¸¯ä¸­æ–‡å¤§å­¦

CD

Phoenix-chat

7B

2023-04

ä¸­æ–‡

é€šç”¨

\[ğŸ¤—HF\]

LLMZoo

é¦™æ¸¯ä¸­æ–‡å¤§å­¦

CD

ChatPLUG

3.7B

2023-04

ä¸­æ–‡

é€šç”¨

\[ğŸ¤—HF\]

ChatPLUG

é˜¿é‡Œå·´å·´

ED

Paper

Chinese-Alpaca

13B

2023-04

ä¸­æ–‡

é€šç”¨

\[ğŸ¤—HF\]

Chinese-LLaMA-Alpaca

Yiming Cui

CD

BELLE-LLAMA

13B

2023-04

ä¸­æ–‡

é€šç”¨

\[ğŸ¤—HF\]

BELLE

è´å£³

CD

LLaMA-tuned

7/13/  
33/65B

2023-04

ä¸­æ–‡

é€šç”¨

\[ğŸ¤—HF\]

LMFlow

é¦™æ¸¯ç§‘æŠ€å¤§å­¦

CD

Chinese-Vicuna

7/13B

2023-03

ä¸­æ–‡

é€šç”¨

\[ğŸ¤—HF\]

Chinese-Vicuna

Facico

CD

ChatYuan-V2

0.7B

2023-03

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

ChatYuan

å…ƒè¯­æ™ºèƒ½

ED

Chinese-Alpaca

7B

2023-03

ä¸­æ–‡

é€šç”¨

\[ğŸ¤—HF\]

Chinese-LLaMA-Alpaca

Yiming Cui

CD

Luotuo

7B

2023-03

ä¸­æ–‡

é€šç”¨

\[ğŸ¤—HF\]

Chinese-alpaca-lora

åä¸­å¸ˆèŒƒå¤§å­¦

CD

BELLE-LLAMA

7B

2023-03

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

BELLE

è´å£³

CD

ChatGLM

6B

2023-03

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

ChatGLM-6B

æ¸…åå¤§å­¦

ND

\[Back to Top\]

Domain-ChatLLM
--------------

> å¼€æºçš„å‚ç›´é¢†åŸŸå¯¹è¯å¤§æ¨¡å‹

æ¨¡å‹

å¤§å°

æ—¶é—´

è¯­è¨€

é¢†åŸŸ

ä¸‹è½½

é¡¹ç›®åœ°å€

æœºæ„/ä¸ªäºº

æ¶æ„

æ–‡çŒ®

**KAT-Dev-72B-Exp**

72B

2025-10

å¤šè¯­

è½¯ä»¶å·¥ç¨‹

**ğŸ¤— Huggingface**

/

Kwaipilot

CD

KwaiCoder-23B-A4B-v1

A4/23B

2025-10

å¤šè¯­

è½¯ä»¶å·¥ç¨‹

**ğŸ¤— Huggingface**

/

Kwaipilot

CD

Qwen3-Coder

A3/30B

2025-08

ä¸­è‹±

ä»£ç 

**ğŸ¤— Huggingface**

Qwen3-Coder

QwenLM

MoE

Arxiv

Skywork-SWE

32B

2025-06

ä¸­è‹±

ä»£ç 

**ğŸ¤— Huggingface**

/

SkyworkAI

CD

Technical Report

Kimi-Dev

72B

2025-06

ä¸­è‹±

ä»£ç 

**ğŸ¤— Huggingface**

Kimi-Dev

MoonshotAI

CD

Qwen-coder-2.5

0.5/1.5/14/32B

2024-11

ä¸­è‹±

ä»£ç 

ğŸ¤—HF

Qwen2.5-Coder

QwenLM

CD

Paper

OpenCoder-Instruct

1.5/8B

2024-11

ä¸­è‹±

ä»£ç 

ğŸ¤—HF

OpenCoder-llm

OpenCoder-llm

CD

Paper

ç ç®—

2.7B

2024-09

ä¸­è‹±

ä»£ç 

ğŸ¤—HF

Abacus

HIT-SCIR

CD

Qwen-2.5-code

1.5/7B

2024-09

ä¸­è‹±

ä»£ç 

ğŸ¤—HF

Qwen2.5

QwenLM

CD

Blog

Qwen-2.5-math

1.5/7/72B

2024-09

ä¸­è‹±

æ•°å­¦

ğŸ¤—HF

Qwen2.5

QwenLM

CD

Blog

Yi-Coder

1.5/9B

2024-09

ä¸­è‹±

ä»£ç 

ğŸ¤— Hugging Face â€¢ ğŸ¤– ModelScope â€¢ ğŸŸ£ wisemodel

Yi-Coder

01-ai

CD

Paper Blog

CodeGeeX4

9B

2024-07

å¤šè¯­

ä»£ç 

ğŸ¤—HF

**CodeGeeX4**

THUDM

DeepSeek-Coder-V2

A16B/236B

2024-06

ä¸­è‹±

ä»£ç 

ğŸ¤—HF

DeepSeek-V2

deepseek-ai

MoE

Paper

AutoCoder

6.7/33B

2024-06

/

ä»£ç 

ğŸ¤—HF

AutoCoder

Bin Lei

CD

Paper

Codestral

22B

2024-05

/

ä»£ç 

ğŸ¤—HF

/

mistralai

/

Blog

CodeQwen1.5-Chat

7B

2024-04

ä¸­è‹±

ä»£ç 

ğŸ¤—HF

**Qwen1.5**

Qwen

CD

Blog

codegemma

2/7B

2024-04

å¤šè¯­

ä»£ç 

ğŸ¤—HF

/

Google

WaveCoder

6.7B

2024-04

å¤šè¯­

ä»£ç 

ğŸ¤—HF

WaveCoder

microsoft

Paper

ChemDFM

13B

2024-03

ä¸­è‹±

åŒ–å­¦

ğŸ¤—HF

/

OpenDFM

CD

Paper

starcoder2

3/7/15B

2024-02

ä¸­è‹±

ä»£ç 

ğŸ¤—HF

starcoder2

bigcode-project

CD

Paper

TuringMM-Chat

34B

2024-02

ä¸­è‹±

æ•™è‚²

ğŸ¤—HuggingFace ğŸ¤–ModelScope

/

å…‰å¹´æ— é™

CD

deepseek-moe

16B

2024-01

ä¸­è‹±

ä»£ç 

\[ğŸ¤—HF\]

DeepSeekMoE

DeepSeek

CD-MOE

Code Millenials

1/3/  
13/34B

2023-01

å¤šè¯­

ä»£ç 

\[ğŸ¤—HF\]

code-millenials

BudEcosystem

CD

WizardCoder

15/33B

2024-01

å¤šè¯­

ä»£ç 

\[ğŸ¤—HF\]

WizardLM

operatorx

CD

Paper

DeepSeek-Coder

1/7/33B

2023-11

ä¸­è‹±

ä»£ç 

\[ğŸ¤—HF\]

DeepSeek-Coder

deepseek-ai

Blog

Phind

34B

2023-10

å¤šè¯­

ä»£ç 

\[ğŸ¤—HF\]

/

Phind

CD

Blog zh

Tongyi-Finance-Chat

14B

2023-11

ä¸­æ–‡

é‡‘è

ModelScope

é€šä¹‰é‡‘è-14B-Chat

é€šä¹‰é‡‘èå¤§æ¨¡å‹

CD

Skywork-math

13B

2023-10

ä¸­æ–‡

æ•°å­¦

\[ğŸ¤—HF\]

Skywork

SkyworkAI

CD

Paper

XuanYuan-Chat

70B

2023-10

ä¸­è‹±

é‡‘è

\[ğŸ¤—HF\]

XuanYuan

Duxiaomanåº¦å°æ»¡

CD

zhilu

13B

2023-10

ä¸­è‹±

é‡‘è

\[ğŸ¤—HF\]

/

SYSU-MUCFC-FinTech-Research-Center

CD

TestGPT

7B

2023-10

ä¸­æ–‡

æµ‹è¯•

\[ğŸ¤—HF\]

Test-Agent

codefuse-ai

CD

cross

7/13B

2023-10

å¤šè¯­

æ•°å­¦

\[ğŸ¤—HF\]

/

Mathoctopus

CD

CodeFuse

13/14/  
15/34B

2023-10

ä¸­æ–‡

ä»£ç 

\[ğŸ¤—HF\]

MFTCoder

codefuse-ai

CD

Taiyi

7B

2023-10

ä¸­è‹±

åŒ»å­¦

\[ğŸ¤—HF\]

Taiyi-LLM

DUTIR-BioNLP

CD

CodeShell-chat

7B

2023-10

ä¸­è‹±

ä»£ç 

\[ğŸ¤—HF\]

codeshell

WisdomShell

CD

DISC-LawLLM

13B

2023-09

ä¸­æ–‡

æ³•å¾‹

\[ğŸ¤—HF\]

/

ShengbinYue

CD

Report

WiNGPT-chat

7B

2023-09

ä¸­æ–‡

åŒ»å­¦

\[ğŸ¤—HF\]

WiNGPT2

Winning Health AI Research

CD

ziya-coding

15/34B

2023-09

ä¸­è‹±

ä»£ç 

\[ğŸ¤—HF\]

Fengshenbang-LM

IDEAç ”ç©¶é™¢

CD

AgriGPT

6/13b

2023-09

ä¸­æ–‡

å†œä¸š

\[ğŸ¤—HF\]

AgriGPTs

AgriGPTs

XuanYuan-chat

70B

2023-09

ä¸­æ–‡

é‡‘è

TODO

XuanYuan

åº¦å°æ»¡

CD

Report

å¤«å­â€¢æ˜å¯Ÿ

6B

2023-09

ä¸­æ–‡

å¸æ³•

\[ğŸ¤—HF\]

fuzi.mingcha

å±±ä¸œå¤§å­¦

ND

ä»²æ™¯

13B

2023-09

ä¸­æ–‡

åŒ»å­¦

\[ğŸ¤—HF\]

Zhongjing

Songhua Yang

CD

Paper

CodeFuse

13/34B

2023-09

ä¸­è‹±

ä»£ç 

\[ğŸ¤—HF\]

MFTCoder

codefuse-ai

CD

EcomGPT

7B

2023-09

ä¸­è‹±

ç”µå•†

TODO

EcomGPT

Alibaba

DISC-MedLLM

13B

2023-08

ä¸­æ–‡

åŒ»ç–—

\[ğŸ¤—HF\]

DISC-MedLLM

FudanDISC

CD

Paper

K2

7B

2023-08

ä¸­è‹±

ç§‘å­¦

\[ğŸ¤—HF\]

k2

daven

CD

CodeLLAma

7/13/34B

2023-08

å¤šè¯­

ä»£ç 

\[ğŸ¤—HF\]

codellama

Meta Research

CD

Paper

sqlcoder

15B

2023-08

ä¸­è‹±

ä»£ç 

\[ğŸ¤—HF\]

sqlcoder

Defog.ai

CD

æ™ºæµ·-å½•é—®

7B

2023-08

ä¸­æ–‡

æ³•å¾‹

\[ğŸ¤—HF\]

wisdomInterrogatory

zhihaiLLM

CD

WizardMath-V1.0

7/13/70B

2023-08

å¤šè¯­

æ•°å­¦

\[ğŸ¤—HF\]

WizardLM

operatorx

CD

QiaoBan

7B

2023-08

ä¸­æ–‡

æƒ…æ„Ÿ

\[ğŸ¤—HF\]

QiaoBen

å“ˆå°”æ»¨å·¥ä¸šå¤§å­¦

HuangDi

13B

2023-08

ä¸­æ–‡

ä¸­åŒ»

\[ğŸ¤—HF\]

HuangDI

Zlasejd

CD

ZhongJing

2023-08

ä¸­æ–‡

ä¸­åŒ»

TODO

CMLM-ZhongJing

å¤æ—¦å¤§å­¦

TCMLLM

6B

2023-08

ä¸­æ–‡

ä¸­åŒ»

\[ğŸ¤—HF\]

TCMLLM

2020MEAI

ND

AutoAudit

7B

2023-07

ä¸­æ–‡

å®‰å…¨

\[ğŸ¤—HF\]

AutoAudit

Jiaying Li

CD

Lychee

10B

2023-07

ä¸­æ–‡

æ³•å¾‹

\[ğŸ¤—HF\]

lychee\_law

davidpig

ND

IvyGPT

6B

2023-07

ä¸­æ–‡

åŒ»å­¦

\[ğŸ¤—HF\]

IvyGPT

WangRongsheng

MING

7B

2023-07

ä¸­æ–‡

åŒ»å­¦

\[ğŸ¤—HF\]

MING

ä¸Šæµ·äº¤é€šå¤§å­¦

CD

Mozi

7B

2023-07

ä¸­è‹±

ç§‘æŠ€

\[ğŸ¤—HF\]

science-llm

GMFTBY

CD

StarGLM

6B

2023-07

ä¸­æ–‡

å¤©æ–‡

\[ğŸ¤—HF\]

StarGLM

LI YUYANG

ND

TransGPT

7B

2023-07

ä¸­è‹±

äº¤é€š

\[ğŸ¤—HF\]

TransGPT

åŒ—äº¬äº¤é€šå¤§å­¦

CD

CodeGeeX2

6B

2023-07

ä¸­è‹±

ä»£ç 

\[ğŸ¤—HF\]

CodeGeeX2

æ¸…åå¤§å­¦

ND

Yayi-llama2

7/13B

2023-07

ä¸­è‹±

èˆ†æƒ…

\[ğŸ¤—HF\]

Yayi

ä¸­ç§‘é—»æ­Œ

CD

Ziya-Writing

13B

2023-07

ä¸­è‹±

å†™ä½œ

\[ğŸ¤—HF\]

Fengshenbang-LM

IDEAç ”ç©¶é™¢

CD

MindChat

13B

2023-07

ä¸­æ–‡

å¿ƒç†

\[ğŸ¤—HF\]

MindChat

åä¸œç†å·¥å¤§å­¦

CD

ShenNong-TCM-LLM

7B

2023-07

ä¸­è‹±

åŒ»å­¦

\[ğŸ¤—HF\]

ShenNong-TCM-LLM

michael-wzhu

CD

ailawyer

13B

2023-07

ä¸­è‹±

æ³•å¾‹

\[ğŸ¤—HF\]

JurisLMs

openkg

CD

educhat

7B/13B

2023-06

ä¸­è‹±

æ•™è‚²

\[ğŸ¤—HF\]

EduChat

åä¸œå¸ˆèŒƒå¤§å­¦

CD

Sunsimiao

7B

2023-06

ä¸­è‹±

åŒ»å­¦

\[ğŸ¤—HF\]

Sunsimiao

åä¸œç†å·¥å¤§å­¦

CD

Media LLaMA

7B

2023-06

ä¸­æ–‡

åª’ä½“

baidu

Media-LLaMA

æ™ºåª’å¼€æºç ”ç©¶é™¢

CD

PULSE

7/14B

2023-06

ä¸­æ–‡

åŒ»å­¦

\[ğŸ¤—HF\]

PULSE

OpenMEDLab

CD

ChatLaw

13/33B

2023-06

ä¸­æ–‡

æ³•å¾‹

\[ğŸ¤—HF\]

ChatLaw

åŒ—äº¬å¤§å­¦

CD

BaoLuo

6B

2023-06

ä¸­æ–‡

æ³•å¾‹

\[ğŸ¤—HF\]

BaoLuo-LawAssisant

LeiZi

ND

CoLLaMA

7B

2023-06

ä¸­è‹±

ä»£ç 

\[ğŸ¤—HF\]

CoLLaMA

Denilah

CD

TechGPT

7B

2023-06

ä¸­è‹±

æ•™è‚²

\[ğŸ¤—HF\]

TechGPT

ä¸œåŒ—å¤§å­¦

CD

Yayi

7B

2023-06

ä¸­è‹±

èˆ†æƒ…

\[ğŸ¤—HF\]

Yayi

ä¸­ç§‘é—»æ­Œ

CD

MeChat

6B

2023-06

ä¸­æ–‡

åŒ»å­¦

\[ğŸ¤—HF\]

smile

qiuhuachuan

ND

ziya-medical

13b

2023-06

ä¸­è‹±

åŒ»å­¦

\[ğŸ¤—HF\]

MedicalGPT

Ming Xu

CD

Taoli

7B

2023-06

ä¸­è‹±

æ•™è‚²

å¾…å¼€æº

taoli

åŒ—äº¬è¯­è¨€å¤§å­¦

CD

Lawyer-llama

13B

2023-06

ä¸­è‹±

æ³•å¾‹

\[ğŸ¤—HF\]

lawyer-llama

Quzhe Huang

CD

QiZhen-CaMA

13B

2023-06

ä¸­è‹±

åŒ»å­¦

\[ğŸ¤—HF\]

QiZhenGPT

æµ™æ±Ÿå¤§å­¦

CD

æ‰é¹Š-2.0

6B

2023-06

ä¸­æ–‡

åŒ»å­¦

\[ğŸ¤—HF\]

BianQue

åå—ç†å·¥å¤§å­¦

ND

SoulChat

6B

2023-06

ä¸­æ–‡

å¿ƒç†

\[ğŸ¤—HF\]

SoulChat

åå—ç†å·¥å¤§å­¦

ND

HanFei

7B

2023-05

ä¸­æ–‡

æ³•å¾‹

baidu-d6t5

HanFei

ä¸­å›½ç§‘å­¦é™¢æ·±åœ³å…ˆè¿›é™¢

CD

QiZhen

6B

2023-05

ä¸­è‹±

åŒ»å­¦

\[baidu\]

QiZhenGPT

æµ™æ±Ÿå¤§å­¦

CD

ChatMed-Consult

7B

2023-05

ä¸­è‹±

åŒ»å­¦

\[ğŸ¤—HF\]

ChatMed

michael-wzhu

CD

LaWGPT-beta1.1

7B

2023-05

ä¸­è‹±

æ³•å¾‹

\[ğŸ¤—HF\]

LawGPT

Pengxiao Song

CD

Cornucopia

7B

2023-05

ä¸­è‹±

é‡‘è

\[ğŸ¤—HF\]

Cornucopia-LLaMA-Fin-Chinese

yuyangmu

CD

HuatuoGPT

7B

2023-05

ä¸­æ–‡

åŒ»å­¦

\[ğŸ¤—HF\]

HuatuoGPT

é¦™æ¸¯ä¸­æ–‡å¤§å­¦

CD

Paper

LexiLaw

6B

2023-05

ä¸­æ–‡

æ³•å¾‹

\[ğŸ¤—HF\]

LexiLaw

Haitao Li

ND

Paper

XuanYuan

176B

2023-05

ä¸­æ–‡

é‡‘è

ç”³è¯·

XuanYuan

åº¦å°æ»¡

CD

Paper

LawGPT

6B

2023-05

ä¸­æ–‡

æ³•å¾‹

\[ğŸ¤—HF\]

LAW-GPT

hongchengliu

N

æ‰é¹Š-1.0

0.7B

2023-04

ä¸­æ–‡

åŒ»å­¦

\[ğŸ¤—HF\]

BianQue

scutcyr

ED

ChatGLM-Med

6B

2023-04

ä¸­æ–‡

åŒ»å­¦

\[ğŸ¤—HF\]

Med-ChatGLM

å“ˆå°”æ»¨å·¥ä¸šå¤§å­¦

ED

BenTsao

7B

2023-04

ä¸­æ–‡

åŒ»å­¦

\[ğŸ¤—HF\]

Huatuo-Llama-Med-Chinese

å“ˆå°”æ»¨å·¥ä¸šå¤§å­¦

CD

DoctorGLM

6B

2023-04

ä¸­æ–‡

åŒ»å­¦

TODO

DoctorGLM

xionghonglin

ND

Firefly

1/2/7B

2023-04

ä¸­æ–‡

æ–‡åŒ–

\[ğŸ¤—HF\]

Firefly

Yang JianXin

CD

ChatRWKV

7B

2023-01

ä¸­è‹±

å°è¯´

\[ğŸ¤—HF\]

ChatRWKV

BlinkDL

RNN

Blog

\[Back to Top\]

MultiModal-ChatLLM
------------------

> æ”¶é›†åŒ…å«ä¸­æ–‡çš„å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼Œå…·å¤‡å¯¹è¯ç­‰åŠŸèƒ½ã€‚

æ¨¡å‹

å¤§å°

æ—¶é—´

è¯­è¨€æ¨¡å‹

éè¯­è¨€æ¨¡å‹

è¯­è¨€

é¢†åŸŸ

ä¸‹è½½

é¡¹ç›®åœ°å€

æœºæ„/ä¸ªäºº

æ–‡çŒ®

DeepSeek-OCR

3B

2025-10

/

/

ä¸­è‹±

æ–‡å›¾

ğŸ¤— HF

DeepSeek-OCR

deepseek-ai

**Paper Link**

VoxCPM

0.5B

2025-09

MiniCPM-4

/

ä¸­è‹±

æ–‡éŸ³

ğŸ¤— HF

VoxCPM

OpenBMB

/

VibeVoice

1.5B

2025-09

Qwen2.5-1.5B

/

ä¸­è‹±

æ–‡éŸ³

ğŸ¤— HF

VibeVoice

microsoft

VibeVoice Technical Report

HunyuanImage

17B

2025-09

/

/

ä¸­è‹±

æ–‡å›¾

ğŸ¤— HF

HunyuanImage-2.1

Tencent-Hunyuan

/

PromptEnhancerV2

32B

2025-09

/

/

ä¸­è‹±

æ–‡å›¾

ğŸ¤— HF

PromptEnhancer

Hunyuan-PromptEnhancer

report paper

**Qwen-Image**

20B

2025-08

/

/

ä¸­è‹±

æ–‡å›¾

ğŸ¤— HF

Qwen-Image

QwenLM

Tech Report

ERNIE-4.5-VL

A47/424B

2025-07

/

/

ä¸­è‹±

æ–‡å›¾

ğŸ¤— HF

/

BaiDu

**ğŸ“„ Tech Report**

Dolphin

A3/16B

2025-05

MBart

Swin Transformer

ä¸­è‹±

æ–‡å›¾

ğŸ¤— HF

Dolphin

bytedance

arXiv.

Wan2.1-VACE

14B

2025-05

/

/

ä¸­è‹±

æ–‡å›¾è§†

ğŸ¤— HF

Wan2.1

Wan-Video

arXiv

Kimi-VL

A3/16B

2025-04

/

/

å¤šè¯­

æ–‡å›¾

ğŸ¤— HF

Kimi-VL

MoonshotAI

**Tech Report**

Aya Vision

8/32B

2025-03

C4AI Command R7B

SigLIP2-patch14-384

å¤šè¯­

æ–‡å›¾

ğŸ¤— HF

/

Cohere For AI

Phi-4-multimodal-instruct

5.6B

2025-03

/

/

å¤šè¯­

æ–‡å›¾

ğŸ¤— HF

/

Microsoft

Phi-4-multimodal Technical Report

CogView4

6B

2025-03

GLM-4-9B

/

ä¸­è‹±

æ–‡å›¾

ğŸ¤— HF

CogView4

THUDM

arxiv

Wan2.1

1.3/14B

2025-02

/

/

ä¸­è‹±

æ–‡è§†å›¾

ğŸ¤— HF

Wan2.1

Wan-Video

/

Step-Audio-Chat

130B

2025-02

Step-1

/

å¤šè¯­

æ–‡éŸ³

ğŸ¤— HF

Step-Audio

stepfun-ai

Paper

Ovis2

1/4/16/34B

2025-02

Qwen2.5

aimv2-large

ä¸­è‹±

æ–‡å›¾è§†

ğŸ¤— HF

Ovis

AIDC-AI

Paper

Janus-Pro

1.5/7B

2025-02

deepseek-llm

SigLIP-L

ä¸­è‹±

æ–‡å›¾

ğŸ¤— HF

Janus

deepseek-ai

paper

OuteTTS

2025-01

Qwen2.5-0.5B

OLMo-1B

å¤šè¯­

æ–‡éŸ³

ğŸ¤— HF

OuteTTS

edwko

Blog

MiniCPM-o

8B

2025-01

Qwen2.5-7B

SigLip-400Mã€Whisper-medium-300M, ChatTTS-200M

ä¸­è‹±

æ–‡éŸ³å›¾

ğŸ¤— HF

MiniCPM-o

OpenBMB

Sa2VA

1/4/8B

2024-12

Qwen2.5

InternVL2.5

ä¸­è‹±

æ–‡è§†å›¾

ğŸ¤— HF

Sa2VA

magic-research/ Sa2VA

Paper

QVQ-72B-Preview

72B

2024-12

/

/

ä¸­è‹±

æ–‡è§†å›¾

ğŸ¤— HF

Qwen2-VL

QwenLM

Blog

Megrez-3B-Omni

3B

2024-12

Megrez-3B-Instruct

SigLip-400M/Qwen2-Audio/whisper-large-v3

ä¸­è‹±

æ–‡éŸ³å›¾

ğŸ¤— HF

Infini-Megrez-Omni

infinigence

DeepSeek-VL2

1/2.8/4.5B

2024-12

/

/

æ–‡å›¾

ğŸ¤— HF

DeepSeek-VL2

deepseek-ai

Paper

InternVL 2.5

2/4/8/26/38/78B

2024-12

Qwen-2.5

InternVit

å¤šè¯­

æ–‡å›¾

ğŸ¤— HF

InternVL

OpenGVLab

blog

Pixtral-Large-Instruct

124B

2024-11

Mistral-Large-Instruct-2407

/

å¤šè¯­

æ–‡å›¾

ğŸ¤— Huggingface

/

mistralai

Pixtral Large blog post

fish-agent

3B

2024-11

Qwen-2.5

/

å¤šè¯­

æ–‡éŸ³

ğŸ¤— Huggingface

fish-speech

fishaudio

GLM-4-Voice

9B

2024-10

GLM-4-9B

Whisper

ä¸­è‹±

æ–‡éŸ³

ğŸ¤— Huggingface

GLM-4-Voice

THUDM

Pangea

7B

2024-10

Qwen2-7B-Instruct

LLaVA-NeXT

å¤šè¯­

å›¾æ–‡

ğŸ¤—HF

Pangea

neulab

Paper

GOT-OCR-2.0

/

2024-09

Qwen

/

ä¸­è‹±

å›¾æ–‡

ğŸ¤—HF

GOT-OCR2.0

**StepFun-AI**

Paper

Ovis-1.6

9B

2024-09

Gemma2-9B-It

Siglip-400M

ä¸­è‹±

å›¾æ–‡

ğŸ¤—

Ovis

AIDC-AI

Paper

Qwen2-VL

2/7/72B

2024-08

/

/

å¤šè¯­

å›¾æ–‡è§†

ğŸ¤— ğŸ¤–

Qwen2-VL

QwenLM

CogVideoX

2/5B

2024-08

/

/

ä¸­è‹±

æ–‡è§†

ğŸ¤— link

CogVideo

THUDM

MiniCPM-V 2.6

8B

2024-08

Qwen2-7B

SigLip-400M

ä¸­è‹±

æ–‡å›¾è§†

ğŸ¤— link

MiniCPM-V

OpenBMB

InternVL2

1/2/4/8/26/40/76B

2024-07

Qwen2/internlm2/llama3

InternViT

ä¸­è‹±

æ–‡å›¾

ğŸ¤— link ğŸ¤– link

InternVL

OpenGVLab

report

Qwen2-Audio

8.2B

2024-07

Qwen2

Whisper-large-V3

ä¸­è‹±

æ–‡éŸ³

ğŸ¤—HF

Qwen2-Audio

QwenLM

report

**Kolors**

/

2024-07

ChatGLM3-Base

/

ä¸­è‹±

æ–‡å›¾

ğŸ¤—HF

Kolors

Kwai-Kolors

Paper

ChatTTS

/

2024-06

/

/

ä¸­è‹±

æ–‡éŸ³

ğŸ¤—HF

ChatTTS

2noise

/

GLM-4V

9B

2024-06

GLM-4

/

å¤šè¯­

æ–‡å›¾

ğŸ¤—HF

GLM-4

THUDM

/

HunyuanDiT

1.5B

2024-05

multilingual T5 encoder

CLIP

ä¸­è‹±

æ–‡å›¾

ğŸ¤—

**HunyuanDiT**

Tencent

Paper

**CogVLM2**

2024-05

Meta-Llama-3-8B-Instruct

/

ä¸­è‹±

æ–‡å›¾

ğŸ¤—

CogVLM

Skip to content

360VL

8/70B

2024-05

LLama3

CLIP-ViT

ä¸­è‹±

æ–‡å›¾

ğŸ¤—

360VL

360CVGroup

**XVERSE-V**

13B

2024-05

**XVERSE-13B-Chat**

**clip-vit-large-patch14-224**

ä¸­è‹±

æ–‡å›¾

ğŸ¤–

XVERSE-V-13B

xverse-ai

MiniCPM-V 2.0

2.8B

2024-04

MiniCPM-2.4B

SigLip-400M

ä¸­è‹±

æ–‡å›¾

ğŸ¤— ğŸ¤–

**MiniCPM-V**

OpenBMB

Blog

**Qwen-Audio**

7B

2024-03

Qwen-7B

Whisper-large-v2

ä¸­è‹±

æ–‡éŸ³

ğŸ¤—HF

Qwen-Audio

Qwen

Paper

DeepSeek-VL

1.3/7B

2024-03

DeepSeek

SigLip/SAM

ä¸­è‹±

å›¾æ–‡

ğŸ¤—HF

DeepSeek-VL

deepseek-ai

Paper

**OmniLMM**

3/12B

2024-02

MiniCPM

SigLip

ä¸­è‹±

å›¾æ–‡

ğŸ¤—HF

OmniLMM

\[OpenBMB\](https://github.com/01-ai)

**MiniCPM-V**

3B

2024-02

MiniCPM-2.4B

SigLip-400M

ä¸­è‹±

å›¾æ–‡

ğŸ¤—HF

OmniLMM

\[OpenBMB\](https://github.com/01-ai)

Yi-VL

6/34B

2024-01

Yi

CLIP-VIT

ä¸­è‹±

å›¾æ–‡

\[ğŸ¤—HF\]

Yi

01-ai

Lyrics

14B

2023-12

/

/

ä¸­è‹±

å›¾æ–‡

\[ğŸ¤—HF\]

Fengshenbang-LM

IDEAç ”ç©¶é™¢

Qwen-Audio

7B

2023-12

Qwen-7B

Whisper-large-v2

ä¸­è‹±

æ–‡éŸ³

\[ğŸ¤—HF\]

Qwen-Audio

Qwen

Paper

SPHINX

13B

2023-10

/

/

ä¸­è‹±

å›¾æ–‡

\[ğŸ¤—HF\]

LLaMA2-Accessory

Alpha-VLLM

Skywork-MM

13B

2023-10

/

/

ä¸­è‹±

å›¾æ–‡

\[ğŸ¤—HF\]

Skywork

SkyworkAI

Paper

CogVLM

7/14B

2023-10

Qwen

ViT

ä¸­è‹±

å›¾æ–‡

\[ğŸ¤—HF\]

/

CausalLM

fuyu

8B

2023-10

/

/

ä¸­è‹±

å›¾æ–‡

\[ğŸ¤—HF\]

/

Adept AI Labs

Blog

Ziya-Visual

14B

2023-10

LLaMA

InstructBLIP

ä¸­è‹±

å›¾æ–‡

\[ğŸ¤—HF\]

Fengshenbang-LM

IDEAç ”ç©¶é™¢

Paper

CogVLM

17B

2023-10

EVA2-CLIP-E

Vicuna-v1.5

ä¸­è‹±

å›¾æ–‡

TODO

CogVLM

THUDM

Paper

idefics

9/80B

2023-10

LLaMA

CLIP-ViT

ä¸­è‹±

å›¾æ–‡

\[ğŸ¤—HF\]

/

HuggingFaceM4

log

InternLM-XComposer

7B

2023-10

InternLM

EVA-CLIP

ä¸­è‹±

å›¾æ–‡

\[ğŸ¤—HF\]

InternLM-XComposer

InternLM

Report

WeMix-LLM

13B

2023-09

LLama2

/

ä¸­è‹±

å›¾æ–‡

\[ğŸ¤—HF\]

WeMix-LLM

Alpha-VLLM

Vally

7/13B

2023-08

BelleGroup/BELLE-LLaMA-EXT

OFA-Sys/chinese-clip-vit-large-patch14

ä¸­è‹±

å›¾æ–‡

\[ğŸ¤—HF\] \[ğŸ¤—HF\]

Valley

ç½—ç‘ç’

Paper

SALMONN

/

2023-08

/

/

ä¸­è‹±

è¯­éŸ³

TODO

SALMONN

Bytedance

IDEFICS

9/80B

2023-08

llama

CLIP-ViT

ä¸­è‹±

å›¾æ–‡-é€šç”¨

\[ğŸ¤—HF\]

m4-logs

HuggingFaceM4

Paper

Qwen-VL

7B

2023-08

Qwen-7B

Openclip ViT-bigG

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

Qwen-VL

é˜¿é‡Œäº‘

Qwen-VL-chat

7B

2023-08

Qwen-7B

Openclip ViT-bigG

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

Qwen-VL

é˜¿é‡Œäº‘

LLasM

7B

2023-07

Chinese-Llama2

whisper-large-v2

ä¸­è‹±

è¯­éŸ³

\[ğŸ¤—HF\]

LLaSM

åŒ—äº¬çµç

Chinese-LLaVA

7B

2023-07

Chinese-Llama2

Clip-vit

ä¸­è‹±

è§†è§‰

\[ğŸ¤—HF\]

Chinese-LLaVA

åŒ—äº¬çµç

RemoteGLM

6B

2023-07

VisualGLM-6B

VisualGLM-6B

ä¸­æ–‡

é¥æ„Ÿ

TODO

RemoteGLM

lzw-lzw

VisualCLA

7B

2023-07

Chinese-Alpaca-Plus

CLIP-ViT-L/14

ä¸­æ–‡

è§†è§‰

\[ğŸ¤—HF\]

Visual-Chinese-LLaMA-Alpaca

Ziqing Yang

yuren

7B

2023-07

baichuan-7B

CLIP

ä¸­è‹±

è§†è§‰

\[ğŸ¤—HF\]

yuren-baichuan-7b

Pleisto

VisCPM-Chat

10B

2023-06

CPM-Bee

Q-Former

ä¸­è‹±

è§†è§‰

\[ğŸ¤—HF\]

VisCPM

OpenBMB

VisCPM-Paint

10B

2023-06

CPM-Bee

Stable Diffusion 2.1

ä¸­è‹±

è§†è§‰

\[ğŸ¤—HF\]

VisCPM

OpenBMB

XrayPULSE

7B

2023-06

PULSE

MedCLIP

ä¸­æ–‡

åŒ»å­¦

\[ğŸ¤—HF\]

XrayPULSE

OpenMEDLab

SEEChat

6B

2023-06

ChatGLM

CLIP-ViT

ä¸­æ–‡

/

\[ğŸ¤—HF\]

SEEChat

360

Ziya-BLIP2-14B-Visual-v1

14B

2023-06

LLaMA-13B

BLIP2

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

Fengshenbang-LM

IDEAç ”ç©¶é™¢

Video-LLaMA-BiLLA

7B

2023-05

BiLLa-7B

MiniGPT-4

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

Video-LLaMA

è¾¾æ‘©é™¢å¤šè¯­è¨€NLP

Paper

Video-LLaMA-Ziya

13B

2023-05

Ziya-13B

MiniGPT-4

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

Video-LLaMA

è¾¾æ‘©é™¢å¤šè¯­è¨€NLP

Paper

XrayGLM

6B

2023-05

ChatGLM-6B

BLIP2-Qformer

ä¸­è‹±

åŒ»å­¦

\[ğŸ¤—HF\]

XrayGLM

æ¾³é—¨ç†å·¥å¤§å­¦

X-LLM

2023-05

ChatGLM

ViT-g

ä¸­æ–‡

/

TODO

X-LLM

ä¸­ç§‘é™¢è‡ªåŠ¨åŒ–æ‰€

Paper

VisualGLM

6B

2023-05

ChatGLM-6B

BLIP2-Qformer

ä¸­è‹±

è§†è§‰

\[ğŸ¤—HF\]

VisualGLM-6B

æ¸…åå¤§å­¦

\[Back to Top\]

ReasoningLLM
------------

> æ”¶é›†æ¨ç†èƒ½åŠ›æ¯”è¾ƒçªå‡ºçš„ä¸­æ–‡å¤§æ¨¡å‹

æ¨¡å‹

å¤§å°

æ—¶é—´

è¯­è¨€

é¢†åŸŸ

ä¸‹è½½

é¡¹ç›®åœ°å€

æœºæ„/ä¸ªäºº

ç»“æ„

æ–‡

**Tongyi DeepResearch**

A3/30B

2025-09

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

DeepResearch

Alibaba-NLP  

MoE

Tech Blog

**Qwen3-Next**

A3/80B

2025-09

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

Qwen3

QwenLM

MoE

Qwen3-Next

Magistral Small 1.2

24B

2025-09

å¤šè¯­

é€šç”¨

**Hugging Face**

/

mistralai

CD

blog post

gpt-oss-20B

A2/20B

2025-08

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

gpt-oss

openai

MoE

**OpenAI blog**

gpt-oss-120B

A5/120B

2025-08

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

gpt-oss

openai

MoE

**OpenAI blog**

Baichuan-M2

32B

2025-08

ä¸­è‹±

åŒ»ç–—

**Hugging Face**

Baichuan-M2-32B

baichuan-inc

CD

technical blog

**Ovis2.5**

2/9B

2025-08

ä¸­è‹±

å¤šæ¨¡æ€

ğŸ¤—HF

Ovis

AIDC-AI

CD

Paper

GLM-4.5V

108B

2025-07

ä¸­è‹±

å¤šæ¨¡æ€

**Hugging Face**

GLM-V

zai-org

MoE

Paper

GLM-4.5

A32/355B

2025-07

ä¸­è‹±

é€šç”¨

**Hugging Face**

GLM-4.5

zai-org

MoE

technical blog

GLM-4.5-Air

106B-A12B

2025-07

ä¸­è‹±

é€šç”¨

**Hugging Face**

GLM-4.5

zai-org

MoE

technical blog

Hunyuan

0.5/4/7B

2025-07

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

Tencent-Hunyuan

Tencent-Hunyuan

/

/

Qwen3-Thinking-2507

A3/30B

2025-07

ä¸­è‹±

é€šç”¨

**ğŸ¤— Huggingface**

Qwen3

QwenLM

MoE

Paper

Step3

A38/321B

2025-07

ä¸­è‹±

å¤šæ¨¡æ€

HF

Step3

stepfun-ai

MoE

Paper

Dhanishtha-2.0

14B

2025-07

å¤šè¯­

é€šç”¨

**Hugging Face**

/

HelpingAI

CD

/

GLM-4.1V-Thinking

9B

2025-07

ä¸­è‹±

å¤šæ¨¡æ€

ğŸ¤—HF

GLM-4.1V-Thinking

THUDM

/

paper

Kimi-VL-Thinking-2506

A3B

2025-06

ä¸­è‹±

å¤šæ¨¡æ€

ğŸ¤—HF

Kimi-VL

MoonshotAI

/

**ğŸ“„ Tech Report**

Hunyuan-A13B

A13/80B

2025-06

ä¸­è‹±

é€šç”¨

**Hugging Face**

Hunyuan-A13B

Tencent-Hunyuan

MoE

**Technical Report**

LongWriter-Zero

32B

2025-06

ä¸­è‹±

/

ğŸ¤—HF

/

THU-KEG

/

Paper

MiniMax-M1

A46/456B

2025-06

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

MiniMax-M1

MiniMax-AI

MoE

Paper

DeepSeek-R1-0528

A37/671B

2025-05

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

DeepSeek-R1

deepseek-ai

MoE

**Paper Link**ğŸ‘ï¸

QwenLong-L1

32B

2025-05

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

QwenLong-L1

Tongyi-Zhiwen

CD

Paper

GLM-Z1-0414

32B

2025-04

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

GLM-4

THUDM

DeepCoder

1.5/14B

2025-04

ä¸­è‹±

ä»£ç 

ğŸ¤—HF

rllm

agentica-project

CD

Kimi-VL-Thinking

A3/16B

2025-04

ä¸­è‹±

å¤šæ¨¡æ€

ğŸ¤—HF

Kimi-VL

MoonshotAI

MoE

**Tech Report**

Skywork-OR1

7/32B

2025-04

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

Skywork-OR1

SkyworkAI/

MoE

Notion Blog

Skywork-R1V

38B

2025-03

ä¸­è‹±

å¤šæ¨¡æ€

ğŸ¤—HF

Skywork-R1V

SkyworkAI

CD

Paper

Fin-R1

7B

2025-03

ä¸­è‹±

é‡‘è

ğŸ¤—HF

Fin-R1

SUFE-AIFLM-Lab

CD

Paper

QwQ-32B

32B

2025-03

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

/

QwenLM

CD

ğŸ“‘ blog

DeepSeek-R1

A37/671B

2025-01

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

DeepSeek-R1

deepseek-ai

MoE

**Paper Link**ğŸ‘ï¸

DeepSeek-R1-Zero

A37/671B

2025-01

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

DeepSeek-R1

deepseek-ai

MoE

**Paper Link**ğŸ‘ï¸

DeepSeek-R1-Distill-Qwen

1.5/7/14/32B

2025-01

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

DeepSeek-R1

deepseek-ai

MoE

**Paper Link**ğŸ‘ï¸

MiniMax-Text-01

A46/456B

2025-01

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

MiniMax-01

MiniMax-AI

MoE

Paper

MiniMax-VL-01

A46/456B

2025-01

ä¸­è‹±

å¤šæ¨¡æ€

ğŸ¤—HF

MiniMax-01

MiniMax-AI

MoE

Paper

Sky-T1

32B

2025-01

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

SkyThought

NovaSky-AI

CD

Blog

Search-O1

2025-01

ä¸­è‹±

é€šç”¨

/

Search-o1

sunnynexus

CD

Paper

HuatuoGPT-o1

7/8/70/72B

2025-01

ä¸­è‹±

åŒ»ç–—

ğŸ¤—HF

HuatuoGPT-o1

FreedomIntelligence/

CD

Paper

QwQ-32B-Preview

32B

2024-11

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

/

QwenLM

CD

Marco-o1

7B

2024-11

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

Marco-o1

AIDC-AI

CD

**Paper**

Skywork-01-Open

8B

2024-11

ä¸­è‹±

é€šç”¨

ğŸ¤—HF

skywork-o1-prm-inference

SkyworkAI

CD

Blog

HK-01aw

8B

2024-11

ä¸­æ–‡

æ³•å¾‹

ğŸ¤—HF

HK-O1aw

HKAIR-Lab

CD

QVQ-72B-Preview

72B

2024-12

ä¸­è‹±

å¤šæ¨¡

ğŸ¤— HF

Qwen2-VL

QwenLM

Blog

\[Back to Top\]

ä¸­æ–‡æŒ‡ä»¤æ•°æ®é›†
-------

> æ”¶é›†åŒ…å«ä¸­æ–‡çš„æŒ‡ä»¤æ•°æ®é›†ï¼Œç”¨äºå¾®è°ƒè¯­è¨€æ¨¡å‹ã€‚

åç§°

å¤§å°

æ—¶é—´

è¯­è¨€

ä¸‹è½½

é¡¹ç›®åœ°å€

ä½œè€…

å¤‡æ³¨

FinCorpus

50G

2023-09

ä¸­æ–‡

dataset

XuanYuan

åº¦å°æ»¡

é‡‘èé¢†åŸŸ

TransGPT-sft

346k

2023-07

ä¸­æ–‡

dataset

TransGPT

åŒ—äº¬äº¤é€šå¤§å­¦

TransGPT-pt

58k

2023-07

ä¸­æ–‡

dataset

TransGPT

åŒ—äº¬äº¤é€šå¤§å­¦

ShareGPT-Chinese-English

90K

2023-07

ä¸­è‹±

dataset

llama2-Chinese-chat

Ke Bai

educhat-sft-002-data-osm

400w

2023-06

ä¸­è‹±

dataset

EduChat

åä¸œå¸ˆèŒƒå¤§å­¦

æ•™è‚²

chatgpt-corpus

3M

2023-06

ä¸­æ–‡

dataset

chatgpt-corpus

plex

Simle

350k

2023-06

ä¸­æ–‡

dataset

smile

qiuhuachuan

å¿ƒç†å¥åº·

QiZhen

20k

2023-06

ä¸­æ–‡

dataset

QiZhenGPT

æµ™æ±Ÿå¤§å­¦

åŒ»å­¦

BayLing-80

80

2023-06

ä¸­è‹±

dataset

BayLing

ä¸­å›½ç§‘å­¦é™¢

å¤šè½®æŒ‡ä»¤

Tigerbot-dataset

120k

2023-06

ä¸­è‹±

dataset

TigerBot

è™åšç§‘æŠ€

lawyer-llama

/

2023-05

ä¸­æ–‡

dataset

lawyer-llama

Quzhe Huang

æ³•å¾‹

Bactrian-X

67K

2023-05

å¤šè¯­

dataset

bactrian-x

MBZUAI

CrimeKgAssitant

52k

2023-05

ä¸­æ–‡

dataset

LAW-GPT

hongchengliu

æ³•å¾‹

moss-002-sft-data

1.1M

2023-04

ä¸­è‹±

dataset

MOSS

å¤æ—¦å¤§å­¦

moss-003-sft-data

1.1M

2023-04

ä¸­è‹±

dataset

MOSS

å¤æ—¦å¤§å­¦

moss-003-sft-plugin-data

300K

2023-04

ä¸­è‹±

dataset

MOSS

å¤æ—¦å¤§å­¦

Safety-Prompts

100K

2023-04

ä¸­æ–‡

dataset

Safety-Prompts

æ¸…åå¤§å­¦

è¯„æµ‹å¹³å°

OASST1

/

2023-04

å¤šè¯­

dataset

Open-Assistant

OpenAssistant

ShareChat

90K

2023-04

ä¸­è‹±

dataset

ShareChat

czhko

GPT-4-LLM

52K

2023-04

ä¸­æ–‡

dataset

GPT-4-LLM

Instruction-Tuning-with-GPT-4

paper

COIG

200K

2023-04

ä¸­æ–‡

dataset

FlagInstruct

BAAI

paper

RedGPT

50k

2023-04

ä¸­æ–‡

dataset

RedGPT

MiniGPT

shareGPT\_cn

20k

2023-04

ä¸­æ–‡

dataset

shareGPT\_cn

shareAI

generated\_chat\_0.4M

0.4M

2023-04

ä¸­æ–‡

dataset

BELLE

Ke Technologies

è§’è‰²å¯¹è¯

multiturn\_chat\_0.8M

0.8M

2023-04

ä¸­æ–‡

dataset

BELLE

Ke Technologies

å¤šè½®ä»»åŠ¡

school\_math\_0.25M

0.25M

2023-04

ä¸­æ–‡

dataset

BELLE

Ke Technologies

æ•°å­¦é¢˜

Zhihu-KOL

/

2023-03

ä¸­æ–‡

dataset

Zhihu-KOL

Rui Wang

InstructionWild

104k

2023-03

ä¸­è‹±

dataset

InstructionWild

Xue Fuzhao

Alpaca-CoT

/.

2023-03

ä¸­è‹±

dataset

Alpaca-CoT

Qingyi Si

GuanacoDataset

/

2023-03

å¤šè¯­

dataset

guanaco-model

Guanaco

Traditional-Chinese-alpaca

52K

2023-03

ä¸­æ–‡

dataset

Traditional-Chinese Alpaca

NTU NLP Lab

gptç¿»è¯‘

alpaca\_chinese\_dataset

/

2023-03

ä¸­æ–‡

dataset

alpaca\_chinese\_dataset

akou

äººå·¥æ ¡éªŒ

alpaca-chinese-dataset

/

2023-03

ä¸­æ–‡

dataset

alpaca-chinese-dataset

carbonz

æœºå™¨ç¿»è¯‘

train\_2M\_CN

2M

2023-03

ä¸­æ–‡

dataset

BELLE

Ke Technologies

train\_1M\_CN

1M

2023-03

ä¸­æ–‡

dataset

BELLE

Ke Technologies

train\_0.5M\_CN

0.5M

2023-03

ä¸­æ–‡

dataset

BELLE

Ke Technologies

HC3 äººç±»-ChatGPT é—®ç­”

/

2023-03

ä¸­æ–‡

dataset

chatgpt-comparison-detection

SimpleAI

firefly-train-1.1M

1.1M

2023-03

ä¸­æ–‡

dataset

Firefly

Jianxin Yang

\[Back to Top\]

### Embedding

> MTEBæ’è¡Œæ¦œ: https://huggingface.co/spaces/mteb/leaderboard é•œåƒ

æ¨¡å‹

å¤§å°

æ—¶é—´

è¯­è¨€

é¢†åŸŸ

ä¸‹è½½

é¡¹ç›®åœ°å€

æœºæ„/ä¸ªäºº

æ–‡

Qwen3-Embedding

0.6/4/8B

2025-06

å¤šè¯­

é€šç”¨

\[ğŸ¤—HF\]

Qwen3-Embedding

QwenLM

Arxiv

JinaColBERT V2

large

2024-08

å¤šè¯­

é€šç”¨

\[ğŸ¤—HF\]

/

Jina AI

Paper

Conan-embedding-v1

large

2024-08

ä¸­æ–‡

é€šç”¨

\[ğŸ¤—HF\]

/

TencentABC

Paper

xiaobu-v2

large

2024-07

ä¸­æ–‡

é€šç”¨

\[ğŸ¤—HF\]

/

lier007

zpoint\_large

Large

2024-06

ä¸­æ–‡

é€šç”¨

\[ğŸ¤—HF\]

/

**yang**

BCE

279M

2024-01

å¤šè¯­

é€šç”¨

\[ğŸ¤—HF\]

BCEmbedding

netease-youdao

Cohere

Base

2023-09

å¤šè¯­

é€šç”¨

\[ğŸ¤—HF\]

/

Cohere

Blog

jina

Base

2023-10

ä¸­è‹±

é€šç”¨

\[ğŸ¤—HF\]

/

Jina AI

Dmeta

**400MB**

2024-02

ä¸­æ–‡

é€šç”¨

\[ğŸ¤—HF\]

/

DMetaSoul

bge-m3

2024-02

ä¸­æ–‡

é€šç”¨

\[ğŸ¤—HF\]

/

BAAI

Paper

tao-8k

2023-11

ä¸­æ–‡

é€šç”¨

\[ğŸ¤—HF\]

amu

bge

s/b/l

2023-10

ä¸­æ–‡

é€šç”¨

\[ğŸ¤—HF\]

/

BAAI

gte-zh

s/b/l

2023-08

ä¸­æ–‡

é€šç”¨

\[ğŸ¤—HF\]

/

Alibaba DAMO

Paper

m3e

s/b/l

2023-06

ä¸­æ–‡

é€šç”¨

\[ğŸ¤—HF\]

/

Moka-AI

LaBSE

å¤šè¯­

é€šç”¨

\[ğŸ¤—HF\]

/

Sentence Transformers

\[Back to Top\]

å¤§æ¨¡å‹è¯„ä¼°åŸºå‡†
-------

### 1\. C-Eval

C-Eval æ˜¯ä¸€ä¸ªå…¨é¢çš„ä¸­æ–‡åŸºç¡€æ¨¡å‹è¯„ä¼°å¥—ä»¶ã€‚å®ƒåŒ…å«äº†13948ä¸ªå¤šé¡¹é€‰æ‹©é¢˜ï¼Œæ¶µç›–äº†52ä¸ªä¸åŒçš„å­¦ç§‘å’Œå››ä¸ªéš¾åº¦çº§åˆ«ï¼ŒæŸ¥çœ‹è®ºæ–‡äº†è§£æ›´å¤šç»†èŠ‚ã€‚

\[å®˜æ–¹ç½‘ç«™\] \[Github\] \[è®ºæ–‡\]

### 2\. FlagEval

FlagEvalæ˜¯ä¸€ä¸ªé¢å‘AIåŸºç¡€æ¨¡å‹çš„è¯„æµ‹å·¥å…·åŒ…ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯æ¢ç´¢å’Œé›†åˆç§‘å­¦ã€å…¬æ­£ã€å¼€æ”¾çš„åŸºç¡€æ¨¡å‹è¯„æµ‹åŸºå‡†ã€æ–¹æ³•åŠå·¥å…·ï¼Œå¯¹å¤šé¢†åŸŸï¼ˆå¦‚è¯­è¨€ã€è¯­éŸ³ã€è§†è§‰åŠå¤šæ¨¡æ€ï¼‰çš„åŸºç¡€æ¨¡å‹è¿›è¡Œå¤šç»´åº¦ï¼ˆå¦‚å‡†ç¡®æ€§ã€æ•ˆç‡ã€é²æ£’æ€§ç­‰ï¼‰çš„è¯„æµ‹ã€‚æˆ‘ä»¬å¸Œæœ›é€šè¿‡å¯¹åŸºç¡€æ¨¡å‹çš„è¯„æµ‹ï¼ŒåŠ æ·±å¯¹åŸºç¡€æ¨¡å‹çš„ç†è§£ï¼Œä¿ƒè¿›ç›¸å…³çš„æŠ€æœ¯åˆ›æ–°åŠäº§ä¸šåº”ç”¨ã€‚

\[å®˜æ–¹ç½‘ç«™\] \[Github\]

### 3\. SuperCLUElyb

SuperCLUEç…çŠæ¦œï¼Œè¿™æ˜¯ä¸€ä¸ªä¸­æ–‡é€šç”¨å¤§æ¨¡å‹å¯¹æˆ˜è¯„ä»·åŸºå‡†ï¼Œå®ƒä»¥ä¼—åŒ…çš„æ–¹å¼æä¾›åŒ¿åã€éšæœºçš„å¯¹æˆ˜ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å‘å¸ƒäº†åˆæ­¥çš„ç»“æœå’ŒåŸºäºEloè¯„çº§ç³»ç»Ÿçš„æ’è¡Œæ¦œï¼ŒEloè¯„çº§æ˜¯å›½é™…è±¡æ£‹å’Œå…¶ä»–ç«æŠ€æ¸¸æˆä¸­å¹¿æ³›ä½¿ç”¨çš„è¯„çº§ç³»ç»Ÿã€‚æˆ‘ä»¬é‚€è¯·æ•´ä¸ªç¤¾åŒºåŠ å…¥è¿™é¡¹å·¥ä½œï¼Œè´¡çŒ®æ–°çš„æ¨¡å‹ï¼Œå¹¶é€šè¿‡æé—®å’ŒæŠ•ç¥¨é€‰å‡ºä½ æœ€å–œæ¬¢çš„ç­”æ¡ˆæ¥è¯„ä¼°å®ƒä»¬ã€‚

\[å®˜æ–¹ç½‘ç«™\] \[Github\]

### 4\. XiezhiBenchmark

è¯¥åŸºå‡†åŒ…æ‹¬æ¥è‡ª13ä¸ªä¸åŒå­¦ç§‘çš„516ä¸ªå­¦ç§‘çš„220,000ä¸ªå¤šé¡¹é€‰æ‹©é¢˜ï¼Œä»¥åŠ15,000ä¸ªæ¥è‡ªå•ä¸€å­¦ç§‘å’Œå¤šä¸ªå­¦ç§‘çš„é—®é¢˜ã€‚æˆ‘ä»¬å¯¹47ä¸ªæœ€æ–°çš„å¤§å‹è¯­è¨€æ¨¡å‹åœ¨Xiezhiä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œç»“æœè¡¨æ˜åœ¨ç§‘å­¦ã€å·¥ç¨‹ã€å†œå­¦ã€åŒ»å­¦å’Œè‰ºæœ¯ç­‰é¢†åŸŸï¼Œå¤§å‹è¯­è¨€æ¨¡å‹çš„è¡¨ç°è¶…è¿‡äº†äººç±»çš„å¹³å‡æ°´å¹³ï¼Œä½†åœ¨ç»æµå­¦ã€æ³•å­¦ã€æ•™è‚²å­¦ã€æ–‡å­¦ã€å†å²å’Œç®¡ç†å­¦ç­‰é¢†åŸŸï¼Œäººç±»çš„è¡¨ç°ä»ç„¶è¿œè¿œè¶…è¿‡äº†å¤§å‹è¯­è¨€æ¨¡å‹ã€‚

\[å®˜æ–¹ç½‘ç«™\] \[Github\] \[è®ºæ–‡\]

### 5\. Open LLM Leaderboard

ç”±HuggingFaceç»„ç»‡çš„ä¸€ä¸ªLLMè¯„æµ‹æ¦œå•ï¼Œç›®å‰å·²è¯„ä¼°äº†è¾ƒå¤šä¸»æµçš„å¼€æºLLMæ¨¡å‹ï¼Œä»¥è‹±æ–‡ä¸ºä¸»ã€‚ä¸»è¦ç›®æ ‡æ˜¯è·Ÿè¸ªã€æ’åå’Œè¯„ä¼°æœ€æ–°çš„å¤§è¯­è¨€æ¨¡å‹å’ŒèŠå¤©æœºå™¨äººï¼Œè®©æ‰€æœ‰äººæ–¹ä¾¿çš„è§‚å¯Ÿåˆ°å¼€æºç¤¾åŒºçš„è¿›å±•å’Œè¯„ä¼°è¿™äº›æ¨¡å‹ã€‚è¿™ä¸ªæ’è¡Œæ¦œæœ‰ä¸€ä¸ªå…³é”®ä¼˜åŠ¿ï¼Œç¤¾åŒºä¸­çš„ä»»ä½•æˆå‘˜éƒ½å¯ä»¥æäº¤æ¨¡å‹ï¼Œå¹¶åœ¨ Hugging Face çš„ GPU é›†ç¾¤ä¸Šè‡ªåŠ¨è¯„ä¼°ã€‚

\[å®˜æ–¹ç½‘ç«™\]

### 6\. ä¸­æ–‡å¤§æ¨¡å‹å®‰å…¨è¯„æµ‹å¹³å°

å¤§æ¨¡å‹å®‰å…¨æµ‹è¯„ä¾æ‰˜äºä¸€å¥—ç³»ç»Ÿçš„å®‰å…¨è¯„æµ‹æ¡†æ¶ï¼Œæ¶µç›–äº†ä»‡æ¨è¨€è®ºã€åè§æ­§è§†è¨€è®ºã€çŠ¯ç½ªè¿æ³•ã€éšç§ã€ä¼¦ç†é“å¾·ç­‰å…«å¤§ç±»åˆ«ï¼ŒåŒ…æ‹¬ç»†ç²’åº¦åˆ’åˆ†çš„40ä½™ä¸ªäºŒçº§å®‰å…¨ç±»åˆ«ã€‚

\[å®˜æ–¹ç½‘ç«™\] \[Github\] \[è®ºæ–‡\]

### 7\. OpenCompasså¤§è¯­è¨€æ¨¡å‹è¯„æµ‹

OpenCompass æ˜¯ä¸€æ¬¾å¼€æºã€é«˜æ•ˆã€å…¨é¢çš„è¯„æµ‹å¤§æ¨¡å‹ä½“ç³»åŠå¼€æ”¾å¹³å°ã€‚æˆ‘ä»¬æä¾›å®Œæ•´å¼€æºå¯å¤ç°çš„è¯„æµ‹æ¡†æ¶ï¼Œæ”¯æŒå¤§è¯­è¨€æ¨¡å‹ã€å¤šæ¨¡æ€æ¨¡å‹å„ç±»æ¨¡å‹çš„ä¸€ç«™å¼è¯„æµ‹ã€‚åˆ©ç”¨åˆ†å¸ƒå¼æŠ€æœ¯ï¼Œå³ä½¿é¢å¯¹åƒäº¿å‚æ•°æ¨¡å‹ä¹Ÿèƒ½åœ¨æ•°å°æ—¶å†…å®Œæˆè¯„æµ‹ã€‚åŸºäºå¤šä¸ªä¸åŒç»´åº¦çš„é«˜è®¤å¯åº¦æ•°æ®é›†å¼€æ”¾å¤šæ ·åŒ–çš„è¯„æµ‹æ–¹å¼ï¼ŒåŒ…æ‹¬é›¶æ ·æœ¬è¯„æµ‹ã€å°æ ·æœ¬è¯„æµ‹å’Œæ€ç»´é“¾è¯„æµ‹ï¼Œå…¨æ–¹ä½é‡åŒ–æ¨¡å‹å„ä¸ªç»´åº¦èƒ½åŠ›ã€‚

\[å®˜æ–¹ç½‘ç«™\] \[Github\]

\[Back to Top\]

åœ¨çº¿ä½“éªŒå¤§æ¨¡å‹
-------

> **æ³¨**ï¼šéœ€è¦ç”³è¯·æˆ–è€…æ³¨å†Œæ–¹å¯ä½“éªŒ,æ›´å¤šè§Github

### 1\. ChatGPT--OpenAI

OpenAIæ‰€æå‡ºçš„GPTç›¸å…³æ¨¡å‹ï¼Œä¹Ÿæ˜¯ç›®å‰æœ€ç«çš„å¤§è¯­è¨€æ¨¡å‹ï¼Œå‘å¸ƒç‰ˆæœ¬å·²ç»åˆ°äº†4.0.

\[å®˜æ–¹ç½‘ç«™\]

### 2\. New bing--å¾®è½¯

NewBingæ˜¯å¾®è½¯åœ¨2023å¹´3æœˆæ¨å‡ºçš„ä¸€æ¬¾å…¨æ–°çš„æœç´¢å¼•æ“ï¼Œå®ƒåŸºäºOpenAIçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œå¹¶ç»“åˆäº†ChatGPTå’ŒDALLÂ·Eçš„æŠ€æœ¯ï¼Œä¸ºç”¨æˆ·æä¾›äº†ä¸€ä¸ªAIé©±åŠ¨çš„ç½‘ç»œåŠ©æ‰‹ã€‚

\[å®˜æ–¹ç½‘ç«™\]

### 3\. æ–‡å¿ƒä¸€è¨€--ç™¾åº¦

ç™¾åº¦å…¨æ–°ä¸€ä»£çŸ¥è¯†å¢å¼ºå¤§è¯­è¨€æ¨¡å‹ï¼Œæ–‡å¿ƒå¤§æ¨¡å‹å®¶æ—çš„æ–°æˆå‘˜ï¼Œèƒ½å¤Ÿä¸äººå¯¹è¯äº’åŠ¨ï¼Œå›ç­”é—®é¢˜ï¼ŒååŠ©åˆ›ä½œï¼Œé«˜æ•ˆä¾¿æ·åœ°å¸®åŠ©äººä»¬è·å–ä¿¡æ¯ã€çŸ¥è¯†å’Œçµæ„Ÿã€‚

\[å®˜æ–¹ç½‘ç«™\]

### 4\. é€šä¹‰å¤§æ¨¡å‹--é˜¿é‡Œ

é˜¿é‡Œå¤§æ¨¡å‹ç»Ÿä¸€å“ç‰Œï¼Œè¦†ç›–è¯­è¨€ã€å¬è§‰ã€å¤šæ¨¡æ€ç­‰é¢†åŸŸè‡´åŠ›äºå®ç°æ¥è¿‘äººç±»æ™ºæ…§çš„é€šç”¨æ™ºèƒ½ï¼Œè®©AIä»â€œå•ä¸€æ„Ÿå®˜â€åˆ°â€œäº”å®˜å…¨å¼€â€

\[å®˜æ–¹ç½‘ç«™\]

### 5\. æ˜Ÿç«è®¤çŸ¥å¤§æ¨¡å‹--ç§‘å¤§è®¯é£

ç§‘å¤§è®¯é£æ¨å‡ºçš„æ–°ä¸€ä»£è®¤çŸ¥æ™ºèƒ½å¤§æ¨¡å‹ï¼Œæ‹¥æœ‰è·¨é¢†åŸŸçš„çŸ¥è¯†å’Œè¯­è¨€ç†è§£èƒ½åŠ›ï¼Œèƒ½å¤ŸåŸºäºè‡ªç„¶å¯¹è¯æ–¹å¼ç†è§£ä¸æ‰§è¡Œä»»åŠ¡ã€‚ä»æµ·é‡æ•°æ®å’Œå¤§è§„æ¨¡çŸ¥è¯†ä¸­æŒç»­è¿›åŒ–ï¼Œå®ç°ä»æå‡ºã€è§„åˆ’åˆ°è§£å†³é—®é¢˜çš„å…¨æµç¨‹é—­ç¯ã€‚

\[å®˜æ–¹ç½‘ç«™\]

### 6\. Claude--Anthropic

Claudeï¼Œæ˜¯äººå·¥æ™ºèƒ½åˆåˆ›å…¬å¸Anthropic å‘å¸ƒçš„ä¸€æ¬¾ç±»ä¼¼ChatGPTçš„äº§å“ã€‚

\[å®˜æ–¹ç½‘ç«™\]

### 7\. ChatGLM--æ™ºè°±AI

åŸºäºåƒäº¿åŸºåº§æ¨¡å‹ GLM-130Bï¼Œæ³¨å…¥ä»£ç é¢„è®­ç»ƒï¼Œé€šè¿‡æœ‰ç›‘ç£å¾®è°ƒç­‰æŠ€æœ¯å®ç°äººç±»æ„å›¾å¯¹é½ï¼Œå…·å¤‡é—®ç­”ã€å¤šè½®å¯¹è¯ã€ä»£ç ç”ŸæˆåŠŸèƒ½çš„ä¸­è‹±åŒè¯­å¤§æ¨¡å‹ã€‚

\[å®˜æ–¹ç½‘ç«™\]

### 8\. å¤©å·¥å¤§æ¨¡å‹--æ˜†ä»‘ä¸‡ç»´

å¤©å·¥ä½œä¸ºä¸€æ¬¾å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œæ‹¥æœ‰å¼ºå¤§çš„è‡ªç„¶è¯­è¨€å¤„ç†å’Œæ™ºèƒ½äº¤äº’èƒ½åŠ›ï¼Œèƒ½å¤Ÿå®ç°æ™ºèƒ½é—®ç­”ã€èŠå¤©äº’åŠ¨ã€æ–‡æœ¬ç”Ÿæˆç­‰å¤šç§åº”ç”¨åœºæ™¯ï¼Œå¹¶ä¸”å…·æœ‰ä¸°å¯Œçš„çŸ¥è¯†å‚¨å¤‡ï¼Œæ¶µç›–ç§‘å­¦ã€æŠ€æœ¯ã€æ–‡åŒ–ã€è‰ºæœ¯ã€å†å²ç­‰é¢†åŸŸã€‚

\[å®˜æ–¹ç½‘ç«™\]

### 9\. åºåˆ—çŒ´å­å¤§æ¨¡å‹--å‡ºé—¨é—®é—®

åºåˆ—çŒ´å­å¤§æ¨¡å‹æ˜¯ä¸€ä¸ªå…·æœ‰é•¿åºåˆ—ã€å¤šæ¨¡æ€ã€å•æ¨¡å‹ã€å¤§æ•°æ®ç­‰ç‰¹ç‚¹çš„è¶…å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ŒåŸºäºå…¶é€šç”¨çš„è¡¨ç¤ºèƒ½åŠ›ä¸æ¨ç†èƒ½åŠ›ï¼Œèƒ½å¤Ÿè¿›è¡Œå¤šè½®äº¤äº’ï¼Œæ‰“é€ æ›´ä¾¿æ·æµç•…çš„ç”¨æˆ·ä½“éªŒï¼Œæå¤§åœ°æé«˜äº†ç”Ÿäº§æ•ˆç‡å’Œæ•°æ®å¤„ç†èƒ½åŠ›ï¼Œè¢«å¹¿æ³›åº”ç”¨äºé—®ç­”ç³»ç»Ÿã€è‡ªç„¶è¯­è¨€å¤„ç†ã€æœºå™¨ç¿»è¯‘ã€æ–‡æœ¬æ‘˜è¦ç­‰é¢†åŸŸã€‚

\[å®˜æ–¹ç½‘ç«™\]

### 10\. MOSS--å¤æ—¦å¤§å­¦

MOSSæ˜¯å¤æ—¦å¤§å­¦è‡ªç„¶è¯­è¨€å¤„ç†å®éªŒå®¤å‘å¸ƒçš„å›½å†…ç¬¬ä¸€ä¸ªå¯¹è¯å¼å¤§å‹è¯­è¨€æ¨¡å‹

\[å®˜æ–¹ç½‘ç«™\]

### 11\. 360æ™ºè„‘å¤§æ¨¡--360

360æ™ºè„‘çš„ç”Ÿæˆä¸åˆ›ä½œã€å¤šè½®å¯¹è¯ã€ä»£ç èƒ½åŠ›ã€é˜…è¯»ç†è§£ã€é€»è¾‘ä¸æ¨ç†ã€å¤šæ¨¡æ€ç­‰åå¤§æ ¸å¿ƒèƒ½åŠ›å¯è¦†ç›–å¤§æ¨¡å‹å…¨éƒ¨åº”ç”¨åœºæ™¯ã€‚

\[å®˜æ–¹ç½‘ç«™\]

### 12\. æ›¹æ¤GPTå¤§è¯­è¨€æ¨¡å‹--è¾¾è§‚æ•°æ®

è¾¾è§‚æ•°æ®ç§¯ææ¢ç´¢å¤§è¯­è¨€æ¨¡å‹LLMçš„å®è·µï¼Œç ”å‘å›½äº§ç‰ˆGPTâ€œæ›¹æ¤â€ç³»ç»Ÿï¼Œä½œä¸ºå‚ç›´ã€ä¸“ç”¨ã€è‡ªä¸»å¯æ§çš„å›½äº§ç‰ˆChatGPTæ¨¡å‹ï¼Œä¸ä»…å®ç°ä¸“ä¸šé¢†åŸŸçš„AIGCæ™ºèƒ½åŒ–åº”ç”¨ï¼Œä¸”å¯å†…ç½®åœ¨å®¢æˆ·å„ç±»ä¸šåŠ¡ç³»ç»Ÿä¸­æä¾›ä¸“ç”¨æœåŠ¡

\[å®˜æ–¹ç½‘ç«™\]

### 13\. æ—¥æ—¥æ–°--å•†æ±¤

å•†æ±¤â€œæ—¥æ—¥æ–°SenseNovaâ€å¤§æ¨¡å‹ä½“ç³»ï¼Œæ­£å¼é—®ä¸–

ä¸ä»…å±•ç¤ºäº†å¤§æ¨¡å‹ä½“ç³»ä¸‹çš„è¯­è¨€å¤§æ¨¡å‹ï¼Œè¿˜å±•ç¤ºäº†AIæ–‡ç”Ÿå›¾åˆ›ä½œã€2D/3Dæ•°å­—äººç”Ÿæˆã€å¤§åœºæ™¯/å°ç‰©ä½“ç”Ÿæˆç­‰ä¸€ç³»åˆ—ç”Ÿæˆå¼AIæ¨¡å‹åŠåº”ç”¨ï¼Œè¿˜æ­å¼€äº†ä¾æ‰˜å•†æ±¤AIå¤§è£…ç½®SenseCoreå®ç°â€œå¤§æ¨¡å‹+å¤§ç®—åŠ›â€èåˆåˆ›æ–°çš„ç ”å‘ä½“ç³»ã€‚

\[å®˜æ–¹ç½‘ç«™\]

### 14\. å¤©ç‡•å¤§æ¨¡å‹--APUS

å¤©ç‡•å¤§æ¨¡å‹æ˜¯APUSå…¬å¸è‡ªç ”çš„å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼ˆLMMï¼‰ï¼Œå…·å¤‡å¯¹æ–‡æœ¬ã€å›¾åƒã€è§†é¢‘ã€éŸ³é¢‘çš„ç†è§£å’Œç”Ÿæˆèƒ½åŠ›ï¼ˆè§†é¢‘å’ŒéŸ³é¢‘çš„èƒ½åŠ›å³å°†æ¨å‡ºï¼‰ã€‚

\[å®˜æ–¹ç½‘ç«™\]

### 15\. å…ƒä¹˜è±¡--æ™ºå­å¼•æ“

å›¾æ–‡æœºå™¨äºº

\[å®˜æ–¹ç½‘ç«™\]

### 16\. è¥¿æ¹–å¤§æ¨¡å‹--è¥¿æ¹–å¿ƒè¾°

\[å®˜æ–¹ç½‘ç«™\]

### 17\. Dongni--æ·±æ€è€ƒ

AIå¤šæ¨¡æ€æœç´¢å¼•æ“

\[å®˜æ–¹ç½‘ç«™\]

### 18\. å±±æµ·å¤§æ¨¡å‹--äº‘çŸ¥å£°

åªéœ€ä¸€æ¬¡å¯¹è¯å³å¯è·å–ä¿¡æ¯ã€çŸ¥è¯†å’Œçµæ„Ÿï¼Œè§£å†³éœ€æ±‚ã€‚æ˜¯æ¯ä¸ªäººèº«è¾¹çš„åŠ©ç†ã€æœ‹å‹å’Œä¸“å®¶ã€‚

\[å®˜æ–¹ç½‘ç«™\]

### 19\. MiniMaxå¤§æ¨¡å‹--MiniMax

MiniMax æœ€æ–°ä¸€ä»£çš„ä¸­æ–‡å¤§è¯­è¨€æ¨¡å‹å¸®åŠ©äººç±»é«˜æ•ˆå†™ä½œã€æ¿€å‘åˆ›æ„ã€è·å–çŸ¥è¯†ã€åšå‡ºå†³ç­–ç°å·²å¯¹ä¼ä¸šå¼€æ”¾APIä½“éªŒ

\[å®˜æ–¹ç½‘ç«™\]

\[Back to Top\]

å¼€æºæ¨¡å‹åº“å¹³å°
-------

1.  ğŸ¤—HuggingFace: The AI community building the future.

-   æ¨¡å‹ä¸‹è½½åœ°å€: https://huggingface.co/models

1.  ModelScope: ModelScopeå¹³å°æ˜¯ä»¥æ¨¡å‹ä¸ºä¸­å¿ƒçš„æ¨¡å‹å¼€æºç¤¾åŒº

-   æ¨¡å‹ä¸‹è½½åœ°å€:https://modelscope.cn/models

1.  flagopen: flagopené£æ™ºå¤§æ¨¡å‹æŠ€æœ¯å¼€æºä½“ç³»

-   æ¨¡å‹ä¸‹è½½åœ°å€: https://model.baai.ac.cn/models

1.  å§‹æ™ºAI: ä¸­å›½AIå¼€æºåˆ›æ–°ç¤¾åŒº

-   æ¨¡å‹ä¸‹è½½åœ°å€: https://wisemodel.cn/models

\[Back to Top\]

å¼€æºæ•°æ®é›†åº“
------

1.  huggfaceingæ•°æ®é›†ä»“åº“: https://huggingface.co/datasets

-   åŒ…å«äº†è‡ªç„¶è¯­è¨€å¤„ç†ã€è®¡ç®—æœºè§†è§‰ã€è¯­éŸ³ã€å¤šæ¨¡æ€ç­‰æ•°æ®é›†ï¼Œå†…ç½®100å¤šä¸ªå¤šè¯­è¨€å…¬å…±æ•°æ®é›†ä¸‹è½½

1.  ModelScopeæ•°æ®é›†ä»“åº“:https://modelscope.cn/datasets

-   æä¾›äº†è¦†ç›–è‡ªç„¶è¯­è¨€å¤„ç†ã€è®¡ç®—æœºè§†è§‰ã€è¯­éŸ³ã€å¤šæ¨¡æ€ç­‰æ•°æ®é›†ï¼Œæ›´æœ‰é˜¿é‡Œå·´å·´é›†å›¢è´¡çŒ®çš„ä¸“ä¸šé¢†åŸŸæ•°æ®é›†ï¼Œ

1.  flagopenæ•°æ®é›†ä»“åº“: https://data.baai.ac.cn/data

-   å†…ç½®å…¬å…±æ•°æ®é›†ä¸‹è½½ï¼Œå¯ä¸‹200Gå¤§è§„æ¨¡é¢„è®­ç»ƒè¯­æ–™WuDaoCorpora

1.  cluebenchmarksæ•°æ®é›†ä»“åº“ï¼šhttps://www.cluebenchmarks.com/dataSet\_search.html

-   å¤šä¸ªä¸­è‹±æ–‡NLPæ•°æ®é›†ï¼Œå¹¶å¯ç”³è¯·ä¸‹è½½100GBçš„é«˜è´¨é‡ä¸­æ–‡é¢„è®­ç»ƒè¯­æ–™CLUECorpus2020

1.  MNBVC: Massive Never-ending BT Vast Chinese corpus

-   è¶…å¤§è§„æ¨¡ä¸­æ–‡è¯­æ–™é›†

1.  OpenDataLabæ•°æ®é›†ä»“åº“: https://opendatalab.com/

-   OpenDataLab æ˜¯æœ‰å½±å“åŠ›çš„æ•°æ®å¼€æºå¼€æ”¾å¹³å°ï¼Œå…¬å¼€æ•°æ®é›†è§¦æ‰‹å¯åŠã€‚

1.  OSCAR: Open Super-large Crawled Aggregated coRpus, å¤šè¯­è¨€æ•°æ®é›†

-   æœ€æ–°ç‰ˆæœ¬åŒ…å«1.4Tçš„ä¸­æ–‡è¯­è¨€æ•°æ®é›†

\[Back to Top\]

other-awesome
-------------

#### 1\. Awesome-Chatgpt github

æœ¬é¡¹ç›®æ—¨åœ¨æ”¶é›†å…³äºChatGPT çš„èµ„æºã€å·¥å…·ã€åº”ç”¨å’Œç”¨æ³•ç­‰ã€‚

#### 2\. Awesome-ChatGPT-Prompts github

æœ¬é¡¹ç›®æ—¨åœ¨æ”¶é›†å…³äºChatGPT æ¨¡å‹ä½¿ç”¨çš„Promptsç¤ºä¾‹é›†ã€‚

#### 3\. Awesome-LLM github

æœ¬é¡¹ç›®æ—¨åœ¨æ”¶é›†æœ‰å…³å¤§å‹è¯­è¨€æ¨¡å‹ç›¸å…³èµ„æ–™ï¼Œå°¤å…¶æ˜¯ ChatGPT çš„è®ºæ–‡çš„ç²¾é€‰åˆ—è¡¨ã€‚å®ƒè¿˜åŒ…å« LLM è®­ç»ƒæ¡†æ¶ã€éƒ¨ç½² LLM çš„å·¥å…·ã€æœ‰å…³ LLM çš„è¯¾ç¨‹å’Œæ•™ç¨‹ä»¥åŠæ‰€æœ‰å…¬å¼€å¯ç”¨çš„ LLM æ¨¡å‹å’Œ APIã€‚

#### 4\. Awesome-LangChain github

æœ¬é¡¹ç›®æ—¨åœ¨æ”¶é›†ä¸LangChainæœ‰å…³åº”ç”¨åˆ—è¡¨ã€‚LangChainæ˜¯ä¸€ä¸ªæƒŠäººçš„æ¡†æ¶ï¼Œå¯ä»¥åœ¨çŸ­æ—¶é—´å†…å®Œæˆç›¸å…³LLMåº”ç”¨å¼€å‘ã€‚

#### 5\. Awesome-Open-Gpt github

æœ¬é¡¹ç›®æ—¨åœ¨æ”¶é›†å…³äºGPTå¼€æºç²¾é€‰é¡¹ç›®çš„åˆé›†ï¼ˆ170+å…¨ç½‘æœ€å…¨)ï¼Œå…¶ä¸­åŒ…æ‹¬äº†ä¸€äº›GPTé•œåƒã€GPTå¢å¼ºã€GPTæ’ä»¶ã€GPTå·¥å…·ã€GPTå¹³æ›¿çš„èŠå¤©æœºå™¨äººã€å¼€æºå¤§è¯­è¨€æ¨¡å‹ç­‰ç­‰ã€‚

#### 6\. Awesome-Multimodal-Large-Language-Models github

æœ¬é¡¹ç›®æ˜¯å…³äºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰çš„ç²¾é€‰åˆ—è¡¨ï¼ŒåŒ…æ‹¬æ•°æ®é›†ã€å¤šæ¨¡æ€æ¨¡å‹ã€å¤šæ¨¡æ€è¯­å¢ƒå­¦ä¹ ã€å¤šæ¨¡æ€æ€ç»´é“¾ã€llm è¾…åŠ©è§†è§‰æ¨ç†ã€åŸºç¡€æ¨¡å‹ç­‰ã€‚æ­¤åˆ—è¡¨å°†å®æ—¶æ›´æ–°ã€‚âœ¨

#### 7\. Awesome-Transformer-Attention github

æ­¤ repo åŒ…å« Vision Transformer & Attention çš„ç»¼åˆè®ºæ–‡åˆ—è¡¨ï¼ŒåŒ…æ‹¬è®ºæ–‡ã€ä»£ç å’Œç›¸å…³ç½‘ç«™ã€‚

#### 8\. Awesome-Prompt-Engineering github

This repository contains a hand-curated resources for Prompt Engineering with a focus on Generative Pre-trained Transformer (GPT), ChatGPT, PaLM etc

#### 9\. Awesome-AITools github

è¿™ä¸ªä»“åº“æ•´ç†AIç›¸å…³çš„å®ç”¨å·¥å…·ã€‚

#### 10\. Awesome-Chinese-LLM github

æœ¬é¡¹ç›®æ—¨åœ¨æ”¶é›†å’Œæ¢³ç†ä¸­æ–‡LLMç›¸å…³çš„å¼€æºæ¨¡å‹ã€åº”ç”¨ã€æ•°æ®é›†åŠæ•™ç¨‹ç­‰èµ„æ–™ï¼Œç›®å‰æ”¶å½•çš„èµ„æºå·²è¾¾100+ä¸ªï¼

#### 11\. Awesome-LLM4Tool github

Awesome-LLM4Tool is a curated list of the papers, repositories, tutorials, and anythings related to the large language models for tools.

#### 12\. Awesome LLM Security github

A curation of awesome tools, documents and projects about LLM Security.

#### 13\. Awesome AI Agents github

Welcome to our list of AI agents. We structured the list into two parts: Open source projects and Closed-source projects and companies

#### 14\. Awesome-LLM-Large-Language-Models-Notes github

LLM-Large-Language-Models-Notes

#### 15\. Awesome-Efficient-LLM github

A curated list for Efficient Large Language Modelsã€‚

#### 16\. Awesome Datasets for LLM Training github

A quick guide (especially) for trending instruction finetuning datasetsã€‚

#### 17\. Awesome-Align-LLM-Human github

A collection of papers and resources about aligning large language models (LLMs) with human.

#### 18\. Awesome RLHF (RL with Human Feedback) github

This is a collection of research papers for Reinforcement Learning with Human Feedback (RLHF). And the repository will be continuously updated to track the frontier of RLHF.

#### 19\. Prompt-in-context-learning github

An Open-Source Engineering Guide for Prompt-in-context-learning from EgoAlpha Lab.

#### 20\. Awesome Instruction Learning github

An awesome reading list of Instruction Tuning (or, put it more comprehensively, Instruction Learning), including papers and datasets.

#### 21\. Awesome-Foundation-Models github

A foundation model is a large-scale pretrained model (e.g., BERT, DALL-E, GPT-3) that can be adapted to a wide range of downstream applications. This term was first popularized by the Stanford Institute for Human-Centered Artificial Intelligence. This repository maintains a curated list of foundation models for vision and language tasks. Research papers without code are not included.

#### 22\. Awesome-AI-Devtools github

This is a curated list of AI-powered developer tools. These tools leverage AI to assist developers in tasks such as code completion, refactoring, debugging, documentation, and more.

#### 23\. Awesome-Autonomous-GPT github

A curated list of awesome projects and resources related to autonomous AI agents.

#### 24\. Awesome-Papers-Autonomous-Agent github

This is a collection of recent papers focusing on autonomous agent.

#### 25\. Awesome-Code-LLM github

a comprehensive review of LLM researches for code.

#### 26\. Awesome-LLM-Compression github

Awesome LLM compression research papers and tools to accelerate LLM training and inference.

#### 27\. Autonomous-Agents github

Autonomous Agents (LLMs). Updated daily.

#### 28\. Awesome-Large-Multimodal-Agents github

Awesome Large Multimodal Agents.

#### 29\. Awesome-LLM-Prompt-Optimization github

This repo aims to record advanced papers of LLM prompt tuning and automatic optimization (after 2022).

#### 30\. Awesome-LLMs-Datasets github

ä»£è¡¨æ€§LLMæ–‡æœ¬æ•°æ®é›†å¤§åˆ—è¡¨ï¼ŒåŒ…æ‹¬é¢„è®­ç»ƒè¯­æ–™åº“ã€å¾®è°ƒæŒ‡ä»¤æ•°æ®é›†ã€åå¥½æ•°æ®é›†ã€è¯„ä¼°æ•°æ®é›†å’Œä¼ ç»ŸNLPæ•°æ®é›†.

#### 30\. Awesome-RAG-Survey github

This repo is constructed for collecting and categorizing papers about RAG according to our survey paper: Retrieval-Augmented Generation for AI-Generated Content: A Survey. Considering the rapid growth of this field, we will continue to update both paper and this repo.

#### 31\. Awesome-Tool-LLM github

Language models (LMs) are powerful yet mostly for text-generation tasks. Tools have substantially enhanced their performance for tasks that require complex skills.

#### 32\. LLM-Tool-Survey github

Recently, tool learning with large language models~(LLMs) has emerged as a promising paradigm for augmenting the capabilities of LLMs to tackle highly complex problems.

This is the collection of papers related to tool learning with LLMs. These papers are organized according to our survey paper "Tool Learning with Large Language Models: A Survey".

#### 33\. Awesome-Foundation-Model-Leaderboards github

Awesome Foundation Model Leaderboard is a curated list of awesome foundation model leaderboards (for an explanation of what a leaderboard is, please refer to this post), along with various development tools and evaluation organizations according to our survey:.

#### 34\. Awesome-LLM-KV-Cache github

Awesome-LLM-KV-Cache: A curated list of ğŸ“™Awesome LLM KV Cache Papers with Codes. This repository is for personal use of learning and classifying the burning KV Cache related papers!

#### 35\. Awesome-LLM-Strawberry github

This is a collection of research papers & blogs for OpenAI Strawberry(o1) and Reasoning.

And the repository will be continuously updated to track the frontier of LLM Reasoning.

#### 36\. Awesome-LLM-Resourses github

ğŸ§‘â€ğŸš€ å…¨ä¸–ç•Œæœ€å¥½çš„LLMèµ„æ–™æ€»ç»“ | Summary of the world's best LLM resources.

#### 37\. Awesome-LLM-Reasoning-Openai-o1-Survey github

The related works and background techniques about OpenAI o1, including LLM reasoning, self-play reinforcement learning, complex logic reasoning, scaling law, etc.

#### 38\. Awesome-LLM-Reasoning github

Curated collection of papers and resources on how to unlock the reasoning ability of LLMs and MLLMs.

#### 39\. Awesome-Computer-Use-Agents github

This is a collection of resources for computer-use agents, including papers and blogs. The repository is currently under construction and will be continuously updated. We welcome contributions and feedback as we continue expanding this collection!

#### 40\. LLM\_MultiAgents\_Survey\_Papers github

Our survey about LLM based Multi-Agents is available at: https://arxiv.org/abs/2402.01680

#### 41\. Awesome\_Think\_With\_Images github

Welcome to the Awesome-Think-With-Images repository! This repository serves as the first systematic and comprehensive curated collection of pivotal research dedicated to enabling LVLMs to truly think with images. We delve into how these sophisticated models are evolving beyond mere pattern recognition, acquiring capabilities for intricate reasoning, nuanced understanding, and dynamic interaction by processing and interpreting visual information in cognitive-inspired ways.

#### 42\. Awesome Label-free Reinforcement Learning Papers github

Warning: This repo is built for researchers interested in the recent "flurry" in RL field. Many new papers claim to improve the â€œreasoning abilitiesâ€ in language models. However, as shown by recent work, the improvement of most of Reinforcement Learning with Verifiable Reward (RLVR) papers could be a mirage due to various accidental issues in the evaluation setups. The baseline numbers of the pre-RL models may be massively underreported. Thus we should carefully examine the degree by which true learning happens.

#### 43\. Awesome-AI-Agent-Papers github

ai-agent-papersï¼šAIæ™ºèƒ½ä½“ç ”ç©¶èµ„æºåº“ã€‚å®ƒä¸ºç ”ç©¶äººå‘˜å’Œå¼€å‘è€…æä¾›äº†ä¸€ä¸ªå…¨é¢çš„AIæ™ºèƒ½ä½“è®ºæ–‡é›†åˆï¼ŒåŠ©åŠ›å¿«é€Ÿäº†è§£é¢†åŸŸå‰æ²¿åŠ¨æ€ã€‚äº®ç‚¹ï¼š1. æ¶µç›–å¤šç§æ™ºèƒ½ä½“èƒ½åŠ›ä¸åº”ç”¨åœºæ™¯ï¼›2. å®šæœŸæ›´æ–°ï¼Œç´§è·Ÿæœ€æ–°ç ”ç©¶æˆæœï¼›3. æä¾›è¯¦ç»†åˆ†ç±»ï¼Œæ–¹ä¾¿å¿«é€Ÿå®šä½æ„Ÿå…´è¶£çš„å†…å®¹ã€‚

#### 44\. Awesome-Large-Search-Models github

æ±‡èšæœ€æ–°æœç´¢å¯¼å‘å‹å¤§è¯­è¨€æ¨¡å‹ï¼ˆå¤§æœç´¢æ¨¡å‹ï¼‰çš„ç ”ç©¶è®ºæ–‡ã€åšå®¢åŠç›¸å…³èµ„æºã€‚å®ƒèƒ½ä¸ºç ”ç©¶äººå‘˜å’Œå¼€å‘è€…æä¾›ä¸€ç«™å¼çš„å­¦ä¹ å’Œç ”ç©¶å¹³å°ï¼ŒåŠ©åŠ›å¿«é€Ÿäº†è§£è¯¥é¢†åŸŸçš„å‰æ²¿åŠ¨æ€ã€‚äº®ç‚¹ï¼š1. æ¶µç›–åŸºäºè®­ç»ƒå’Œæ— è®­ç»ƒçš„å¤šç§æ–¹æ³•ï¼›2. æ•´åˆä¸°å¯Œå¤šæ ·çš„æ•°æ®é›†èµ„æºï¼›3. æä¾›å¤šä¸ªçƒ­é—¨æ¡†æ¶é“¾æ¥ï¼Œæ–¹ä¾¿ç›´æ¥ä½¿ç”¨

#### 45\. Awesome-Deep-Research github

ä¸€ç«™å¼æ¢ç´¢Agentæ·±åº¦ç ”ç©¶èµ„æºçš„å®è—åº“ã€‚äº®ç‚¹ï¼š1. æ±‡é›†å…¨çƒé¡¶å°–çš„æ·±åº¦ç ”ç©¶äº§å“ï¼›2. æ•´ç†å‰æ²¿å¼€æºå·¥å…·å’Œæœ€æ–°ç ”ç©¶è®ºæ–‡ï¼›3. æä¾›ä¸°å¯Œçš„è¯„ä¼°åŸºå‡†ä¸å®é™…åº”ç”¨æ¡ˆä¾‹

#### 46\. Reading-List-of-LLM-Based-Data-Science-Agent github

This is the reading list of Large Language Model-Based Data Science Agent

\[Back to Top\]

NLUç³»åˆ—
-----

### BERT

-   2018 | BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding | Jacob Devlin, et al. | arXiv | `PDF`
-   2019 | Pre-Training with Whole Word Masking for Chinese BERT | Yiming Cui, et al. | arXiv | `PDF`

æ¨¡å‹

ç‰ˆæœ¬

TensorFlow

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

BERT-Base

base

Google Drive

Google Research

github

é€šç”¨

BERT-wwm

base

Google Drive  
è®¯é£äº‘-07Xj

Google Drive

Yiming Cui

github

é€šç”¨

BERT-wwm-ext

base

Google Drive  
è®¯é£äº‘-4cMG

Google Drive

Yiming Cui

github

é€šç”¨

bert-base-æ°‘äº‹

base

é˜¿é‡Œäº‘

THUNLP

github

å¸æ³•

bert-base-åˆ‘äº‹

base

é˜¿é‡Œäº‘

THUNLP

github

å¸æ³•

BAAI-JDAI-BERT

base

äº¬ä¸œäº‘

JDAI

github

ç”µå•†å®¢æœå¯¹è¯

FinBERT

base

Google Drive  
ç™¾åº¦ç½‘ç›˜-1cmp

Google Drive  
ç™¾åº¦ç½‘ç›˜-986f

Value Simplex

github

é‡‘èç§‘æŠ€é¢†åŸŸ

EduBERT

base

å¥½æœªæ¥AI

å¥½æœªæ¥AI

tal-tech

github

æ•™è‚²é¢†åŸŸ

guwenbert-base

base

ç™¾åº¦ç½‘ç›˜-4jng  
\[ğŸ¤—HF\]

Ethan

github

å¤æ–‡é¢†åŸŸ

guwenbert-large

large

ç™¾åº¦ç½‘ç›˜-m5sz  
\[ğŸ¤—HF\]

Ethan

github

å¤æ–‡é¢†åŸŸ

BERT-CCPoem

small

thunlp

THUNLP-AIPoet

github

å¤å…¸è¯—æ­Œ

å¤‡æ³¨:

> wwmå…¨ç§°ä¸º\*\*Whole Word Masking \*\*,ä¸€ä¸ªå®Œæ•´çš„è¯çš„éƒ¨åˆ†WordPieceå­è¯è¢«maskï¼Œåˆ™åŒå±è¯¥è¯çš„å…¶ä»–éƒ¨åˆ†ä¹Ÿä¼šè¢«mask

> extè¡¨ç¤ºåœ¨æ›´å¤šæ•°æ®é›†ä¸‹è®­ç»ƒ

\[Back to Top\]

### ChineseBERT

-   2021 | ChineseBERT: Chinese Pretraining Enhanced by Glyph and Pinyin Information | Zijun Sun, et al. | arXiv | `PDF`

æ¨¡å‹

ç‰ˆæœ¬

TensorFlow

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

ChineseBERT

base

\[ğŸ¤—HF\]

ShannonAI

github

é€šç”¨

ChineseBERT

large

\[ğŸ¤—HF\]

ShannonAI

github

é€šç”¨

\[Back to Top\]

### RoBERTa

-   2019 | RoBERTa: A Robustly Optimized BERT Pretraining Approach | Yinhan Liu, et al. | arXiv | `PDF`

æ¨¡å‹

ç‰ˆæœ¬

TensorFlow

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

RoBERTa-tiny-clue

tiny

Google Drive

ç™¾åº¦ç½‘ç›˜-8qvb

CLUE

github

é€šç”¨

RoBERTa-tiny-pair

tiny

google drive

ç™¾åº¦ç½‘ç›˜-8qvb

CLUE

github

é€šç”¨

RoBERTa-tiny3L768-clue

tiny

Google Drive

CLUE

github

é€šç”¨

RoBERTa-tiny3L312-clue

tiny

google drive

ç™¾åº¦ç½‘ç›˜-8qvb

CLUE

github

é€šç”¨

RoBERTa-large-pair

large

Google Drive

ç™¾åº¦ç½‘ç›˜-8qvb

CLUE

github

é€šç”¨

RoBERTa-large-clue

large

google drive

ç™¾åº¦ç½‘ç›˜-8qvb

CLUE

github

é€šç”¨

RBT3

3å±‚base

Google Drive  
è®¯é£äº‘-b9nx

Google Drive

Yiming Cui

github

é€šç”¨

RBTL3

3å±‚large

Google Drive  
è®¯é£äº‘-vySW

Google Drive

Yiming Cui

github

é€šç”¨

RBTL4

4å±‚large

è®¯é£äº‘-e8dN

Yiming Cui

github

é€šç”¨

RBTL6

6å±‚large

è®¯é£äº‘-XNMA

Yiming Cui

github

é€šç”¨

RoBERTa-wwm-ext

base

Google Drive  
è®¯é£äº‘-Xe1p

Google Drive

Yiming Cui

github

é€šç”¨

RoBERTa-wwm-ext-large

large

Google Drive  
è®¯é£äº‘-u6gC

Google Drive

Yiming Cui

github

é€šç”¨

RoBERTa-base

base

Google Drive  
ç™¾åº¦ç½‘ç›˜

Google Drive  
ç™¾åº¦ç½‘ç›˜

brightmart

github

é€šç”¨

RoBERTa-Large

large

Google Drive  
ç™¾åº¦ç½‘ç›˜

Google Drive

brightmart

github

é€šç”¨

RoBERTa-tiny

tiny

\[ğŸ¤—HF\]

\[ğŸ¤—HF\]

DBIIR @ RUC

UER

é€šç”¨

RoBERTa-mini

mini

\[ğŸ¤—HF\]

\[ğŸ¤—HF\]

DBIIR @ RUC

UER

é€šç”¨

RoBERTa-small

small

\[ğŸ¤—HF\]

\[ğŸ¤—HF\]

DBIIR @ RUC

UER

é€šç”¨

RoBERTa-medium

medium

\[ğŸ¤—HF\]

\[ğŸ¤—HF\]

DBIIR @ RUC

UER

é€šç”¨

RoBERTa-base

base

\[ğŸ¤—HF\]

\[ğŸ¤—HF\]

DBIIR @ RUC

UER

é€šç”¨

\[Back to Top\]

### ALBERT

-   2019 | ALBERT: A Lite BERT For Self-Supervised Learning Of Language Representations | Zhenzhong Lan, et al. | arXiv | `PDF`

æ¨¡å‹

ç‰ˆæœ¬

TensorFlow

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

Albert\_tiny

tiny

Google Drive

Google Drive

brightmart

github

é€šç”¨

Albert\_base\_zh

base

Google Drive

Google Drive

brightmart

github

é€šç”¨

Albert\_large\_zh

large

Google Drive

Google Drive

brightmart

github

é€šç”¨

Albert\_xlarge\_zh

xlarge

Google Drive

Google Drive

brightmart

github

é€šç”¨

Albert\_base

base

Google Drive

Google Research

github

é€šç”¨

Albert\_large

large

Google Drive

Google Research

github

é€šç”¨

Albert\_xlarge

xlarge

Google Drive

Google Research

github

é€šç”¨

Albert\_xxlarge

xxlarge

Google Drive

Google Research

github

é€šç”¨

\[Back to Top\]

### NEZHA

-   2019 | NEZHA: Neural Contextualized Representation for Chinese Language Understanding | Junqiu Wei, et al. | arXiv | `PDF`

æ¨¡å‹

ç‰ˆæœ¬

TensorFlow

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

NEZHA-base

base

Google Drive  
ç™¾åº¦ç½‘ç›˜-ntn3

lonePatient

HUAWEI

github

é€šç”¨

NEZHA-base-wwm

base

Google Drive  
ç™¾åº¦ç½‘ç›˜-f68o

lonePatient

HUAWEI

github

é€šç”¨

NEZHA-large

large

Google Drive  
ç™¾åº¦ç½‘ç›˜-7thu

lonePatient

HUAWEI

github

é€šç”¨

NEZHA-large-wwm

large

Google Drive  
ç™¾åº¦ç½‘ç›˜-ni4o

lonePatient

HUAWEI

github

é€šç”¨

WoNEZHA  
(word-base)

base

ç™¾åº¦ç½‘ç›˜-qgkq

ZhuiyiTechnology

github

é€šç”¨

\[Back to Top\]

### MacBERT

-   2020 | Revisiting Pre-Trained Models for Chinese Natural Language Processing | Yiming Cui, et al. | arXiv | `PDF`

æ¨¡å‹

ç‰ˆæœ¬

TensorFlow

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

MacBERT-base

base

Google Drive  
è®¯é£äº‘-E2cP

Yiming Cui

github

é€šç”¨

MacBERT-large

large

Google Drive  
è®¯é£äº‘-3Yg3

Yiming Cui

github

é€šç”¨

\[Back to Top\]

### WoBERT

-   2020 | æé€Ÿä¸æ‰ç‚¹ï¼šåŸºäºè¯é¢—ç²’åº¦çš„ä¸­æ–‡WoBERT | è‹å‰‘æ—. | spaces | `Blog post`

æ¨¡å‹

ç‰ˆæœ¬

TensorFlow

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

WoBERT

base

ç™¾åº¦ç½‘ç›˜-kim2

ZhuiyiTechnology

github

é€šç”¨

WoBERT-plus

base

ç™¾åº¦ç½‘ç›˜-aedw

ZhuiyiTechnology

github

é€šç”¨

\[Back to Top\]

### XLNET

-   2019 | XLNet: Generalized Autoregressive Pretraining for Language Understanding | Zhilin Yang, et al. | arXiv | `PDF`

æ¨¡å‹

ç‰ˆæœ¬

TensorFlow

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

XLNet-base

base

Google Drive  
è®¯é£äº‘-uCpe

Google Drive

Yiming Cui

github

é€šç”¨

XLNet-mid

middle

Google Drive  
è®¯é£äº‘-68En

Google Drive

Yiming Cui

github

é€šç”¨

XLNet\_zh\_Large

large

ç™¾åº¦ç½‘ç›˜

brightmart

github

é€šç”¨

\[Back to Top\]

### ELECTRA

-   2020 | ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators | Kevin Clark, et al. | arXiv | `PDF`

æ¨¡å‹

ç‰ˆæœ¬

TensorFlow

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

ELECTRA-180g-large

large

Google Drive  
è®¯é£äº‘-Yfcy

Yiming Cui

github

é€šç”¨

ELECTRA-180g-small-ex

small

Google Drive  
è®¯é£äº‘-GUdp

Yiming Cui

github

é€šç”¨

ELECTRA-180g-base

base

Google Drive  
è®¯é£äº‘-Xcvm

Yiming Cui

github

é€šç”¨

ELECTRA-180g-small

small

Google Drive  
è®¯é£äº‘-qsHj

Yiming Cui

github

é€šç”¨

legal-ELECTRA-large

large

Google Drive  
è®¯é£äº‘-7f7b

Yiming Cui

github

å¸æ³•é¢†åŸŸ

legal-ELECTRA-base

base

Google Drive  
è®¯é£äº‘-7f7b

Yiming Cui

github

å¸æ³•é¢†åŸŸ

legal-ELECTRA-small

small

Google Drive  
è®¯é£äº‘-7f7b

Yiming Cui

github

å¸æ³•é¢†åŸŸ

ELECTRA-tiny

tiny

Google Drive  
ç™¾åº¦ç½‘ç›˜-rs99

CLUE

github

é€šç”¨

\[Back to Top\]

### ZEN

-   2019 | ZEN: Pre-training Chinese Text Encoder Enhanced by N-gram Representations | Shizhe Diao, et al. | arXiv | `PDF`
-   2021 | ZEN 2.0: Continue Training and Adaption for N-gram Enhanced Text Encoders | Yan Song, et al. | arXiv | `PDF`

æ¨¡å‹

ç‰ˆæœ¬

TensorFlow

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

ZEN-Base

base

Google Drive  
ç™¾åº¦ç½‘ç›˜

Sinovation Ventures AI Institute

github

é€šç”¨

Erlangshen-ZEN2

large

\[ğŸ¤—HF\]

IDEA-CCNL

github

é€šç”¨

\[Back to Top\]

### ERNIE

-   2019 | ERNIE: Enhanced Representation through Knowledge Integration | Yu Sun, et al. | arXiv | `PDF`
    
-   2020 | SKEP: Sentiment Knowledge Enhanced Pre-training for Sentiment Analysis | Hao Tian, et al. | arXiv | `PDF`
    
-   2020 | ERNIE-Gram: Pre-Training with Explicitly N-Gram Masked Language Modeling for Natural Language Understanding | Dongling Xiao, et al. | arXiv | `PDF`
    

æ¨¡å‹

ç‰ˆæœ¬

PaddlePaddle

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

ernie-1.0-base

base

link

PaddlePaddle

github

é€šç”¨

ernie\_1.0\_skep\_large

large

link

Baidu

github

æƒ…æ„Ÿåˆ†æ

ernie-gram

base

link

Baidu

github

é€šç”¨

å¤‡æ³¨:

> PaddlePaddleè½¬TensorFlowå¯å‚è€ƒ: tensorflow\_ernie

> PaddlePaddleè½¬PyTorchå¯å‚è€ƒ: ERNIE-Pytorch

\[Back to Top\]

### ERNIE3

-   2021 | ERNIE 3.0: Large-scale Knowledge Enhanced Pre-training for Language Understanding and Generation | Yu Sun, et al. | arXiv | `PDF`
    
-   2021 | ERNIE 3.0 Titan: Exploring Larger-scale Knowledge Enhanced Pre-training for Language Understanding and Generation | Shuohuan Wang, et al. | arXiv | `PDF`
    

æ¨¡å‹

ç‰ˆæœ¬

PaddlePaddle

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

ernie-3.0-base

12-layer, 768-hidden, 12-heads

link

\[ğŸ¤—HF\]

PaddlePaddle

github

é€šç”¨

ernie-3.0-medium

6-layer, 768-hidden, 12-heads

link

\[ğŸ¤—HF\]

PaddlePaddle

github

é€šç”¨

ernie-3.0-mini

6-layer, 384-hidden, 12-heads

link

\[ğŸ¤—HF\]

PaddlePaddle

github

é€šç”¨

ernie-3.0-micro

4-layer, 384-hidden, 12-heads

link

\[ğŸ¤—HF\]

PaddlePaddle

github

é€šç”¨

ernie-3.0-nano

4-layer, 312-hidden, 12-heads

link

\[ğŸ¤—HF\]

PaddlePaddle

github

é€šç”¨

> PaddlePaddleè½¬PyTorchå¯å‚è€ƒ: ERNIE-Pytorch

\[Back to Top\]

### RoFormer

-   2021 | RoFormer: Enhanced Transformer with Rotary Position Embedding | Jianlin Su, et al. | arXiv | `PDF`
    
-   2021 | Transformerå‡çº§ä¹‹è·¯ï¼š2ã€åšé‡‡ä¼—é•¿çš„æ—‹è½¬å¼ä½ç½®ç¼–ç  | è‹å‰‘æ—. | spaces | `Blog post`
    

æ¨¡å‹

ç‰ˆæœ¬

TensorFlow

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

roformer

base(L12)

ç™¾åº¦ç½‘ç›˜-xy9x

ZhuiyiTechnology

github

é€šç”¨

roformer

small(L6)

ç™¾åº¦ç½‘ç›˜-gy97

ZhuiyiTechnology

github

é€šç”¨

roformer-char

base(L12)

ç™¾åº¦ç½‘ç›˜-bt94

ZhuiyiTechnology

github

é€šç”¨

roformerV2

small(L6)

ç™¾åº¦ç½‘ç›˜-ttn4è¿½ä¸€

ZhuiyiTechnology

github

é€šç”¨

roformerV2

base(L12)

ç™¾åº¦ç½‘ç›˜-pfohè¿½ä¸€

ZhuiyiTechnology

github

é€šç”¨

roformerV2

large(L24)

ç™¾åº¦ç½‘ç›˜-npfvè¿½ä¸€

ZhuiyiTechnology

github

é€šç”¨

\[Back to Top\]

### StructBERT

-   2019 | StructBERT: Incorporating Language Structures into Pre-training for Deep Language Understanding | Wei Wang, et al. | arXiv | `PDF`

æ¨¡å‹

ç‰ˆæœ¬

TensorFlow

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

StructBERT

large(L24)

é˜¿é‡Œäº‘

Alibaba

github

é€šç”¨

\[Back to Top\]

### Lattice-BERT

-   2021 | Lattice-BERT: Leveraging Multi-Granularity Representations in Chinese Pre-trained Language Models | Yuxuan Lai, et al. | arXiv | `PDF`

æ¨¡å‹

ç‰ˆæœ¬

TensorFlow

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

LatticeBERT

tiny(L4)

é˜¿é‡Œäº‘

Alibaba

github

é€šç”¨

LatticeBERT

small(L6)

é˜¿é‡Œäº‘

Alibaba

github

é€šç”¨

LatticeBERT

base(L12)

é˜¿é‡Œäº‘

Alibaba

github

é€šç”¨

\[Back to Top\]

### Mengzi-BERT

-   2021 | Mengzi: Towards Lightweight yet Ingenious Pre-trained Models for Chinese | Zhuosheng Zhang, et al. | arXiv | `PDF`

æ¨¡å‹

ç‰ˆæœ¬

TensorFlow

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

Mengzi-BERT

base(L12)

\[ğŸ¤—HF\]

Langboat

github

é€šç”¨

Mengzi-BERT-fin

base(L12)

\[ğŸ¤—HF\]

Langboat

github

é‡‘èè´¢ç»

\[Back to Top\]

### Bloom

-   2022 | Bloom: BigScience Large Open-science Open-access Multilingual Language Model | huggingface bigscience | - | `BLOG`

æ¨¡å‹

ç‰ˆæœ¬

TensorFlow

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

bloom-6b4-zh

6B(L30)

\[ğŸ¤—HF\]

Langboat

github

é€šç”¨

> æ³¨ï¼šä½œè€…å¦æœ‰bloom-389m-zhåˆ°bloom-2b5-zhç­‰å¤šä¸ªä¸­æ–‡æ¨¡å‹

\[Back to Top\]

### TaCL

-   2021 | TaCL: Improving BERT Pre-training with Token-aware Contrastive Learning | Yixuan Su, et al. | arXiv | `PDF`

æ¨¡å‹

ç‰ˆæœ¬

TensorFlow

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

TaCL

base(L12)

\[ğŸ¤—HF\]

yxuansu

github

é€šç”¨

\[Back to Top\]

### MC-BERT

-   2021 | MC-BERT: Conceptualized Representation Learning for Chinese Biomedical Text Mining | alibaba-research | arXiv | `PDF`

æ¨¡å‹

ç‰ˆæœ¬

TensorFlow

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

MC-BERT

base(L12)

link

alibaba-research

github

ç”Ÿç‰©åŒ»ç–—

\[Back to Top\]

### äºŒéƒç¥

æ¨¡å‹

ç‰ˆæœ¬

ç±»å‹

TensorFlow

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

Erlangshen

large(L24)

bert

\[ğŸ¤—HF\]

IDEA-CCNL

github

ä¸­æ–‡é€šç”¨

\[Back to Top\]

### PERT

-   2022 | PERT: Pre-Training BERT with Permuted Language Model | Yiming Cui, et al. | arXiv | `PDF`

æ¨¡å‹

ç‰ˆæœ¬

TensorFlow

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

PERT-base

base(12L)

ç™¾åº¦ç½‘ç›˜-rcsw

\[ğŸ¤—HF\]

Yiming Cui

github

é€šç”¨

PERT-large

large(24L)

ç™¾åº¦ç½‘ç›˜-e9hs

\[ğŸ¤—HF\]

Yiming Cui

github

é€šç”¨

\[Back to Top\]

### MobileBERT

-   2020 | MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices | Zhiqing Sun, et al. | arXiv | `PDF`

æ¨¡å‹

ç‰ˆæœ¬

TensorFlow

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

Chinese-MobileBERT-base-f2

base

ç™¾åº¦ç½‘ç›˜-56bj

Yiming Cui

github

é€šç”¨

Chinese-MobileBERT-base-f4

base

ç™¾åº¦ç½‘ç›˜-v2v7

Yiming Cui

github

é€šç”¨

Chinese-MobileBERT-large-f2

large

ç™¾åº¦ç½‘ç›˜-6m5a

Yiming Cui

github

é€šç”¨

Chinese-MobileBERT-large-f4

large

ç™¾åº¦ç½‘ç›˜-3h9b

Yiming Cui

github

é€šç”¨

\[Back to Top\]

### GAU-Î±

-   2022 | GAU-Î±: (FLASH) Transformer Quality in Linear Time | Weizhe Hua, et al. | arXiv | `PDF` | `blog`

æ¨¡å‹

ç‰ˆæœ¬

TensorFlow

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

chinese\_GAU-alpha-char\_L-24\_H-768

base

ä¸‹è½½

ZhuiyiTechnology

github

é€šç”¨

\[Back to Top\]

### DeBERTa

-   2020 | DeBERTa: Decoding-enhanced BERT with Disentangled Attention | Pengcheng He, et al. | arXiv | `PDF` |

æ¨¡å‹

ç‰ˆæœ¬

TensorFlow

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

DeBERTa-v2-Large

large

\[ğŸ¤—HF\]

IDEA-CCNL

github

é€šç”¨

DeBERTa-v2-xLarge

xlarge

\[ğŸ¤—HF\]

IDEA-CCNL

github

é€šç”¨

DeBERTa-v2

base

\[ğŸ¤—HF\]

IDEA-CCNL

github

é€šç”¨

\[Back to Top\]

### GlyphBERT

-   2021 | GlyphCRM: Bidirectional Encoder Representation for Chinese Character with its Glyph | Yuxin li, et al. | arXiv | `PDF` |

æ¨¡å‹

ç‰ˆæœ¬

TensorFlow

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

GlyphCRM-base

base

\[ğŸ¤—HF\]

HITsz-TMG

github

é€šç”¨

\[Back to Top\]

### CKBERT

-   2022 | Revisiting and Advancing Chinese Natural Language Understanding with Accelerated Heterogeneous Knowledge Pre-training | Zhang, Taolin, et al. | arXiv | `PDF`

æ¨¡å‹

ç‰ˆæœ¬

TensorFlow

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

pai-ckbert-base-zh

base

\[ğŸ¤—HF\]

Alibaba

github

é€šç”¨

pai-ckbert-large-zh

large

\[ğŸ¤—HF\]

Alibaba

github

é€šç”¨

pai-ckbert-huge-zh

huge

\[ğŸ¤—HF\]

Alibaba

github

é€šç”¨

\[Back to Top\]

### LERT

-   2022 | LERT: A Linguistically-motivated Pre-trained Language Model | Yiming Cui et al. | arXiv | `PDF`

æ¨¡å‹

ç‰ˆæœ¬

TensorFlow

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

Chinese-LERT-small

15m

ç™¾åº¦ç½‘ç›˜-4vuy

\[ğŸ¤—HF\]

Yiming Cui

github

é€šç”¨

Chinese-LERT-base

400m

ç™¾åº¦ç½‘ç›˜-9jgi

\[ğŸ¤—HF\]

Yiming Cui

github

é€šç”¨

Chinese-LERT-large

1.2G

ç™¾åº¦ç½‘ç›˜-s82t

\[ğŸ¤—HF\]

Yiming Cui

github

é€šç”¨

\[Back to Top\]

### RoCBert

-   2022 | RoCBert: Robust Chinese Bert with Multimodal Contrastive Pretraining | Hui Su et al. | ACL | `PDF`

æ¨¡å‹

ç‰ˆæœ¬

TensorFlow

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

rocbert

base

\[ğŸ¤—HF\]

Weiwe Shi

github

é€šç”¨

\[Back to Top\]

### M3E

æ¨¡å‹

ç‰ˆæœ¬

PyTorch

ä½œè€…

æºåœ°å€

å¤‡æ³¨

m3e-base

base

m3e-base

Moka-AI

uniem

æ–‡æœ¬åµŒå…¥æ¨¡å‹

M3e-small

Small

m3e-small

Moka-AI

uniem

æ–‡æœ¬åµŒå…¥æ¨¡å‹

\[Back to Top\]

### LEALLA

-   2023 | LEALLA: Learning Lightweight Language-agnostic Sentence Embeddings with Knowledge Distillation | Zhuoyuan Mao et al. | EACL | `PDF`

æ¨¡å‹

ç‰ˆæœ¬

PyTorch

ä½œè€…

æºåœ°å€

å¤‡æ³¨

LEALLA-base

base

LEALLA-base

Google Research

/

æ–‡æœ¬åµŒå…¥æ¨¡å‹

LEALLA-large

large

LEALLA-large

Google Research

/

æ–‡æœ¬åµŒå…¥æ¨¡å‹

\[Back to Top\]

NLGç³»åˆ—
-----

### GPT

-   2019 | Improving Language Understandingby Generative Pre-Training | Alec Radford, et al. | arXiv | `PDF`
    
-   2019 | Language Models are Unsupervised Multitask Learners | Alec Radford, et al. | arXiv | `PDF`
    

æ¨¡å‹

ç‰ˆæœ¬

TensorFlow

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

GPT2

30äº¿è¯­æ–™

Google Drive  
ç™¾åº¦ç½‘ç›˜-ffz6

Caspar ZHANG

gpt2-ml

é€šç”¨

GPT2

15äº¿è¯­æ–™

Google Drive  
ç™¾åº¦ç½‘ç›˜-q9vr

Caspar ZHANG

gpt2-ml

é€šç”¨

CDial-GPTLCCC-base

base

\[ğŸ¤—HF\]

thu-coai

CDial-GPT

ä¸­æ–‡å¯¹è¯

CDial-GPT2LCCC-base

base

\[ğŸ¤—HF\]

thu-coai

CDial-GPT

ä¸­æ–‡å¯¹è¯

CDial-GPTLCCC-large

large

\[ğŸ¤—HF\]

thu-coai

CDial-GPT

ä¸­æ–‡å¯¹è¯

GPT2-dialogue

base

Google Drive  
ç™¾åº¦ç½‘ç›˜-osi6

yangjianxin1

GPT2-chitchat

é—²èŠå¯¹è¯

GPT2-mmi

base

Google Drive  
ç™¾åº¦ç½‘ç›˜-1j88

yangjianxin1

GPT2-chitchat

é—²èŠå¯¹è¯

GPT2-æ•£æ–‡æ¨¡å‹

base

Google Drive  
ç™¾åº¦ç½‘ç›˜-fpyu

Zeyao Du

GPT2-Chinese

æ•£æ–‡

GPT2-è¯—è¯æ¨¡å‹

base

Google Drive  
ç™¾åº¦ç½‘ç›˜-7fev

Zeyao Du

GPT2-Chinese

è¯—è¯

GPT2-å¯¹è”æ¨¡å‹

base

Google Drive  
ç™¾åº¦ç½‘ç›˜-i5n0

Zeyao Du

GPT2-Chinese

å¯¹è”

roformer-gpt

base(L12)

ç™¾åº¦ç½‘ç›˜-2nnn

ZhuiyiTechnology

github

é€šç”¨

\[Back to Top\]

### GPT-3

-   2019 | Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context | Zihang Dai, et al. | arXiv | `PDF`
    
-   2020 | Language Models are Few-Shot Learners | Tom B. Brown, et al. | arXiv | `PDF`
    

æ¨¡å‹

ç‰ˆæœ¬

ä»‹ç»

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

Chinese-Transformer-XL

29äº¿å‚æ•°(GPT-3)

é¡¹ç›®é¦–é¡µ

æ¨¡å‹ä¸‹è½½

THUDM

github

é€šç”¨

\[Back to Top\]

### NEZHA-Gen

-   2019 | NEZHA: Neural Contextualized Representation for Chinese Language Understanding | Junqiu Wei, et al. | arXiv | `PDF`
    
-   2019 | Improving Language Understandingby Generative Pre-Training | Alec Radford, et al. | arXiv | `PDF`
    

æ¨¡å‹

ç‰ˆæœ¬

TensorFlow

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

NEZHA-Gen

base

Google Drive  
ç™¾åº¦ç½‘ç›˜-rb5m

HUAWEI

github

é€šç”¨

NEZHA-Gen

base

Google Drive  
ç™¾åº¦ç½‘ç›˜-ytim

HUAWEI

github

è¯—æ­Œ

\[Back to Top\]

### CPM-Generate

-   2020 | CPM: A Large-scale Generative Chinese Pre-trained Language Model | Zhengyan Zhang, et al. | arXiv | `PDF`

æ¨¡å‹

ç‰ˆæœ¬

èµ„æº

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

CPM

26äº¿å‚æ•°

é¡¹ç›®é¦–é¡µ

æ¨¡å‹ä¸‹è½½

Tsinghua AI

github

é€šç”¨

å¤‡æ³¨:

> PyTorchè½¬TensorFlowå¯å‚è€ƒ: CPM-LM-TF2

> PyTorchè½¬PaddlePaddleå¯å‚è€ƒ: CPM-Generate-Paddle

\[Back to Top\]

### T5

-   2019 | Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer | Colin Raffel, et al. | arXiv | `PDF`

æ¨¡å‹

ç‰ˆæœ¬

TensorFlow

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

T5

small

\[ğŸ¤—HF\]

\[ğŸ¤—HF\]

DBIIR @ RUC

UER

é€šç”¨

\[Back to Top\]

### T5-PEGASUS

-   2019 | Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer | Colin Raffel, et al. | arXiv | `PDF`
    
-   2019 | PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization | Jingqing Zhang, et al. | arXiv | `PDF`
    
-   2021 | T5 PEGASUSï¼šå¼€æºä¸€ä¸ªä¸­æ–‡ç”Ÿæˆå¼é¢„è®­ç»ƒæ¨¡å‹ | è‹å‰‘æ—. | spaces | `Blog post`
    

æ¨¡å‹

ç‰ˆæœ¬

Keras

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

T5 PEGASUS

base

ç™¾åº¦ç½‘ç›˜-3sfn

ZhuiyiTechnology

github

é€šç”¨

T5 PEGASUS

small

ç™¾åº¦ç½‘ç›˜-qguk

ZhuiyiTechnology

github

é€šç”¨

> Kerasè½¬PyTorchå¯å‚è€ƒ: t5-pegasus-pytorch

\[Back to Top\]

### Mengzi-T5

-   2021 | Mengzi: Towards Lightweight yet Ingenious Pre-trained Models for Chinese | Zhuosheng Zhang, et al. | arXiv | `PDF`

æ¨¡å‹

ç‰ˆæœ¬

TensorFlow

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

Mengzi-T5

base(L12)

\[ğŸ¤—HF\]

Langboat

github

é€šç”¨

\[Back to Top\]

### PanGu-Alpha

-   2021 | PanGu-Î±: Large-scale Autoregressive Pretrained Chinese Language Models with Auto-parallel Computation | Wei Zeng, et al. | arXiv | `PDF`

æ¨¡å‹

ç‰ˆæœ¬

èµ„æº

ä¸‹è½½åœ°å€

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

ç›˜å¤Î±-2.6B

2.6G

é¡¹ç›®é¦–é¡µ

æ¨¡å‹ä¸‹è½½

PCL-Platform.Intelligence

github

é€šç”¨

ç›˜å¤Î±-13B

12G

é¡¹ç›®é¦–é¡µ

æ¨¡å‹ä¸‹è½½

PCL-Platform.Intelligence

github

é€šç”¨

ç›˜å¤Î±-2.6B pytorchç‰ˆæœ¬

2.6G

é¡¹ç›®é¦–é¡µ

æ¨¡å‹ä¸‹è½½

PCL-Platform.Intelligence

github

é€šç”¨

ç›˜å¤Î±-13B pytorchç‰ˆæœ¬

12G

é¡¹ç›®é¦–é¡µ

æ¨¡å‹ä¸‹è½½

PCL-Platform.Intelligence

github

é€šç”¨

\[Back to Top\]

### EVA

-   2021 | EVA: An Open-Domain Chinese Dialogue System with Large-Scale Generative Pre-Training | Hao Zhou, et al. | arXiv | `PDF`

æ¨¡å‹

ç‰ˆæœ¬

ä»‹ç»

æ¨¡å‹ä¸‹è½½

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

å¤‡æ³¨

EVA

28äº¿å‚æ•°

é¡¹ç›®é¦–é¡µ

æ¨¡å‹ä¸‹è½½

thu-coai

github

ä¸­æ–‡å¼€æ”¾åŸŸå¯¹è¯

éœ€è¦ç™»é™†æ‰èƒ½ä¸‹è½½

EVA2.0-xLarge

xlarge

é¡¹ç›®é¦–é¡µ

\[ğŸ¤—HF\]

thu-coai

github

ä¸­æ–‡å¼€æ”¾åŸŸå¯¹è¯

EVA2.0-large

large

é¡¹ç›®é¦–é¡µ

\[ğŸ¤—HF\]

thu-coai

github

ä¸­æ–‡å¼€æ”¾åŸŸå¯¹è¯

EVA2.0-base

base

é¡¹ç›®é¦–é¡µ

\[ğŸ¤—HF\]

thu-coai

github

ä¸­æ–‡å¼€æ”¾åŸŸå¯¹è¯

\[Back to Top\]

\-

### BART

-   2019 | BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension | Mike Lewis, et al. | arxiv | `PDF`

æ¨¡å‹

ç‰ˆæœ¬

TensorFlow

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

BART-base

base

\[ğŸ¤—HF\]

fastNLP

github

ä¸­æ–‡é€šç”¨

BART-large

large

\[ğŸ¤—HF\]

fastNLP

github

ä¸­æ–‡é€šç”¨

\[Back to Top\]

### é—»ä»²

æ¨¡å‹

ç‰ˆæœ¬

ç±»å‹

TensorFlow

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

Wenzhong

large(L24)

GPT2

\[ğŸ¤—HF\]

IDEA-CCNL

github

ä¸­æ–‡é€šç”¨

\[Back to Top\]

### ä½™å…ƒ

æ¨¡å‹

ç‰ˆæœ¬

ç±»å‹

TensorFlow

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

Yuyuan

large(L24)

GPT2

\[ğŸ¤—HF\]

IDEA-CCNL

github

åŒ»å­¦é¢†åŸŸ

\[Back to Top\]

### RWKV

-   2021 | An Attention Free Transformer | Shuangfei Zhai, et al. | arxiv | `PDF`
-   2022 | The RWKV Language Model . | github

æ¨¡å‹

ç‰ˆæœ¬

ç±»å‹

TensorFlow

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

RWKV

base(L12)

github

PENG Bo

github

å°è¯´

RWKV

7B

\[ğŸ¤—HF\]

PENG Bo

github

å°è¯´

RWKV

14B

\[ğŸ¤—HF\]

PENG Bo

github

å°è¯´

\[Back to Top\]

### PromptCLUE

æ¨¡å‹

ç‰ˆæœ¬

TensorFlow

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

PromptCLUE

base(L12)

\[ğŸ¤—HF\]

ClueAI

github

é€šç”¨

PromptCLUE-v1-5

base(L12)

\[ğŸ¤—HF\]

ClueAI

github

é€šç”¨

PromptCLUE-large

large

APIåœ¨çº¿è°ƒç”¨

ClueAI

github

é€šç”¨

\[Back to Top\]

### ChatYuan

æ¨¡å‹

ç‰ˆæœ¬

ç±»å‹

TensorFlow

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

ChatYuan

large

T5

\[ğŸ¤—HF\]

ClueAI

github

åŠŸèƒ½å‹å¯¹è¯

ChatYuan-large-v2

large

T5

\[ğŸ¤—HF\]

ClueAI

github

åŠŸèƒ½å‹å¯¹è¯

\[Back to Top\]

### SkyText

æ¨¡å‹

ç‰ˆæœ¬

ç±»å‹

TensorFlow

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

SkyText

large

GPT3

\[ğŸ¤—HF\]

SkyWorkAIGC

github

é€šç”¨

\[Back to Top\]

### ProphetNet

-   2020 | Prophetnet: Predicting future n-gram for sequence-to-sequence pre-training | Qi, Weizhen, et al. | arxiv | `PDF`
-   2021 | ProphetNet-X: Large-Scale Pre-training Models for English, Chinese, Multi-lingual, Dialog, and Code Generation | Qi, Weizhen, et al. | arxiv | `PDF`

æ¨¡å‹

ç‰ˆæœ¬

ç±»å‹

TensorFlow

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

ProphetNet-Zh

link

microsoft

github

é€šç”¨

ProphetNet-Dialog-Zh

link

microsoft

github

å¯¹è¯

\[Back to Top\]

NLU-NLGç³»åˆ—
---------

### UniLM

-   2019 | Unified Language Model Pre-training for Natural Language Understanding and Generation | Li Dong, et al. | arXiv | `PDF`

æ¨¡å‹

ç‰ˆæœ¬

TensorFlow

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

Unilm

base

ç™¾åº¦ç½‘ç›˜-tblr

ç™¾åº¦ç½‘ç›˜-etwf

YunwenTechnology

github

é€šç”¨

\[Back to Top\]

### Simbert

-   2020 | é±¼ä¸ç†ŠæŒå…¼å¾—ï¼šèåˆæ£€ç´¢å’Œç”Ÿæˆçš„SimBERTæ¨¡å‹ | è‹å‰‘æ—. | spaces | `Blog post`

æ¨¡å‹

ç‰ˆæœ¬

TensorFlow

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

SimBERT Tiny

tiny

ç™¾åº¦ç½‘ç›˜-1tp7

ZhuiyiTechnology

github

é€šç”¨

SimBERT Small

small

ç™¾åº¦ç½‘ç›˜-nu67

ZhuiyiTechnology

github

é€šç”¨

SimBERT Base

base

ç™¾åº¦ç½‘ç›˜-6xhq

ZhuiyiTechnology

github

é€šç”¨

\[Back to Top\]

### RoFormer-sim

-   2021 | SimBERTv2æ¥äº†ï¼èåˆæ£€ç´¢å’Œç”Ÿæˆçš„RoFormer-Simæ¨¡å‹ | è‹å‰‘æ—. | spaces | `Blog post`

æ¨¡å‹

ç‰ˆæœ¬

TensorFlow

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

roformer-sim

base(L12)

ç™¾åº¦ç½‘ç›˜-2cgz

ZhuiyiTechnology

github

é€šç”¨

roformer-sim

small(L6)

ç™¾åº¦ç½‘ç›˜-h68q

ZhuiyiTechnology

github

é€šç”¨

roformer-sim-v2

base(L12)

ç™¾åº¦ç½‘ç›˜-w15n

ZhuiyiTechnology

github

é€šç”¨

\[Back to Top\]

### å‘¨æ–‡ç‹

æ¨¡å‹

ç‰ˆæœ¬

ç±»å‹

TensorFlow

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

Zhouwenwang

base(L12)

roformer

\[ğŸ¤—HF\]

IDEA-CCNL

github

ä¸­æ–‡é€šç”¨

Zhouwenwang

large(L24)

roformer

\[ğŸ¤—HF\]

IDEA-CCNL

github

ä¸­æ–‡é€šç”¨

\[Back to Top\]

### CPM-2

-   2021 | CPM-2: Large-scale Cost-effective Pre-trained Language Models | Zhengyan Zhang, et al. | arXiv | `PDF`

æ¨¡å‹

ç‰ˆæœ¬

ä»‹ç»

æ¨¡å‹ä¸‹è½½

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

å¤‡æ³¨

CPM-2

110äº¿å‚æ•°

é¡¹ç›®é¦–é¡µ

æ¨¡å‹ä¸‹è½½

BAAI-WuDao

github

é€šç”¨

éœ€è¦ç”³è¯·æ‰èƒ½ä¸‹è½½

CPM-2

100äº¿å‚æ•°

é¡¹ç›®é¦–é¡µ

æ¨¡å‹ä¸‹è½½

BAAI-WuDao

github

ä¸­è‹±

éœ€è¦ç”³è¯·æ‰èƒ½ä¸‹è½½

CPM-2

1980äº¿å‚æ•°

é¡¹ç›®é¦–é¡µ

æ¨¡å‹ä¸‹è½½

BAAI-WuDao

github

ä¸­è‹±

éœ€è¦ç”³è¯·æ‰èƒ½ä¸‹è½½

\[Back to Top\]

### CPT

-   2021 | CPT: A Pre-Trained Unbalanced Transformer for Both Chinese Language Understanding and Generation | Yunfan Shao, et al. | arxiv | `PDF`

æ¨¡å‹

ç‰ˆæœ¬

TensorFlow

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

CPT-base

base(L12)

\[ğŸ¤—HF\]

fastNLP

github

é€šç”¨

CPT-large

large(L24)

\[ğŸ¤—HF\]

fastNLP

github

é€šç”¨

\[Back to Top\]

### GLM

-   2022 | GLM: General Language Model Pretraining with Autoregressive Blank Infilling | Zhengxiao Du, et al. | arXiv | `PDF`
-   2022 | GLM-130B: An Open Bilingual Pre-trained Model | Aohan Zeng, et al. | arXiv | `PDF`

æ¨¡å‹

ç‰ˆæœ¬

TensorFlow

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

GLM

large

\[ğŸ¤—HF\]

THUDM

github

é€šç”¨

GLM

xxlarge

\[ğŸ¤—HF\]

THUDM

github

é€šç”¨

GLM-130B

130B

ç”³è¯·åœ°å€1ç”³è¯·åœ°å€2

THUDM

github

é€šç”¨

\[Back to Top\]

### PLUG

-   2019 | StructBERT: Incorporating Language Structures into Pre-training for Deep Language Understanding | Wei Wang, et al. | arXiv | `PDF`
-   2020 | PALM: Pre-training an Autoencoding&Autoregressive Language Model for Context-conditioned Generation | Bin Bi, et al. | ACL| `PDF`

æ¨¡å‹

ç‰ˆæœ¬

æ¨¡å‹ä¸‹è½½

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

PLUG

27B

AliceMind-éœ€è¦ç”³è¯·

Alibaba

github

é€šç”¨

\[Back to Top\]

### OPD

-   2022 | å¾…å®š | , et al. | arXiv | `PDF`

æ¨¡å‹

ç‰ˆæœ¬

ä»‹ç»

æ¨¡å‹ä¸‹è½½

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

å¤‡æ³¨

OPD

6.3B

é¡¹ç›®é¦–é¡µ

æ¨¡å‹ä¸‹è½½

thu-coai

github

ä¸­æ–‡å¼€æ”¾åŸŸå¯¹è¯

éœ€è¦ç”³è¯·æ‰èƒ½ä¸‹è½½

\[Back to Top\]

Multi-Modal
-----------

### WenLan

-   2021 | WenLan: Bridging Vision and Language by Large-Scale Multi-Modal Pre-Training | Yuqi Huo, et al. | arXiv | `PDF`

æ¨¡å‹

ç‰ˆæœ¬

ä»‹ç»

æ¨¡å‹ä¸‹è½½

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

å¤‡æ³¨

BriVL(WenLan)

10äº¿å‚æ•°

é¡¹ç›®é¦–é¡µ

æ¨¡å‹ä¸‹è½½

BAAI-WuDao

github

ä¸­æ–‡é€šç”¨å›¾æ–‡

éœ€è¦ç™»é™†æ‰èƒ½ä¸‹è½½

\[Back to Top\]

### CogView

-   2021 | CogView: Mastering Text-to-Image Generation via Transformers | Ming Ding, et al. | arXiv | `PDF`

æ¨¡å‹

ç‰ˆæœ¬

ä»‹ç»

æ¨¡å‹ä¸‹è½½

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

å¤‡æ³¨

CogView

40äº¿å‚æ•°

é¡¹ç›®é¦–é¡µ

æ¨¡å‹ä¸‹è½½

THUDM

github

ä¸­æ–‡å¤šæ¨¡æ€ç”Ÿæˆæ¨¡å‹

éœ€è¦ç™»é™†æ‰èƒ½ä¸‹è½½

\[Back to Top\]

### ç´«ä¸œå¤ªåˆ

æ¨¡å‹

ç‰ˆæœ¬

ä»‹ç»

æ¨¡å‹ä¸‹è½½

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

å¤‡æ³¨

ç´«ä¸œå¤ªåˆ- light\_vision\_text

é¡¹ç›®é¦–é¡µ

æ¨¡å‹ä¸‹è½½

ä¸­ç§‘é™¢è‡ªåŠ¨åŒ–æ‰€

github

ä¸­æ–‡å›¾åƒ-æ–‡æœ¬é¢†åŸŸ

ç´«ä¸œå¤ªåˆå¤šæ¨¡æ€å¤§æ¨¡å‹ä¸­çš„å›¾åƒ-æ–‡æœ¬é¢„è®­ç»ƒæ¨¡å‹

ç´«ä¸œå¤ªåˆ-text\[GPT\]

32äº¿å‚æ•°

é¡¹ç›®é¦–é¡µ

ç™¾åº¦ç½‘ç›˜-nos5

ä¸­ç§‘é™¢è‡ªåŠ¨åŒ–æ‰€

github

ä¸­æ–‡é€šç”¨

ç´«ä¸œå¤ªåˆå¤šæ¨¡æ€å¤§æ¨¡å‹ä¸­çš„æ–‡æœ¬é¢„è®­ç»ƒæ¨¡å‹

ç´«ä¸œå¤ªåˆ-vision

é¡¹ç›®é¦–é¡µ

æ¨¡å‹ä¸‹è½½

ä¸­ç§‘é™¢è‡ªåŠ¨åŒ–æ‰€

github

è§†è§‰é¢†åŸŸ

ç´«ä¸œå¤ªåˆå¤šæ¨¡æ€å¤§æ¨¡å‹ä¸­çš„è§†è§‰é¢„è®­ç»ƒæ¨¡å‹

ç´«ä¸œå¤ªåˆ-speech

é¡¹ç›®é¦–é¡µ

æ¨¡å‹ä¸‹è½½

ä¸­ç§‘é™¢è‡ªåŠ¨åŒ–æ‰€

github

è¯­éŸ³é¢†åŸŸ

ç´«ä¸œå¤ªåˆå¤šæ¨¡æ€å¤§æ¨¡å‹ä¸­çš„è¯­éŸ³æ£€æµ‹ä¸è¯†åˆ«å¤šä»»åŠ¡æ¨¡å‹

\[Back to Top\]

### Mengzi-oscar

-   2021 | Mengzi: Towards Lightweight yet Ingenious Pre-trained Models for Chinese | Zhuosheng Zhang, et al. | arXiv | `PDF`

æ¨¡å‹

ç‰ˆæœ¬

TensorFlow

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

Mengzi-oscar

base(L12)

\[ğŸ¤—HF\]

Langboat

github

ä¸­æ–‡å¤šæ¨¡æ€-å›¾æ–‡

\[Back to Top\]

### R2D2

-   2022 | Zero and R2D2: A Large-scale Chinese Cross-modal Benchmark and A Vision-Language Framework | Chunyu Xie, et al. | arXiv | `PDF`

æ¨¡å‹

ç‰ˆæœ¬

TensorFlow

PyTorch

ä½œè€…

æºåœ°å€

é¦–é¡µ

åº”ç”¨é¢†åŸŸ

R2D2ViT-L

large

Google

yuxie11

github

zero

ä¸­æ–‡å¤šæ¨¡æ€-å›¾æ–‡

PRD2ViT-L

large

Google

yuxie11

github

zero

ä¸­æ–‡å¤šæ¨¡æ€-å›¾æ–‡

\[Back to Top\]

### Chinese-CLIP

-   2021 | Learning Transferable Visual Models From Natural Language Supervision | Alec Radford, et al. | arXiv | `PDF`
-   2022 | Chinese CLIP: Contrastive Vision-Language Pretraining in Chinese | An Yang, et al. | arXiv | `PDF`

æ¨¡å‹

ç‰ˆæœ¬

TensorFlow

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

CN-CLIPRN50

77M

aliyuncs

OFA-Sys

github

ä¸­æ–‡å¤šæ¨¡æ€-å›¾æ–‡

CN-CLIPViT-B/16

188M

aliyuncs

OFA-Sys

github

ä¸­æ–‡å¤šæ¨¡æ€-å›¾æ–‡

CN-CLIPViT-L/14

406M

aliyuncs

OFA-Sys

github

ä¸­æ–‡å¤šæ¨¡æ€-å›¾æ–‡

CN-CLIPViT-L/14@336px

407M

aliyuncs

OFA-Sys

github

ä¸­æ–‡å¤šæ¨¡æ€-å›¾æ–‡

CN-CLIPViT-H/14

958M

aliyuncs

OFA-Sys

github

ä¸­æ–‡å¤šæ¨¡æ€-å›¾æ–‡

\[Back to Top\]

### TaiYi-CLIP

-   2021 | Learning Transferable Visual Models From Natural Language Supervision | Alec Radford, et al. | arXiv | `PDF`
-   2022 | Fengshenbang 1.0: Being the Foundation of Chinese Cognitive Intelligence | Junjie Wang, et al. | arXiv | `PDF`

æ¨¡å‹

ç‰ˆæœ¬

TensorFlow

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

Taiyi-CLIP-Roberta-large-326M-Chinese

base

\[ğŸ¤—HF\]

IDEA-CCNL

github

ä¸­æ–‡å¤šæ¨¡æ€-å›¾æ–‡

\[Back to Top\]

### AltCLIP

-   2022 | AltCLIP: Altering the Language Encoder in CLIP for Extended Language Capabilities | Chen, Zhongzhi, et al. | arXiv | `PDF`

æ¨¡å‹

ç‰ˆæœ¬

TensorFlow

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

AltCLIP

3.22G

\[ğŸ¤—HF\]

FlagAI

github

ä¸­æ–‡å¤šæ¨¡æ€-å›¾æ–‡

\[Back to Top\]

### AltDiffusion

-   2022 | AltCLIP: Altering the Language Encoder in CLIP for Extended Language Capabilities | Chen, Zhongzhi, et al. | arXiv | `PDF`
-   2022 | High-Resolution Image Synthesis With Latent Diffusion Models | Rombach, et al. | arXiv | `PDF`

æ¨¡å‹

ç‰ˆæœ¬

TensorFlow

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

AltDiffusion

8.0G

\[ğŸ¤—HF\]

FlagAI

github

ä¸­æ–‡å¤šæ¨¡æ€-å›¾æ–‡

\[Back to Top\]

### Taiyi-Stable-Diffusion

-   2022 | Fengshenbang 1.0: Being the Foundation of Chinese Cognitive Intelligence | Junjie Wang, et al. | arXiv | `PDF`
-   2022 | High-Resolution Image Synthesis With Latent Diffusion Models | Rombach, et al. | arXiv | `PDF`

æ¨¡å‹

ç‰ˆæœ¬

TensorFlow

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

Taiyi-Stable-Diffusion

1B

\[ğŸ¤—HF\]

IDEA-CCNL

github

ä¸­æ–‡å¤šæ¨¡æ€-å›¾æ–‡

\[Back to Top\]

### wukong

-   2022 | Wukong: A 100 Million Large-scale Chinese Cross-modal Pre-training Benchmark | Jiaxi Gu, et al. | arXiv | `PDF`

æ¨¡å‹

ç‰ˆæœ¬

TensorFlow

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

CLIP

url

HUAWEI

github

ä¸­æ–‡å¤šæ¨¡æ€-å›¾æ–‡

FILIP

url

HUAWEI

github

ä¸­æ–‡å¤šæ¨¡æ€-å›¾æ–‡

wukong

url

HUAWEI

github

ä¸­æ–‡å¤šæ¨¡æ€-å›¾æ–‡

\[Back to Top\]

### OFA

-   2022 | OFA: Unifying Architectures, Tasks, and Modalities Through a Simple Sequence-to-Sequence Learning Framework | Peng Wang, et al. | arXiv | `PDF`

æ¨¡å‹

ç‰ˆæœ¬

TensorFlow

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

OFA

link

OFA-Sys

github

ä¸­æ–‡å¤šæ¨¡æ€-å›¾æ–‡

OFA-Chinese

\[ğŸ¤—HF\]

Yang JianXin

github

ä¸­æ–‡å¤šæ¨¡æ€-å›¾æ–‡

\[Back to Top\]

### QA-CLIP

æ¨¡å‹

ç‰ˆæœ¬

è§†è§‰æ¶æ„

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

QA-CLIPRN50

77M

ResNet50

\[ğŸ¤—HF\]

è…¾è®¯

QA-CLIP

ä¸­æ–‡å¤šæ¨¡æ€-å›¾æ–‡

QA-CLIPViT-B/16

188M

ViT-B/16

\[ğŸ¤—HF\]

è…¾è®¯

QA-CLIP

ä¸­æ–‡å¤šæ¨¡æ€-å›¾æ–‡

QA-CLIPViT-L/14

406M

ViT-L/14

\[ğŸ¤—HF\]

è…¾è®¯

QA-CLIP

ä¸­æ–‡å¤šæ¨¡æ€-å›¾æ–‡

\[Back to Top\]

Table
-----

### SDCUP

-   2021 | Improving Text-to-SQL with Schema Dependency Learning | Binyuan Hui, et al. | arXiv | `PDF`

æ¨¡å‹

ç‰ˆæœ¬

TensorFlow

PyTorch

ä½œè€…

æºåœ°å€

åº”ç”¨é¢†åŸŸ

sdcup

base

é˜¿é‡Œäº‘

Alibaba

github

ä¸­æ–‡è¡¨æ ¼

sdcup

large

é˜¿é‡Œäº‘

Alibaba

github

ä¸­æ–‡è¡¨æ ¼

\[Back to Top\]

æ›´æ–°
--

-   2025.10.12 å¢åŠ \[Ling-1T,KAT-Dev-72B-Exp, GLM-4.6 \]
-   2025.09.20 å¢åŠ \[Tongyi DeepResearch,Qwen3-Next,Magistral Small,VoxCPM,VibeVoice,HunyuanImage\]
-   2025.08.19 å¢åŠ \[gpt-oss-20B,gpt-oss-120B,Baichuan-M2,Ovis2.5,GLM-4.5V\]
-   2025.08.05 å¢åŠ \[GLM-4.5,Hunyuan,Qwen3-Thinking-2507,Step3,Kimi-k2,Qwen3-Coder\]
-   2025.07.07 å¢åŠ \[Kimi-VL-Thinking,GLM-4.1V-Thinking,Dhanishtha-2.0,ERNIE-4.5\]
-   2025.06.29 å¢åŠ \[Qwen3-Embedding,Skywork-SWEï¼ŒHunyuan-A13B\]
-   2025.06.17 å¢åŠ \[MiniMax-M1,Kimi-Dev\]
-   2025.05.29 å¢åŠ \[DeepSeek-R1-0528,QwenLong-L1,Dolphin\]
-   2025.05.07 å¢åŠ \[Qwen3,MiMo\]
-   2025.04.15 å¢åŠ \[GLM-Z1-0414. DeepCoder, Kimi-VL-Thinking, Skywork-OR1\]
-   2025.03.22 å¢åŠ \[Skywork-R1V,FIN-R1\]
-   2025.03.09 å¢åŠ \[QwQ-32B, Aya Vision,CogView4\]
-   2025.02.26 å¢åŠ \[Moonlightã€Wan2.1ã€Step-Audio-Chat\]
-   2025.02.15 å¢åŠ \[Ovis2\]
-   2025.01.19 å¢åŠ \[MiniMax-01, miniCPM-Oï¼Œ OuteTTS\]
-   2025.01.12 å¢åŠ Sky-T1,search-o1
-   2025.01.02 å¢åŠ Huatuo-o1
-   2024.12.25 å¢åŠ \[QVQ-72B\]
-   2024.12.16 å¢åŠ \[Megrez-3B-Omni, DeepSeek-VL2\]
-   2024.11.29 å¢åŠ QwQ-32B-Preview,Marco-o1 ,Skywork-01-Open,HK-01aw
-   2024.11.15 å¢åŠ Qwen-2.5-coder, OpenCoder
-   2024.11.05 å¢åŠ Hunyuan-Large
-   2024.10.26 å¢åŠ GLM-4-Voice,Pangea,Aya-Expanse
-   2024.10.22 å¢åŠ Granite 3.0,ä¸€å¥—å…¨æ–°çš„è½»é‡çº§ã€å¤šè¯­ç§æ”¯æŒçš„è¯­è¨€æ¨¡å‹ï¼Œä¸“ä¸ºæ¨ç†ã€ç¼–ç¨‹å’Œå·¥å…·ä½¿ç”¨è®¾è®¡ï¼Œå¯åœ¨è®¡ç®—èµ„æºå—é™çš„ç¯å¢ƒä¸­è¿è¡Œï¼Œé€‚åˆä¼ä¸šä½¿ç”¨å’Œå®šåˆ¶
-   2024.09.19 å¢åŠ Qwen2.5
-   2024.09.08 å¢åŠ DeepSeekV2.5, MiniCPM3, Yi-Coder
-   2024.08.30 å¢åŠ C4AI Command R+ 08-2024,Qwen2-VL
-   2024.07.26 å¢åŠ JIUTIAN-Chat,Tele-FLM
-   2024.07.24 å¢åŠ Meta-llama3.1
-   2024.07.05 å¢åŠ CodeGeeX4
-   2024.07.04 å¢åŠ internlm2.5
-   2024.06.19 å¢åŠ MAP-NEO-Chatï¼ŒMAP-NEO is a fully open-sourced Large Language Model that includes the pretraining data, a data processing pipeline (Matrix), pretraining scripts, and alignment code.
-   2024.06.18 å¢åŠ DeepSeek-Coder-V2ã€Nemotron-4
-   2024.06.14 å¢åŠ Index-Chat
-   2024.06.08 å¢åŠ Qwen2,ChatTTS
-   2024.06.03 å¢åŠ GLM-4ã€Skywork-MoE
-   2024.05.30 å¢åŠ Yuan2.0-M32: Mixture of Experts with Attention Router
-   2024.05.20 å¢åŠ \[CogVLM2,360VL,HunyuanDiT,æ˜Ÿè¾°-Chat\]
-   2024.05.13 å¢åŠ \[Yi-1.5\]
-   2024.05.07 å¢åŠ \[XVERSE-V,DeepSeek-V2,XVERSE-MoE\]
-   2024.04.27 å¢åŠ Qwen1.5-110B, Llama3-zh
-   2024.04.14 å¢åŠ MiniCPM-V2ã€WaveCoderã€codegemmaã€Sailorã€Nanbeige2-Chatã€MiniCPM-MoEã€Zhinao-Chat
-   2024.04.12 å¢åŠ XVERSE-MoE
-   2024.04.08 å¢åŠ SoftTigerã€HammerLLM
-   2024.04.06 å¢åŠ Qwen1.5-32B
-   2024.04.04 å¢åŠ Mengzi3
-   2024.03.29 å¢åŠ Qwen-Audioã€Qwen-MoE
-   2024.03.13 å¢åŠ Command-R
-   2024.03.01 å¢åŠ Breeze-Instruct, starcoder2
-   2024.02.18 å¢åŠ aya-101ã€chemLLM
-   2024.02.06 å¢åŠ Qwen1.5
-   2024.02.02 å¢åŠ MiniCPM, TuringMM-Chat
-   2024.02.01 å¢åŠ LongAlign-Chatï¼ŒChinese-Mixtral-Chat
-   2024.01.31 å¢åŠ iFlytekSpark-Chatï¼Œrwkv-5-world
-   2024.01.23 å¢åŠ Yi-VL-6/34B
-   2024.01.22 å¢åŠ orion-4B
-   2024.01.19 å¢åŠ internlm2-chatï¼ŒChinese-Mixtral
-   2024.01.10 å¢åŠ Telechatï¼ŒCode Millenials
-   2024.01.09 å¢åŠ kagentlms,å…·æœ‰Agentsçš„è§„åˆ’ã€åæ€ã€å·¥å…·ä½¿ç”¨ç­‰èƒ½åŠ›çš„ç³»åˆ—å¤§æ¨¡å‹
-   2024.01.05 å¢åŠ WizardCoder-33B-V1.1
-   2023.12.27 å¢åŠ YaYi-30B-Chat
-   2023.12.05 å¢åŠ SUS-Chat-34Bã€Aquila2-Chat-70Bã€Alaya-Chat-7B
-   2023.12.01 å¢åŠ Qwen-Base-1.8/72B,Qwen-Chat-1.8/72B,Qwen-Audio
-   2023.11.30 å¢åŠ Yuan-2.0ã€DeepSeek-Base,DeepSeek-Chat
-   2023.11.20 å¢åŠ Alaya-Chat-7Bã€OrionStar-Yi-Chat-34B
-   2023.11.11 å¢åŠ XVERSE-65Bã€Nanbeige-Chat-16Bã€OpenChat 3.5
-   2023.11.03 å¢åŠ SPHINXã€Tongyi-Financeã€Phindã€DeepSeek-Coder
-   2023.11.02 å¢åŠ AndesGPT-7Bã€SeaLLMã€BlueLM
-   2023.10.31 å¢åŠ Zephyr-7Bã€Mistral-7b
-   2023.10.25 å¢åŠ zhiyinã€zhilu
-   2023.10.20 å¢åŠ crossã€taiyiã€fuyuã€Ziya-visualã€CodeShellã€CogVLM
-   2023.10.17 å¢åŠ Ziya2-13B-Baseã€Ziya2-13B-Chat
-   2023.10.12 å¢åŠ AquilaChat2-7/13Bã€AquilaChat2-16Kã€Vulture-180B
-   2023.10.04 å¢åŠ DISC-LawLLMã€WiNGPTã€ziya-codingã€Vultureã€AgriGPT
-   2023.09.25 å¢åŠ Colossal-LLaMA-2-7B,ç›¸è¾ƒäºåŸå§‹LLaMA-2ï¼Œåœ¨æˆåŠŸæå‡ä¸­æ–‡èƒ½åŠ›çš„åŸºç¡€ä¸Šï¼Œè¿›ä¸€æ­¥æå‡å…¶è‹±æ–‡èƒ½åŠ›ï¼Œæ€§èƒ½å¯ä¸å¼€æºç¤¾åŒºåŒè§„æ¨¡é¢„è®­ç»ƒSOTAæ¨¡å‹åª²ç¾ã€‚
-   2023.09.20 å¢åŠ InternLM-20Bã€OpenBA,InternLM-20Bå·²å‘å¸ƒï¼ŒåŒ…æ‹¬åŸºç¡€ç‰ˆå’Œå¯¹è¯ç‰ˆã€‚OpenBAæ˜¯ä¸€ä¸ªä»å¤´å¼€å§‹é¢„è®­ç»ƒçš„å¼€æº15BåŒè¯­éå¯¹ç§°ç«¯åˆ°ç«¯æ¨¡å‹ã€‚
-   2023.09.08 å¢åŠ FLM-101Bã€falcon-180Bã€Openbuddy-70Bã€TigerBot-70B
-   2023.09.06 å¢åŠ Baichuan2,Baichuan 2 æ˜¯ç™¾å·æ™ºèƒ½æ¨å‡ºçš„æ–°ä¸€ä»£å¼€æºå¤§è¯­è¨€æ¨¡å‹ï¼Œé‡‡ç”¨ 2.6 ä¸‡äº¿ Tokens çš„é«˜è´¨é‡è¯­æ–™è®­ç»ƒã€‚
-   2023.09.01 å¢åŠ DISC-MedLLMã€YuLan-Chat-2ã€Chinese-Alpaca-2-16K,Vally
-   2023.08.29 å¢åŠ CodeLLAmaã€Atom,IDEFICS
-   2023.08.25 å¢åŠ sqlcoder,ä¸€ä¸ª SOTA å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œ SQLCoder å°†è‡ªç„¶è¯­è¨€é—®é¢˜è½¬æ¢ä¸º SQL æŸ¥è¯¢ã€‚åœ¨å¼€å‘è€…çš„å¼€æºè¯„ä¼°æ¡†æ¶ SQLEval ä¸­ï¼ŒSQLCoder çš„æ€§èƒ½æ˜æ˜¾ä¼˜äºæ‰€æœ‰ä¸»è¦çš„å¼€æºæ¨¡å‹ï¼Œå¹¶ä¸”ä¼˜äº OpenAI çš„ GPT-3.5ã€‚
-   2023.08.23 å¢åŠ Qwen-VL,Qwen-VL æ˜¯é˜¿é‡Œäº‘ç ”å‘çš„å¤§è§„æ¨¡è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆLarge Vision Language Model, LVLMï¼‰ã€‚Qwen-VL å¯ä»¥ä»¥å›¾åƒã€æ–‡æœ¬ã€æ£€æµ‹æ¡†ä½œä¸ºè¾“å…¥ï¼Œå¹¶ä»¥æ–‡æœ¬å’Œæ£€æµ‹æ¡†ä½œä¸ºè¾“å‡ºã€‚
-   2023.08.21 å¢åŠ æ™ºæµ·-å½•é—®,æ™ºæµ·-å½•é—®(wisdomInterrogatory)æ˜¯ç”±æµ™æ±Ÿå¤§å­¦ã€é˜¿é‡Œå·´å·´è¾¾æ‘©é™¢ä»¥åŠåé™¢è®¡ç®—ä¸‰å®¶å•ä½å…±åŒè®¾è®¡ç ”å‘çš„æ³•å¾‹å¤§æ¨¡å‹ã€‚
-   2023.08.15 å¢åŠ WizardMath,
-   2023.08.09 å¢åŠ TigerBot-13B,åœ¨Llama-2çš„åŸºç¡€ä¸Šä»¥è™åšç§¯ç´¯çš„æŠ€æœ¯å’Œæ•°æ®ç»§ç»­è®­ç»ƒï¼Œä¸ä½†ä¿æŒäº†Llama-2å‡ºè‰²çš„è‹±æ–‡èƒ½åŠ›ï¼Œæ›´æ˜¯åœ¨ä¸­æ–‡èƒ½åŠ›ä¸Šå¡«è¡¥äº†Llama-2çš„ä¸è¶³ï¼Œå„é¡¹ä¸»æµä¸­æ–‡ä»»åŠ¡ä¸­è¶…è¿‡Llama-2çš„49%ï¼Œåœ¨å¼€æºåŒç±»æ¨¡å‹ä¸­å…·æœ‰ç«äº‰åŠ›ã€‚
-   2023.08.07 å¢åŠ XVERSE-13B,XVERSE-13B,å®ƒæ”¯æŒ40å¤šç§è¯­è¨€ã€8192ä¸Šä¸‹æ–‡é•¿åº¦ã€‚åœ¨å¤šé¡¹ä¸­è‹±æ–‡æµ‹è¯„ä¸­ï¼Œæ€§èƒ½è¶…è¿‡äº†åŒå°ºå¯¸ï¼ˆ130äº¿å‚æ•°ï¼‰çš„LLama2ã€Baichuanç­‰ã€‚
-   2023.08.03 å¢åŠ é€šä¹‰åƒé—®,é€šä¹‰åƒé—®-7Bï¼ˆQwen-7Bï¼‰æ˜¯é˜¿é‡Œäº‘ç ”å‘çš„é€šä¹‰åƒé—®å¤§æ¨¡å‹ç³»åˆ—çš„70äº¿å‚æ•°è§„æ¨¡çš„æ¨¡å‹ã€‚
-   2023.07.31 å¢åŠ LLasMã€Chinese-LLaVAå¤šæ¨¡æ€å¤§æ¨¡å‹
-   2023.07.31 å¢åŠ Chinese-Llama-2.åŸç‰ˆLlama-2çš„åŸºç¡€ä¸Šæ‰©å……å¹¶ä¼˜åŒ–äº†ä¸­æ–‡è¯è¡¨ï¼Œä½¿ç”¨äº†120Gå¤§è§„æ¨¡ä¸­æ–‡æ•°æ®è¿›è¡Œå¢é‡é¢„è®­ç»ƒï¼Œç›¸å…³æ¨¡å‹æ”¯æŒ4Kä¸Šä¸‹æ–‡å¹¶å¯é€šè¿‡NTKæ–¹æ³•æœ€é«˜æ‰©å±•è‡³18K+
-   2023.07.29 å¢åŠ BatGPTï¼ŒMoziï¼ŒStarGLM.
-   2023.07.27 å¢åŠ WizardLM-v1.2.
-   2023.07.25 å¢åŠ ç›¸å…³Awesomeåˆ—è¡¨
-   2023.07.24 å¢åŠ Llama2-chinese-chatã€Jiang-chatç­‰å¯¹è¯è¯­è¨€æ¨¡å‹ã€‚
-   2023.07.19 å¢åŠ LLaMA2,Meta å‘å¸ƒäº†å¤§å®¶æœŸå¾…å·²ä¹…çš„å…è´¹å¯å•†ç”¨ç‰ˆæœ¬ Llama 2ã€‚
-   2023.07.16 å¢åŠ PolyLM,PolyLMæ˜¯ä¸€ä¸ªé€šæ™“å¤šè¯­è¨€è¯­è¨€çš„å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å¯ä»¥åº”ç”¨äºå¯¹è¯é—®ç­”ã€æ–‡æœ¬ç”Ÿæˆã€æœºå™¨ç¿»è¯‘å’Œæƒ…æ„Ÿåˆ†æç­‰é¢†åŸŸï¼Œèƒ½å¤Ÿè‡ªåŠ¨ç”Ÿæˆé«˜è´¨é‡çš„å¤šè¯­è¨€æ–‡æœ¬ã€‚
-   2023.07.11 å¢åŠ Baichuan-13B,baichuan-13Bæ˜¯ç”±ç™¾å·æ™ºèƒ½å¼€å‘çš„ä¸€ä¸ªå¼€æºå¯å•†ç”¨çš„å¤§è§„æ¨¡é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ã€‚
-   2023.07.10 å¢åŠ WizardLM-13B-V1.1
-   2023.07.09 å¢åŠ VisualCLAå¤šæ¨¡æ€å¤§æ¨¡å‹
-   2023.07.04 å¢åŠ ä¹¦ç”ŸÂ·æµ¦è¯­,ä¹¦ç”ŸÂ·æµ¦è¯­å¤§æ¨¡å‹ï¼ŒåŒ…å«é¢å‘å®ç”¨åœºæ™¯çš„70äº¿å‚æ•°åŸºç¡€æ¨¡å‹ä¸å¯¹è¯æ¨¡å‹.
-   2023.07.04 å¢åŠ yuren,vicuna,CuteGPT,ailawyer
-   2023.06.30 å¢åŠ VisCPM,VisCPM æ˜¯ä¸€ä¸ªå¼€æºçš„å¤šæ¨¡æ€å¤§æ¨¡å‹ç³»åˆ—ï¼Œæ”¯æŒä¸­è‹±åŒè¯­çš„å¤šæ¨¡æ€å¯¹è¯èƒ½åŠ›ï¼ˆVisCPM-Chatæ¨¡å‹ï¼‰å’Œæ–‡åˆ°å›¾ç”Ÿæˆèƒ½åŠ›ï¼ˆVisCPM-Paintæ¨¡å‹ï¼‰ï¼Œåœ¨ä¸­æ–‡å¤šæ¨¡æ€å¼€æºæ¨¡å‹ä¸­è¾¾åˆ°æœ€ä½³æ°´å¹³ã€‚
-   2023.06.28 å¢åŠ PULSE,PULSE-ä¸­æ–‡åŒ»ç–—å¤§è¯­è¨€æ¨¡å‹ã€‚
-   2023.06.26 å¢åŠ CoLLaMA,CoLLaMAæ˜¯åŸºäºä»£ç çš„å¤šè¯­è¨€å¤§æ¨¡å‹ã€‚
-   2023.06.25 å¢åŠ ChatGLM2-6B,ChatGLM2-6B æ˜¯å¼€æºä¸­è‹±åŒè¯­å¯¹è¯æ¨¡å‹ ChatGLM-6B çš„ç¬¬äºŒä»£ç‰ˆæœ¬ã€‚
-   2023.06.24 å¢åŠ TechGPT,TechGPTæ˜¯â€œä¸œåŒ—å¤§å­¦çŸ¥è¯†å›¾è°±ç ”ç©¶ç»„â€å‘å¸ƒçš„å‚ç›´é¢†åŸŸå¤§è¯­è¨€æ¨¡å‹ã€‚
-   2023.06.20 å¢åŠ Yayiã€BayLing,ç™¾è†ï¼ˆBayLingï¼‰æ˜¯ä¸€ä¸ªå¼ºåŒ–äº†è¯­è¨€å¯¹é½çš„æŒ‡ä»¤è·Ÿéšå¤§è§„æ¨¡è¯­è¨€æ¨¡å‹;Yayiå¤§æ¨¡å‹ åœ¨ç™¾ä¸‡çº§äººå·¥æ„é€ çš„é«˜è´¨é‡é¢†åŸŸæ•°æ®ä¸Šè¿›è¡ŒæŒ‡ä»¤å¾®è°ƒå¾—åˆ°ï¼Œè®­ç»ƒæ•°æ®è¦†ç›–åª’ä½“å®£ä¼ ã€èˆ†æƒ…åˆ†æã€å…¬å…±å®‰å…¨ã€é‡‘èé£æ§ã€åŸå¸‚æ²»ç†ç­‰äº”å¤§é¢†åŸŸã€‚
-   2023.06.19 å¢åŠ panda,Pandaæ˜¯æµ·å¤–ä¸­æ–‡å¼€æºå¤§è¯­è¨€æ¨¡å‹ã€‚
-   2023.06.18 å¢åŠ ZhiXi,ZhiXiåŸºäºLlamaçš„é’ˆå¯¹çŸ¥è¯†æŠ½å–çš„å¤§æ¨¡å‹ã€‚
-   2023.06.15 å¢åŠ Baichuan-7B,baichuan-7Bæ˜¯ç”±ç™¾å·æ™ºèƒ½å¼€å‘çš„ä¸€ä¸ªå¼€æºå¯å•†ç”¨çš„å¤§è§„æ¨¡é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ã€‚
-   2023.06.14 å¢åŠ Chinese-Falcon,Chinese-Falcon æ¨¡å‹åœ¨ Falcon åŸºç¡€ä¸Šæ‰©å……ä¸­æ–‡è¯è¡¨ï¼Œåœ¨ä¸­è‹±æ–‡æ•°æ®ä¸Šå¢é‡é¢„è®­ç»ƒã€‚ æ¨¡å‹ä»¥ Apache License 2.0 åè®®å¼€æºï¼Œæ”¯æŒå•†ä¸šç”¨é€”ã€‚ã€‚
-   2023.06.13 å¢åŠ OpenLLaMA-Chinese,OpenLLaMA-Chineseæ˜¯å…è´¹çš„ä¸­æ–‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ŒåŸºäºOpenLLaMAï¼Œå¯ç”¨äºéå•†ä¸šå’Œå•†ä¸šç›®çš„ã€‚
-   2023.06.09 å¢åŠ QA-CLIP,M3E,Aquila,QA-CLIPæ˜¯ä¸­æ–‡CLIPæ¨¡å‹,M3Eæ˜¯æ–‡æœ¬åµŒå…¥æ¨¡å‹,Aquilaæ˜¯è¯­è¨€å¤§æ¨¡å‹ã€‚
-   2023.06.08 å¢åŠ YuLan,YuLanæ˜¯ç”±ä¸­å›½äººåå¤§å­¦å¼€æºçš„åŒè¯­è¨€ä»»åŠ¡å¤§æ¨¡å‹,å¼€æº13Bå’Œ65Bå¤§å°ã€‚
-   2023.06.08 å¢åŠ Chinese-Alpaca-33B,Chinese-LLaMA-33Bï¼Œä¸­æ–‡LLaMA/Alpaca-33Bã€‚
-   2023.06.07 å¢åŠ Tigerbot,TigerBotæ˜¯ä¸€æ¬¾å›½äº§è‡ªç ”çš„å¤šè¯­è¨€ä»»åŠ¡å¤§æ¨¡å‹,å¼€æº7Bå’Œ180Bå¤§å°ã€‚
-   2023.06.06 å¢åŠ Video-LLaMA,BiLLa,Video-LLaMAæ˜¯ä¸€ä¸ªç”¨äºè§†é¢‘ç†è§£çš„æŒ‡ä»¤è°ƒæ•´çš„è§†è§‰è¯­è¨€æ¨¡å‹ï¼ŒBiLLaæ˜¯å¼€æºçš„æ¨ç†èƒ½åŠ›å¢å¼ºçš„ä¸­è‹±åŒè¯­LLaMAæ¨¡å‹ã€‚
-   2023.05.26 å¢åŠ XuanYuan,XrayGLM,XuanYuanæ˜¯å›½å†…é¦–ä¸ªå¼€æºçš„åƒäº¿çº§ä¸­æ–‡å¯¹è¯å¤§æ¨¡å‹,XrayGLMæ˜¯ä¸­æ–‡åŒ»å­¦é¢†åŸŸå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ã€‚
-   2023.05.21 å¢åŠ ziya,BLOOMChat,Ziya-LLaMA-13B-v1æ‹¥æœ‰130äº¿å‚æ•°ï¼Œä»LLaMA-13Bå¼€å§‹é‡æ–°æ„å»ºä¸­æ–‡è¯è¡¨ï¼Œè¿›è¡Œåƒäº¿tokené‡çº§çš„å·²çŸ¥çš„æœ€å¤§è§„æ¨¡ç»§ç»­é¢„è®­ç»ƒï¼Œä½¿æ¨¡å‹å…·å¤‡åŸç”Ÿä¸­æ–‡èƒ½åŠ›.
-   2023.05.18 å¢åŠ VisualGLM-6B,VisualGLM-6B æ˜¯ä¸€ä¸ªå¼€æºçš„ï¼Œæ”¯æŒå›¾åƒã€ä¸­æ–‡å’Œè‹±æ–‡çš„å¤šæ¨¡æ€å¯¹è¯è¯­è¨€æ¨¡å‹ã€‚
-   2023.05.16 å¢åŠ BiLLa,å¼€æºä¸­è‹±æ–‡åŒè¯­å¤§æ¨¡å‹ã€‚
-   2023.05.12 å¢åŠ Bactrian-X,å¼€æºå¤šè¯­è¨€å¤§æ¨¡å‹ã€‚
-   2023.05.08 å¢åŠ OpenBuddy,ä¸€æ¬¾å¼ºå¤§çš„å¼€æºå¤šè¯­è¨€èŠå¤©æœºå™¨äººæ¨¡å‹ã€‚
-   2023.04.26 æ›´æ–°LLaMA-zhã€YuYan,å¢åŠ LLama-zhã€Yuyanã€æ‰é¹Šç­‰LLMå’ŒchatLLmæ¨¡å‹
-   2023.04.25 å¢åŠ BBTï¼ŒåŸºäºTransformerå’ŒDecoder-Onlyçš„æ¶æ„å¼€å‘äº†BigBang Transformerã€Œä¹¾å…ƒã€å¤§è§„æ¨¡é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ã€‚
-   2023.04.21 å¢åŠ MOSS,æ›´æ–°å¤æ—¦å¤§å­¦å¼€æºçš„MOSSæ¨¡å‹ä»¥åŠå¯¹åº”çš„æ•°æ®é›†ã€‚
-   2023.04.20 å¢åŠ Phoenix,åŸºäºBLOOMZ-mtæ¨¡å‹å¾®è°ƒå¾—åˆ°çš„å¤§è¯­è¨€æ¨¡å‹ã€‚
-   2023.04.19 å¢åŠ ChatPLUGï¼Œè¯¥æ¨¡å‹åŸºäºPLUGï¼Œä½¿ç”¨äº¿çº§äº’è”ç½‘ç¤¾äº¤æ•°æ®ã€ç™¾ç§‘æ•°æ®é¢„è®­ç»ƒå’Œç™¾ä¸‡çº§é«˜è´¨é‡å¯¹è¯æ•°æ®è¿›è¡Œinstructionå¾®è°ƒå¾—åˆ°ã€‚
-   2023.04.18 å¢åŠ COIGæ•°æ®é›†ï¼Œç”¨ä¸åŒæ–¹æ³•æ„å»ºä¸­æ–‡æŒ‡ä»¤æ•°æ®é›†çš„é¡¹ç›®ï¼Œæ”¶é›†äº†å¤§çº¦20ä¸‡ä¸ªä¸­æ–‡æŒ‡ä»¤æ ·æœ¬ã€‚
-   2023.04.13 æ›´æ–°ChatLLMï¼Œå¢åŠ HuaTuo,Med\_ChatGLMä¸¤ä¸ªåŒ»å­¦æ¨¡å‹ã€‚
-   2023.04.09 æ›´æ–°ä¸­æ–‡æŒ‡ä»¤æ•°æ®é›†ChatLLMï¼Œå¢åŠ ä¸ªæ€§è§’è‰²å¯¹è¯æ•°æ®é›†ã€chinese-alpaca-13bæ¨¡å‹ã€‚
-   2023.04.03 æ›´æ–°ä¸­æ–‡æŒ‡ä»¤æ•°æ®é›†ChatLLMï¼Œå¢åŠ BELLE-13bæ¨¡å‹ï¼Œmath-0.25ï¼Œmultiturn-0.8æ•°æ®é›†ã€‚
-   2023.04.02 æ›´æ–°ChatLLMåˆ—è¡¨ï¼Œå¢åŠ ç”±é¦™æ¸¯ç§‘æŠ€å¤§å­¦å¼€æºçš„7B/13B/33B/65Bä¸­æ–‡å¤§å‹è¯­è¨€æ¨¡å‹
-   2023.03.30 å¢åŠ Chinese-Vicunaæ¨¡å‹ï¼ŒTraditional-Chinese-alpacaæ•°æ®é›†
-   2023.03.29 å¢åŠ OFA,ä¸­æ–‡å¤šæ¨¡æ€ç»Ÿä¸€é¢„è®­ç»ƒæ¨¡å‹,OFAæ˜¯é˜¿é‡Œå·´å·´å‘å¸ƒçš„å¤šæ¨¡æ€ç»Ÿä¸€é¢„è®­ç»ƒæ¨¡å‹.
-   2023.03.29 æ›´æ–°ä¸­æ–‡æŒ‡ä»¤æ•°æ®é›†ï¼Œå¢åŠ InstructionWildæ•°æ®é›†ã€‚
-   2023.03.23 å¢åŠ ä¸­æ–‡æŒ‡ä»¤æ•°æ®é›†ï¼Œå¹¶åˆå§‹åŒ–ä¸‰ä¸ªå·²å…¬å¼€æ•°æ®é›†ã€‚
-   2023.03.20 å¢åŠ BELLE,å¼€æºä¸­æ–‡å¯¹è¯å¤§æ¨¡å‹-70äº¿å‚æ•°,åŸºäºStanford Alpacaï¼Œå¯¹ä¸­æ–‡åšäº†ä¼˜åŒ–ï¼Œæ¨¡å‹è°ƒä¼˜ä»…ä½¿ç”¨ç”±ChatGPTç”Ÿäº§çš„æ•°æ®.
-   2023.03.14 å¢åŠ ChatLLMåˆ—è¡¨ï¼Œä¸»è¦æ”¶é›†å…·å¤‡é—®ç­”è·Ÿå¯¹è¯ç­‰åŠŸèƒ½çš„å¤§å‹è¯­è¨€æ¨¡å‹,å¹¶å¢åŠ ChatGLMæ¨¡å‹ã€‚
-   2023.03.11 å¢åŠ ProphetNet,æå‡ºäº†ä¸€ç§æ–°çš„è‡ªç›‘ç£å­¦ä¹ ç›®æ ‡â€”â€”åŒæ—¶é¢„æµ‹å¤šä¸ªæœªæ¥å­—ç¬¦ï¼Œåœ¨åºåˆ—åˆ°åºåˆ—çš„å¤šä¸ªè‡ªç„¶è¯­è¨€ç”Ÿæˆä»»åŠ¡éƒ½å–å¾—äº†ä¼˜å¼‚æ€§èƒ½ã€‚
-   2023.03.10 å¢åŠ RoCBert,åˆ©ç”¨å¯¹æŠ—å­¦ä¹ ç”Ÿæˆæ›´å¤šå™ªå£°æ•°æ®ï¼Œç”¨æ¥è¿›è¡Œä¸­æ–‡BERTæ¨¡å‹çš„è®­ç»ƒï¼Œå¾—åˆ°é²æ£’æ€§æ›´å¼ºçš„ä¸­æ–‡BERTæ¨¡å‹ã€‚
-   2023.03.03 æ›´æ–°LLM,æ–°å¢å¤šè¯­è¨€æ¨¡å‹`Flan-ul2`å’Œ`Flan-t5-xxl`
-   2023.02.21 å¢åŠ LLM,å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹åˆ—è¡¨ï¼Œåªç½—åˆ—å‡ºå‚æ•°é‡å¤§äº10Bä»¥ä¸Šæ¨¡å‹ï¼Œå…¶ä½™é‡çº§æ¨¡å‹ï¼Œå¯å‚è€ƒå¯¹åº”çš„é¡¹ç›®åœ°å€ã€‚
-   2023.01.14 å¢åŠ SkyText,SkyTextæ˜¯ç”±å¥‡ç‚¹æ™ºæºå‘å¸ƒçš„ä¸­æ–‡GPT3é¢„è®­ç»ƒå¤§æ¨¡å‹ï¼Œå¯ä»¥è¿›è¡ŒèŠå¤©ã€é—®ç­”ã€ä¸­è‹±äº’è¯‘ç­‰ä¸åŒçš„ä»»åŠ¡.
-   2023.01.14 å¢åŠ ChatYuan,ChatYuanæ¨¡å‹å¯ä»¥ç”¨äºé—®ç­”ã€ç»“åˆä¸Šä¸‹æ–‡åšå¯¹è¯ã€åšå„ç§ç”Ÿæˆä»»åŠ¡ï¼ŒåŒ…æ‹¬åˆ›æ„æ€§å†™ä½œï¼Œä¹Ÿèƒ½å›ç­”ä¸€äº›åƒæ³•å¾‹ã€æ–°å† ç­‰é¢†åŸŸé—®é¢˜ã€‚
-   2022.12.10 å¢åŠ PromptCLUE,å…¨ä¸­æ–‡ä»»åŠ¡é›¶æ ·æœ¬å­¦ä¹ æ¨¡å‹,åŸºäº1000äº¿tokenä¸­æ–‡è¯­æ–™ä¸Šé¢„è®­ç»ƒï¼Œå¹¶ä¸”åœ¨æ•°ç™¾ç§ä»»åŠ¡ä¸Šè¿›è¡ŒPromptä»»åŠ¡å¼è®­ç»ƒã€‚
-   2022.12.01 å¢åŠ wukong,åŸºäºä¸€ä¸ªåä¸ºã€Œæ‚Ÿç©ºã€çš„å¤§å‹ä¸­æ–‡è·¨æ¨¡æ€æ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«æ¥è‡ªç½‘ç»œçš„ 1 äº¿ä¸ªå›¾æ–‡å¯¹ï¼Œé¢„è®­ç»ƒçš„å¤šæ¨¡æ€æ¨¡å‹ã€‚
-   2022.11.30 å¢åŠ AltDiffusionï¼Œä½¿ç”¨ AltCLIP ä½œä¸ºtext encoderï¼ŒåŸºäº Stable Diffusion è®­ç»ƒäº†ä¸­è‹±åŒè¯­Diffusionæ¨¡å‹(AltDiffusion)
-   2022.11.30 å¢åŠ AltCLIP,ä¸€ä¸ªç®€å•é«˜æ•ˆçš„æ–¹æ³•å»è®­ç»ƒæ›´åŠ ä¼˜ç§€çš„åŒè¯­CLIPæ¨¡å‹,åä¸ºAltCLIPã€‚AltCLIPåŸºäº OpenAI CLIP è®­ç»ƒã€‚
-   2022.11.30 å¢åŠ Taiyi-Stable-Diffusion,é¦–ä¸ªå¼€æºçš„ä¸­è‹±åŒè¯­Stable Diffusionæ¨¡å‹ï¼ŒåŸºäº0.2äº¿ç­›é€‰è¿‡çš„ä¸­æ–‡å›¾æ–‡å¯¹è®­ç»ƒã€‚
-   2022.11.9 å¢åŠ OPD,OPDæ˜¯ä¸€ä¸ªä¸­æ–‡å¼€æ”¾åŸŸå¯¹è¯é¢„è®­ç»ƒæ¨¡å‹ï¼Œæ‹¥æœ‰63äº¿å‚æ•°ï¼Œåœ¨70GBé«˜è´¨é‡å¯¹è¯æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒè€Œæˆ.`å¤§è§„æ¨¡` & `é«˜æ€§èƒ½`
-   2022.11.8 æ›´æ–°Chinese-CLIP,Chinese-CLIPæ˜¯ä¸­æ–‡å¤šæ¨¡æ€å›¾æ–‡è¡¨å¾æ¨¡å‹ï¼Œæ›´æ–°åChinese-CLIPæ‰©å……åˆ°5ä¸ªæ¨¡å‹è§„æ¨¡ï¼ŒåŒæ—¶å¢åŠ äº†æŠ€æœ¯æŠ¥å‘Šè®ºæ–‡ä»¥åŠæ£€ç´¢demoï¼ŒåŒæ—¶åœ¨è¾¾æ‘©é™¢ModelScopeå¹³å°åŒæ­¥é›†æˆã€‚
-   2022.10.31 å¢åŠ LERT,ä¸ºäº†éªŒè¯é€šè¿‡æ˜¾å¼æ³¨å…¥è¯­è¨€å­¦çŸ¥è¯†é¢„è®­ç»ƒæ¨¡å‹èƒ½å¦è·å¾—è¿›ä¸€æ­¥æ€§èƒ½æå‡ï¼ŒHFLæå‡ºäº†ä¸€ç§**è¯­è¨€å­¦ä¿¡æ¯å¢å¼ºçš„é¢„è®­ç»ƒæ¨¡å‹LERT**ï¼Œèåˆäº†å¤šç§è¯­è¨€å­¦çŸ¥è¯†ã€‚å¤§é‡å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨åŒç­‰è®­ç»ƒæ•°æ®è§„æ¨¡ä¸‹ï¼ŒLERTèƒ½å¤Ÿå¸¦æ¥æ˜¾è‘—æ€§èƒ½æå‡ã€‚
-   2022.10.14 å¢åŠ CKBERTï¼Œä¸­æ–‡çŸ¥è¯†åº“å¢å¼ºBERTé¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ã€‚
-   2022.10.01 å¢åŠ GlyphBERT, GlyphBERTæ˜¯ä¸€ä¸ªåŒ…å«äº†æ±‰å­—å­—å½¢ç‰¹å¾ä¸­æ–‡é¢„è®­ç»ƒæ¨¡å‹ã€‚å®ƒé€šè¿‡å°†è¾“å…¥çš„å­—ç¬¦æ¸²æŸ“æˆå›¾åƒå¹¶è®¾è®¡æˆå¤šé€šé“ä½ç½®ç‰¹å¾å›¾çš„å½¢å¼ï¼Œå¹¶è®¾è®¡äº†ä¸€ä¸ªä¸¤å±‚ æ®‹å·®å·ç§¯ç¥ç»ç½‘ç»œæ¨¡å—æ¥æå–å­—ç¬¦çš„å›¾åƒç‰¹å¾è¿›è¡Œè®­ç»ƒã€‚
-   2022.09.30 å¢åŠ DeBERTaï¼Œä¸€ä¸ªä¸­æ–‡ç‰ˆçš„DeBERTa-v2ï¼Œæˆ‘ä»¬ç”¨æ‚Ÿé“è¯­æ–™åº“(180Gç‰ˆæœ¬)è¿›è¡Œé¢„è®­ç»ƒï¼Œåœ¨é¢„è®­ç»ƒé˜¶æ®µä¸­ä½¿ç”¨äº†å°ç¥æ¡†æ¶ã€‚
-   2022.09.30 å¢åŠ TaiYi-CLIP,é¦–ä¸ªå¼€æºçš„ä¸­æ–‡CLIPæ¨¡å‹ï¼Œ1.23äº¿å›¾æ–‡å¯¹ä¸Šè¿›è¡Œé¢„è®­ç»ƒçš„æ–‡æœ¬ç«¯RoBERTa-largeã€‚
-   2022.09.27 å¢åŠ PLUG,PLUGé›†è¯­è¨€ç†è§£ä¸ç”Ÿæˆèƒ½åŠ›äºä¸€èº«ï¼Œæ”¯æŒæ–‡æœ¬ç”Ÿæˆã€é—®ç­”ã€è¯­ä¹‰ç†è§£ç­‰å¤šç±»ä¸‹æ¸¸ä»»åŠ¡ï¼ŒPLUGå¼€æºå°†åŠ©åŠ›å¼€å‘è€…åœ¨è¯­è¨€ç†è§£å’Œè¯­è¨€ç”Ÿæˆä¸Šåšå‡ºæ›´å¤šå»¶æ‹“ã€‚
-   2022.09.11 å¢åŠ bloom-6b4,å¤šè¯­è¨€é¢„è®­ç»ƒbloomç³»åˆ—ç”Ÿæˆæ¨¡å‹7b1å‚æ•°(https://huggingface.co/bigscience/bloom-7b1 )çš„ä¸­æ–‡vocabæå–ï¼Œbloomç³»åˆ—å¦æœ‰æœ€å¤§176Bæ¨¡å‹(https://huggingface.co/bigscience/bloom).
-   2022.09.11 å¢åŠ GLM-130B,æå‡ºäº†å¼€æºçš„åŒè¯­é¢„è®­ç»ƒç”Ÿæˆæ¨¡å‹ GLM(General Language Model)ã€‚
-   2022.09.11 å¢åŠ PanGu-Î±: Large-scale Autoregressive Pretrained Chinese Language Models with Auto-parallel Computation 2.6Bå’Œ13B ç”Ÿæˆæ¨¡å‹pytorchç‰ˆ
-   2022.06.29 å¢åŠ ERNIE 3.0,å¤§è§„æ¨¡çŸ¥è¯†å¢å¼ºé¢„è®­ç»ƒè¯­è¨€ç†è§£å’Œç”Ÿæˆ.
-   2022.06.22 å¢åŠ Zero and R2D2: A Large-scale Chinese Cross-modal Benchmark and A Vision-Language Frameworkï¼ŒåŸºäºå¤§è§„æ¨¡ä¸­æ–‡è·¨æ¨¡æ€åŸºå‡†æ•°æ®é›†Zeroï¼Œè®­ç»ƒè§†è§‰è¯­è¨€é¢„è®­ç»ƒæ¡†æ¶ R2D2ï¼Œç”¨äºå¤§è§„æ¨¡è·¨æ¨¡æ€å­¦ä¹ ã€‚
-   2022.06.15 å¢åŠ GLM: General Language Model Pretraining with Autoregressive Blank Infilling,æå‡ºäº†ä¸€ç§æ–°çš„é€šç”¨è¯­è¨€æ¨¡å‹ GLM(General Language Model)ã€‚ ä½¿ç”¨è‡ªå›å½’å¡«ç©ºç›®æ ‡è¿›è¡Œé¢„è®­ç»ƒï¼Œå¯ä»¥é’ˆå¯¹å„ç§è‡ªç„¶è¯­è¨€ç†è§£å’Œç”Ÿæˆä»»åŠ¡è¿›è¡Œå¾®è°ƒã€‚
-   2022.05.16 å¢åŠ GAU-Î±,ä¸»è¦æå‡ºäº†ä¸€ä¸ªèåˆäº†Attentionå±‚å’ŒFFNå±‚çš„æ–°è®¾è®¡GAUï¼ˆGated Attention Unitï¼Œé—¨æ§æ³¨æ„åŠ›å•å…ƒï¼‰ï¼Œå®ƒæ˜¯æ–°æ¨¡å‹æ›´å¿«ã€æ›´çœã€æ›´å¥½çš„å…³é”®ï¼Œæ­¤å¤–å®ƒä½¿å¾—æ•´ä¸ªæ¨¡å‹åªæœ‰ä¸€ç§å±‚ï¼Œä¹Ÿæ˜¾å¾—æ›´ä¸ºä¼˜é›…ã€‚
-   2022.03.27 å¢åŠ RoFormer-V2,RoFormerå‡çº§ç‰ˆï¼Œä¸»è¦é€šè¿‡ç»“æ„çš„ç®€åŒ–æ¥æå‡é€Ÿåº¦ï¼Œå¹¶é€šè¿‡æ— ç›‘ç£é¢„è®­ç»ƒå’Œæœ‰ç›‘ç£é¢„è®­ç»ƒçš„ç»“åˆæ¥æå‡æ•ˆæœï¼Œä»è€Œè¾¾åˆ°äº†é€Ÿåº¦ä¸æ•ˆæœçš„â€œåŒèµ¢â€ã€‚
-   2022.03.02 å¢åŠ MobileBERT,MobileBERTæ˜¯BERT-largeæ¨¡å‹æ›´â€œè‹—æ¡â€çš„ç‰ˆæœ¬ï¼Œä½¿ç”¨äº†ç“¶é¢ˆç»“æ„ï¼ˆbottleneckï¼‰å¹¶ä¸”å¯¹è‡ªæ³¨æ„åŠ›å’Œå‰é¦ˆç¥ç»ç½‘ç»œä¹‹é—´çš„å¹³è¡¡åšäº†ç»†è‡´çš„è®¾è®¡ã€‚
-   2022.02.24 å¢åŠ PERT: Pre-Training BERT with Permuted Language Model,ä¸€ç§åŸºäºä¹±åºè¯­è¨€æ¨¡å‹çš„é¢„è®­ç»ƒæ¨¡å‹ï¼ˆPERTï¼‰ï¼Œåœ¨ä¸å¼•å…¥æ©ç æ ‡è®°\[MASK\]çš„æƒ…å†µä¸‹è‡ªç›‘ç£åœ°å­¦ä¹ æ–‡æœ¬è¯­ä¹‰ä¿¡æ¯ã€‚
-   2021.12.06 å¢åŠ SDCUP: Improving Text-to-SQL with Schema Dependency Learning,è¾¾æ‘©é™¢æ·±åº¦è¯­è¨€æ¨¡å‹ä½“ç³» AliceMind å‘å¸ƒä¸­æ–‡ç¤¾åŒºé¦–ä¸ªè¡¨æ ¼é¢„è®­ç»ƒæ¨¡å‹ SDCUPã€‚
-   2021.11.27 å¢åŠ RWKVä¸­æ–‡é¢„è®­ç»ƒç”Ÿæˆæ¨¡å‹,ç±»ä¼¼ GPT-2,æ¨¡å‹å‚è€ƒåœ°å€ï¼šRWKV-LM
-   2021.11.27 å¢åŠ IDEAç ”ç©¶é™¢å¼€æºçš„å°ç¥æ¦œç³»åˆ—è¯­è¨€æ¨¡å‹ï¼ŒåŒ…å«äºŒéƒç¥ã€å‘¨æ–‡ç‹ã€é—»ä»²ã€ä½™å…ƒã€‚
-   2021.11.25 å¢åŠ MC-BERT: Conceptualized Representation Learning for Chinese Biomedical Text Mining, ç”Ÿç‰©åŒ»å­¦é¢†åŸŸçš„ä¸­æ–‡é¢„è®­ç»ƒæ¨¡å‹.
-   2021.11.24 å¢åŠ TaCL: Improving BERT Pre-training with Token-aware Contrastive Learning, Token-awareå¯¹æ¯”å­¦ä¹ é¢„è®­ç»ƒæ¨¡å‹.
-   2021.10.18 å¢åŠ Mengzi: Towards Lightweight yet Ingenious Pre-trained Models for Chinese,åŸºäºè¯­è¨€å­¦ä¿¡æ¯èå…¥å’Œè®­ç»ƒåŠ é€Ÿç­‰æ–¹æ³•ç ”å‘äº† Mengzi ç³»åˆ—æ¨¡å‹.
-   2021.10.14 å¢åŠ ä¸­æ–‡ç‰ˆBART,è®­ç»ƒæ¯”è¾ƒå¯é çš„ä¸­æ–‡ç‰ˆBARTï¼Œä¸ºä¸­æ–‡ç”Ÿæˆç±»ä»»åŠ¡å¦‚æ‘˜è¦ç­‰æä¾›Baseline.
-   2021.10.14 å¢åŠ CPT: A Pre-Trained Unbalanced Transformer for Both Chinese Language Understanding and Generation,CPTï¼šå…¼é¡¾ç†è§£å’Œç”Ÿæˆçš„ä¸­æ–‡é¢„è®­ç»ƒæ¨¡å‹.
-   2021.10.13 å¢åŠ ç´«ä¸œå¤ªåˆå¤šæ¨¡æ€å¤§æ¨¡å‹: å…¨çƒé¦–ä¸ªå¤šæ¨¡æ€å›¾æ–‡éŸ³é¢„è®­ç»ƒæ¨¡å‹,å®ç°äº†è§†è§‰-æ–‡æœ¬-è¯­éŸ³ä¸‰æ¨¡æ€ç»Ÿä¸€è¡¨ç¤ºï¼Œæ„å»ºäº†ä¸‰æ¨¡æ€é¢„è®­ç»ƒå¤§æ¨¡å‹ã€‚
-   2021.09.19 å¢åŠ CogView: Mastering Text-to-Image Generation via Transformers,ä¸–ç•Œæœ€å¤§çš„ä¸­æ–‡å¤šæ¨¡æ€ç”Ÿæˆæ¨¡å‹,æ¨¡å‹æ”¯æŒæ–‡ç”Ÿæˆå›¾ä¸ºåŸºç¡€çš„å¤šé¢†åŸŸä¸‹æ¸¸ä»»åŠ¡.
-   2021.09.10 å¢åŠ WenLan: Bridging Vision and Language by Large-Scale Multi-Modal Pre-Trainingï¼Œé¦–ä¸ªä¸­æ–‡é€šç”¨å›¾æ–‡å¤šæ¨¡æ€å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹ã€‚
-   2021.09.10 å¢åŠ EVA: An Open-Domain Chinese Dialogue System with Large-Scale Generative Pre-Trainingï¼Œä¸€ä¸ªå¼€æ”¾é¢†åŸŸçš„ä¸­æ–‡å¯¹è¯é¢„è®­ç»ƒæ¨¡å‹ã€‚
-   2021.08.19 å¢åŠ Chinese-Transformer-XLï¼šåŸºäºä¸­æ–‡é¢„è®­ç»ƒè¯­æ–™WuDaoCorpusï¼ˆ290Gï¼‰è®­ç»ƒçš„GPT-3æ¨¡å‹ã€‚
-   2021.08.16 å¢åŠ CPM-2: Large-scale Cost-effective Pre-trained Language Models
-   2021.08.16 å¢åŠ Lattice-BERT: Leveraging Multi-Granularity Representations in Chinese Pre-trained Language Models
-   2021.07.19 å¢åŠ roformer-sim-v2ï¼šåˆ©ç”¨æ ‡æ³¨æ•°æ®å¢å¼ºç‰ˆæœ¬
-   2021.07.15 å¢åŠ BERT-CCPoemï¼šå¤å…¸è¯—æ­Œè¯­æ–™è®­ç»ƒçš„BERT
-   2021.07.06 å¢åŠ ChineseBERTï¼šChinese Pretraining Enhanced by Glyph and Pinyin Information
-   2021.06.22 å¢åŠ StructBERT: Incorporating Language Structures into Pre-training for Deep Language Understanding
-   2021.06.14 å¢åŠ RoFormerï¼šEnhanced Transformer with Rotary Position Embedding
-   2021.05.25 å¢åŠ ERNIE-Gram: Pre-Training with Explicitly N-Gram Masked Language Modeling for Natural Language Understanding
-   2021.04.28 å¢åŠ PanGu-Î±: Large-scale Autoregressive Pretrained Chinese Language Models with Auto-parallel Computation
-   2021.03.16 å¢åŠ T5-PEGASUS: å¼€æºä¸€ä¸ªä¸­æ–‡ç”Ÿæˆå¼é¢„è®­ç»ƒæ¨¡å‹
-   2021.03.09 å¢åŠ UERç³»åˆ—æ¨¡å‹
-   2021.03.04 å¢åŠ WoBERT: åŸºäºè¯é¢—ç²’åº¦çš„ä¸­æ–‡
-   2020.11.11 åˆå§‹åŒ–BERTç³»åˆ—æ¨¡å‹BERT

\[Back to Top\]

### Contributors

### Misc

#### â†³ Stargazers

#### â†³ Forkers

#### â†³ Star History

\[!\[Star History Chart\](https://api.star-history.com/svg?repos=lonePatient/awesome-pretrained-chinese-nlp-models&type=Date)\](https://star-history.com/#lonePatient/awesome-pretrained-chinese-nlp-models&Date)
